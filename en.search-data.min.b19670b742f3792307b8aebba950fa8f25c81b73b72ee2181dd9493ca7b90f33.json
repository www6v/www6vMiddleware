[{"id":0,"href":"/www6vMiddleware/docs/RMDB/%E5%8D%95%E6%9C%BA/mysqlTransactionAndLock/","title":"MySQL 事务-隔离性","section":"单机","content":"\nMyISAM vs. InnoDB\r#\r描述 MyISAM InnoDB 行锁(并发高，会死锁) × √ (默认支持)\nRecord lock: 锁记录\nGap lock: 锁范围，不锁记录\nNext-key lock： 锁范围+锁记录 表锁(并发低，不会死锁) √ √ 事务和崩溃恢复 × √ 外键 × √ MVCC × √ 在READ COMMITTED 和 REPEATABLE READ时有效 事务隔离级别 [4]\r#\r隔离级别(从高到低) 脏读 不可重复读\n（重点是修改） 幻影读\n（重点是新增或者删除） SERIALIZABLE × × × REPEATABLE-READ\n（InnoDB默认隔离级别） × × √ READ-COMMITTED × √ √ READ-UNCOMMITTED √ √ √ innodb对于行的查询使用next-key lock Next-locking keying、Gap锁为了解决Phantom Problem幻读问题 当查询的索引含有唯一属性时(单条记录)，将next-key lock降级为record key\n新的隔离级别\r#\rSI[Snapshot Isolation] Oracle 可串行化, PG和MySQL称为RR SSI[Serializable Snapshot Isolation] PostgreSQL 和 CockroachDB 已经支持 SSI RC和RR隔离级别 [chat]\r#\r下面是一个表格，归纳了以上文字中RC和RR隔离级别的特点：\n隔离级别 快照读 #1 当前读 #2 幻读 RC 不加锁 加锁[记录锁 是,间隙锁 否] 存在 RR 不加锁 加锁[记录锁 是, 间隙锁 是] 不存在 在RC隔离级别下，快照读和当前读都不会对记录加锁，因此不会阻塞其他事务的读操作。但是，由于RC隔离级别只对读取到的记录加锁，而不对读取的范围加锁，因此可能会出现幻读现象。幻读指的是，在一个事务中先后进行两次相同的查询操作，第二次查询会发现有新增的记录，这种现象是由于其他事务在事务中新增了这些记录所导致的。\n在RR隔离级别下，快照读和当前读都不会对记录加锁，但是会对读取的范围加锁，防止其他事务在该范围内插入新的记录。因此，在RR隔离级别下不存在幻读现象。\n需要注意的是，虽然RR隔离级别可以避免幻读现象，但是由于对读取范围加锁可能会导致性能问题，因此在实际应用中需要根据具体情况选择合适的隔离级别。 [ 当前读 加锁，快照读 不加锁 ]\nMVCC\r#\r原理 [2][3]\r#\rInnoDB 中的 RC(READ COMMITTED) 和 RR(REPEATABLE READ) 隔离事务是基于多版本并发控制（MVVC）实现高性能事务。 MVCC 对普通的 Select 不加锁，如果读取的数据正在执行 Delete 或 Update 操作，这时读取操作不会等待排它锁的释放，而是直接利用 MVCC 读取该行的数据快照（数据快照是指在该行的之前版本的数据，而数据快照的版本是基于 undo 实现的，undo 是用来做事务回滚的，记录了回滚的不同版本的行记录）。\nMySQL默认的事务隔离级别是RR(REPEATABLE READ), InnoDB引擎的Select操作使用一致性非锁定读（MVCC）。 对于一致性非锁定读， 即使读取的行已经被执行了select\u0026hellip;for update,也是可以读取的。\n实现\r#\r当前读/快照读 含义 例子 当前读 #2 读取的是记录的最新版本，读取时还要保证其他并发事务不能修改当前记录，会对读取的记录进行加锁。 select ... lock in share mode(共享锁)，\nselect ...for update、\nupdate、insert、delete(排他锁) 快照读 #1 简单的select（不加锁）就是快照读，快照读，读取的是记录数据的可见版本，有可能是历史数据，不加锁，是非阻塞读。 Read Committed：每次select，都生成一个快照读。\nRepeatable Read：开启事务后第一个select语句才是快照读的地方。\nSerializable：快照读会退化为当前读。 MVCC实现 [0] 隐藏字段 DB_TRX_ID: 最近修改事务ID DB_ROLL_PTR: 回滚指针 DB_ROW_ID: 隐藏主键 undolog版本链 链表的头部是最新的旧记录，链表尾部是最早的旧记录 readview ReadView（读视图）是 快照读 SQL执行时MVCC提取数据的依据，记录并维护系统当前活跃的事务（未提交的）id。 不同的隔离级别，生成ReadView的时机不同： READ COMMITTED ：在事务中每一次执行快照读时生成ReadView。 REPEATABLE READ：仅在事务中第一次执行快照读时生成ReadView，后续复用该ReadView。 参考\r#\r黑马程序员 MySQL数据库入门到精通 P141-P144 mysql_note 笔记1 MySQL 索引 笔记2 ***\n《深入浅出MySQL：数据库开发、优化与管理维护》\n《03 | 事务隔离：为什么你改了我还看不见？ 》MySQL实战45讲 丁奇\n《33 | MySQL调优之事务：高并发场景下的数据库事务调优》 Java性能调优实战 刘超 deleted\n可能是全网最好的MySQL重要知识点\n《07 | 行锁功过：怎么减少行锁对性能的影响？》 MySQL实战45讲 丁奇 deleted\n《18 | 为什么这些SQL语句逻辑相同性能却差异巨大？》MySQL实战45讲 丁奇\nMYSQL死锁的检测与预防 deleted\n{% post_link \u0026lsquo;mysqlTransaction\u0026rsquo; %} self\n"},{"id":1,"href":"/www6vMiddleware/docs/message/Kafka/kafka/","title":"Kafka总结","section":"Kafka","content":"\n参考:\r#\rKafka剖析（一）：Kafka背景及架构介绍 郭俊 Kafka设计解析（六）- Kafka高性能关键技术解析 郭俊 《kafka权威指南》 薛命灯 第3，5章 Kafka文件存储机制那些事 幽灵之使 分布式发布订阅消息系统 - Kafka架构设计 官方文档翻译 未 "},{"id":2,"href":"/www6vMiddleware/docs/message/Overview/mq/","title":"消息中间件总结","section":"Overview","content":"\n消息积压\r#\r原则: 消费性能要高于生产的性能\r#\r1. 发送端性能优化\r#\r并发和批量\n2. 消费端性能优化\r#\r分区partion和consumer同步扩容\n参考\r#\rJumper, JMQ 代码 文档 Kafka vs RocketMQ——单机系统可靠性 以夕 xxx 分布式开放消息系统(RocketMQ)的原理与实践 CHEN川 *** 消息队列设计精要 点评 王烨 失效 Kafka设计解析（六）- Kafka高性能关键技术解析 郭俊 事务消息 -\u0026gt; 消息队列 RocketMQ 阿里云官方文档 消息队列 RocketMQ、Apache RocketMQ、消息队列 Kafka、Apache Kafka、RabbitMQ 产品对比 阿里云官方文档 RocketMQ消息堆积判断 rocketMQ消息堆积监控的java实现 c614756zhang RocketMQ原理（4）——消息ACK机制及消费进度管理 Jaskey Lam "},{"id":3,"href":"/www6vMiddleware/demo/chaptor1/my-first-doc/","title":"My First Doc","section":"章节一","content":"\r一级标题\r#\r二级标题\r#\r三级标题\r#\r"},{"id":4,"href":"/www6vMiddleware/demo/chaptor1/","title":"章节一","section":"Demoes","content":"\r一级标题\r#\r二级标题\r#\r三级标题\r#\r"},{"id":5,"href":"/www6vMiddleware/demo/chaptor3/","title":"章节三","section":"Demoes","content":"\r一级标题\r#\r二级标题\r#\r三级标题\r#\r"},{"id":6,"href":"/www6vMiddleware/demo/chaptor2/","title":"章节二","section":"Demoes","content":"\r一级标题\r#\r二级标题\r#\r三级标题\r#\r"},{"id":7,"href":"/www6vMiddleware/docs/message/Kafka/kafkaProducer/","title":"Kafka Producer生产者","section":"Kafka","content":"\nProducer 架构\r#\rOverviw 1 [1]\r#\r整个生产者客户端是由主线程和Sender线程协调运行的, 主线程创建消息, 然后通过 拦截器、元信息更新、序列化、分区器、缓存消息等等流程。 Sender线程在初始化的时候就已经运行了,并且是一个while循环。\nOverviw 2\r#\rProducer 分区策略[2]\r#\rDefaultPartitioner 默认分区策略 粘性分区Sticky Partitioner UniformStickyPartitioner 纯粹的粘性分区策略 RoundRobinPartitioner 分区策略 kafka 生产者 里的buffer[3]\r#\rkafka producer中配置的 buffer.memory （参数在文末有详细说明）参数是缓冲区的大小，这个缓存区大家也就是RecordAccmulator所用的内存大小。默认是32MB。\n参考\r#\r图解kafka生产者流程,超详细！ 石臻臻 kafka contributor Kafka生产者的3种分区策略 石臻臻 kafka contributor Kafka Producer全流程分析和思考 "},{"id":8,"href":"/www6vMiddleware/docs/message/Overview/mqCompare/","title":"MQ总结(Kafka, Rocketmq, Rabbitmq)","section":"Overview","content":"\n功能 RocketMQ Kafka RabbitMQ 可靠性* - 同步刷盘\n- 异步刷盘 异步刷盘，丢数据概率高 同步刷盘 横向扩展能力 支持 支持 - 集群扩容依赖前端 - LVS 负载均衡调度 消费模型* Push/Pull Pull Push/Pull 定时消息* 支持（只支持18个固定 Level） 不支持 支持 顺序消息* 支持 支持 不支持 消息堆积能力 百亿级别 影响性能 影响性能 影响性能 消息堆积查询 支持 不支持 不支持 消息回溯 支持 支持（位置，时间） 不支持 消息重试 支持 生产者有重试机制 支持 死信队列 支持 不支持 支持 性能（常规）* 非常好 十万级 QPS 非常好 百万级 QPS 一般 万级 QPS 性能（万级 Topic 场景） 非常好 十万级 QPS 低 低 性能（海量消息堆积场景） 非常好 十万级 QPS 低 低 全链路消息轨迹 不支持 不支持 不支持 MQ比较[3]\r#\r重点[3]\r#\r功能级别不具备一票否决权 选型时要特别注意中间件的性能与扩展性 需要注重团队技术栈与中间件编程语言的匹配度 参数\r#\rKafka、RabbitMQ、RocketMQ等消息中间件的对比 https://honeypps.com/mq/kafka-vs-rabbitmq/ 未 13 | 技术选型：如何根据应用场景选择合适的消息中间件？ 丁威 "},{"id":9,"href":"/www6vMiddleware/docs/RMDB/%E5%8D%95%E6%9C%BA/mysqlUpdate/","title":"MySQL中的SQL更新语句","section":"单机","content":"\nredo log \u0026amp;\u0026amp; bin log\r#\r有了redo log，InnoDB就可以保证即使数据库发生异常重启，之前提交的记录都不会丢失，这个 能力称为crash-safe。\n\\ redo log bin log where InnoDB引擎特有的 MySQL的Server层实现的 what 物理日志，记录的是“在某个数据页上做了什么修改” 逻辑日志，记录的是这个语句的原始逻辑 how 循环写的 追加写入的 update in Mysql\r#\rMySQL里的WAL(Write-Ahead Logging)技术，它的关键点就是先写日志，再写磁盘.\n更新流程还涉及两个重要的日志模块，redo log（重做日志）和 binlog（归档日志）。\n图中浅色框表示是在InnoDB内部执行的，深色框表示是在执行器中执行的。\nredo log的写入拆成了两个步骤：prepare和commit，这就是\u0026quot;两阶段提交\u0026quot;, 让redo log和bin log之间的逻辑一致。\n参考\r#\r《MySQL实战45讲 - 日志系统：一条SQL更新语句是如何执行的？》 丁奇 "},{"id":10,"href":"/www6vMiddleware/docs/serviceGovernance/faultTolerant/soaGracefulStart/","title":"优雅启动","section":"容错\u0026限流","content":"\n优雅启动 实现 [1]\r#\r调用方发起的RPC 调用流程是怎样的，调用方应用通过服务发现能够获取到服务提供方的 IP 地址，然后每次发送请求前，都需要通过负载均衡算法从连接池中选择一个可用连接。那这样的话，我们是不是就可以让负载均衡在选择连接的时候，区分一下是否是刚启动不久的应用？对于刚启动的应用，我们可以让它被选择到的概率特别低，但这个概率会随着时间的推移慢慢变大，从而实现一个动态增加流量的过程。\n首先对于调用方来说，我们要知道服务提供方启动的时间，这个怎么获取呢？我这里给出两 种方法，一种是服务提供方在启动的时候，把自己启动的时间告诉注册中心；另外一种就是 注册中心收到的服务提供方的请求注册时间。\n调用方通过服务发现获取服务提供方的IP地址，并通过负载均衡算法选择一个可用连接进行RPC调用。为了实现动态增加流量的过程，可以让负载均衡在选择连接时区分是否是刚启动不久的应用。可以通过以下两种方法获取服务提供方的启动时间：一种是服务提供方在启动时告知注册中心自己的启动时间，另一种是注册中心记录服务提供方的注册时间。[gpt 总结]\n延迟加载 [1]\r#\r上述问题的解决方法是将应用启动过程中注册服务的步骤延迟到应用启动完成后，以避免在应用启动未完成时接受请求。此外，可以在应用启动完成后，预先加载和初始化相关资源，如缓存数据，以降低请求处理错误的概率。 [gpt总结]\n参考\r#\r《14 | 优雅启动：如何避免流量打到没有启动完成的节点？》 "},{"id":11,"href":"/www6vMiddleware/docs/message/Overview/mqOrdering/","title":"消息系统 顺序消息","section":"Overview","content":"\n顺序消息\r#\r严格顺序消息(场景:数据库复制),单个生产者/消费者[jmq,Rocketmq]\r#\rjmq方案，任意时刻都有两个消息副本 [3] 单个生产者生产，其余生产者会抛出异常[jmq] 单个消费者消费，其余消费者会抛出异常[jmq] 正常流程:消息队列分配在两组以上的BROKER组，每个BROKER组由MASTER-SLAVE组成。消息同步写入单个broker的MASTER。 异常处理流程：Master宕机后，slave只能消费读。生产failover到下一个可用的Broker组，等宕机的broker组的slave消费完，然后消费被挑选到的可用的Broker组的slave 协调者 controller：BROKER组的集群信息在协调者上保存为一个单向的链表，消费者和发送者各有一份独立的链表数据。 rocketmq方案 顺序消息 rocketmq 顺序消息 [6][9][10] 从业务层面来保证消息的顺序而不仅仅是依赖于消息系统.比如，订单号相同的消息会被先后发送到同一个队列中 从业务层面来保证消息的顺序, 而不仅仅是依赖于消息系统 Eg. 订单号相同的消息会被先后发送到同一个队列中 partition 内部有序, 局部有序[kafka]\r#\rpull模型+单线程生产/消费[metaq]\r#\r参考\r#\rjmq顺序消息\r#\r高可用保证消息绝对顺序消费的BROKER设计方案 丁俊 rocketmq顺序消息\r#\r分布式开放消息系统(RocketMQ)的原理与实践 CHEN川 *** 消息的顺序问题 消息的重复问题 聊一聊顺序消息（RocketMQ顺序消息的实现机制） 杭州.Mark producer: selector, 相同orderid的发送到同一个topic; consumer: 多消费者加锁竞争消息 收发顺序消息 阿里云文档 "},{"id":12,"href":"/www6vMiddleware/docs/RMDB/%E5%8D%95%E6%9C%BA/mysqlReliability/","title":"MySQL的主从 高可用 容灾","section":"单机","content":"\nMySQL主从复制原理\r#\r主从复制-流程\r#\rMySQL主从复制\nMySQL master 将数据变更写入二进制日志( binary log, 其中记录叫做二进制日志事件binary log events，可以通过 show binlog events 进行查看) MySQL slave 将 master 的 binary log events 拷贝到它的中继日志(relay log) MySQL slave 重放 relay log 中事件，将数据变更反映它自己的数据 主从复制-类型 [6]\r#\r异步复制 半同步复制 MHA + 半同步复制 全同步复制 MGR + 全同步 主备切换 [1]\r#\r因为readonly设置对超级(super)权限用户是无效的，而用于同步更新的线程，就拥有超级权限。\n一个事务日志同步的完整过程是这样的： 在备库B上通过change master命令，设置主库A的IP、端口、用户名、密码，以及要从哪个 位置开始请求binlog，这个位置包含文件名和日志偏移量。 在备库B上执行start slave命令，这时候备库会启动两个线程，就是图中的io_thread和 sql_thread。其中io_thread负责与主库建立连接。 主库A校验完用户名、密码后，开始按照备库B传过来的位置，从本地读取binlog，发给B。 备库B拿到binlog后，写到本地文件，称为中转日志（relay log）。 sql_thread读取中转日志，解析出日志里的命令，并执行。 Master-Master(双M)循环复制问题 [1]\r#\r如果设置了双M结构，日志的执行流就会变成这样： 从节点A更新的事务，binlog里面记的都是A的server id； 传到节点B执行一次以后，节点B生成的binlog 的server id也是A的server id； 再传回给节点A，A判断到这个server id与自己的相同，就不会再处理这个日志。所以，死循 环在这里就断掉了。 主备延迟 [2]\r#\r主备延迟原因 备库所在机器的性能要比主库所在的机器性能差 备库的压力大 解决方案: I. 一主多从。除了备库外，可以多接几个从库，让这些从库来分担读的压力。 II. 通过binlog输出到外部系统，比如Hadoop这类系统，让外部系统提供统计类查询的能力。 大事务 解决方案: I. 不要一次性地用delete语句删除太多数据 II. 大表DDL场景, 处理方案就是，计划内的DDL，建议使用gh-ost方案. 备库的并行复制能力 [3] 主备切换的策略 [2]\r#\r由于主备延迟的存在，所以在主备切换的时候，就相应的有不同的策略。\n可靠性优先策略 - 数据不丢、安全可靠 可用性优先策略 - 服务可用 小结： 实际的应用中，我更建议使用可靠性优先的策略。 在满足数据可靠性的前提下，MySQL高可用系统的可用性，是依赖于主备延迟的。延迟的时间越小，在主库故障的时候，服务恢复需要的时间就越短，可用性就越高。\n高可用方案-Master高可用[5]\r#\rMMM\r#\r早期，不建议使用\nMHA - 单主 +\r#\rMHA-manager 管理Master 使用半同步复制 缺陷： 只关注到master，对slave关注不够 MySQL Group Replicatoin(MGR) - 单主 [6]+\r#\r单主(荐) 多主(不推荐) 5.7之后支持 raft协议算法，自动选主节点， 自动故障转移 全同步复制, 稳定性高, 强一致性 缺陷： 不支持gap lock(间隙锁)， 隔离级别需设置为read_commited 只能在GTID模式下， 并且日志格式未row格式 不支持对表进行锁操作(lock/unlock table) DDL语句不支持原子性 最多支持9个节点 MySQL Cluster - 多主\r#\r官方亲儿子 NDB engine， 存算分离 实现数据的强一致 缺陷：国内使用少， 配置复杂 Galera Cluster - 多主 +\r#\r三方提供 Master和数据Node部署在一起 WSREP协议来做数据同步 Percona XtraDB(PXC) -多主\r#\r早期 高可用方案 - 数据可靠性[5]\r#\rRaid10( Raid 1+0 )\r#\rSAN共享存储- 贵\r#\rDRBD磁盘复制-系统自带 +\r#\rMySQL Log和可靠性\r#\r{% post_link \u0026lsquo;mysqlLog\u0026rsquo; %}\n容灾 [7]\r#\r参考\r#\r《MySQL是怎么保证主备一致的？》 MySQL实战45讲 丁奇 《MySQL是怎么保证高可用的？》 MySQL实战45讲 丁奇 《备库为什么会延迟好几个小时？》MySQL实战45讲 丁奇 xxx 【IT老齐245】综合对比九种MySQL高可用方案 【IT老齐099】哎，MySQL高可用架构选型要慎重啊！ 腾讯云原生数据库 TDSQL-C异地容灾核心能力构建 MySQL主从复制原理剖析与应用实践 vivo team 未 "},{"id":13,"href":"/www6vMiddleware/docs/message/Kafka/kafkaConsumer/","title":"Kafka消费者总结","section":"Kafka","content":"\nKafka消费者\r#\r总结\r#\rlag\r#\r消费者\r#\r批量消费 消费者的ZeroCopy:\n直接把消息从文件里发送到网络通道， 而不需要内核与用户态之间数据的来回复制。 Q\u0026amp;A\r#\r怎么计算Lag？(注意read_uncommitted和read_committed状态下的不同)\n“消费组中的消费者个数如果超过topic的分区，那么就会有消费者消费不到数据”这句话是否正确？如果不正确，那么有没有什么hack的手段？\n消费者提交消费位移时提交的是当前消费到的最新消息的offset还是offset+1?\n有哪些情形会造成重复消费？\nKafka常见的导致重复消费原因和解决方案\n原因3:（重复消费最常见的原因）：消费后的数据，当offset还没有提交时，partition就断开连接。比如，通常会遇到消费的数据，处理很耗时，导致超过了Kafka的session timeout时间（0.10.x版本默认是30秒），那么就会re-blance重平衡，此时有一定几率offset没提交，会导致重平衡后重复消费。\n那些情景下会造成消息漏消费？\nKafka 可靠性总结\n聊聊 Kafka：Kafka 消息丢失的场景以及最佳实践\nKafkaConsumer是非线程安全的，那么怎么样实现多线程消费？\n简述消费者与消费组之间的关系\nKafka的旧版Scala的消费者客户端的设计有什么缺陷？\n参考\r#\rKafka设计解析（四）- Kafka Consumer设计解析 郭俊 Kafka的Lag计算误区及正确实现 朱小厮 《kafka权威指南》 薛命灯 第3，4 ，5章 Kafka Consumer机制优化-保证每条消息至少消费一次 幽灵之使 分区分配策略\nKafka分区分配策略（1）——RangeAssignor 朱小厮\nKafka分区分配策略（2）——RoundRobinAssignor和StickyAssignor 朱小厮\nKafka分区分配策略（3）——自定义分区分配策略 朱小厮\n图解Kafka消费者分区分配策略 石臻臻 kafka contributor *** 未\n"},{"id":14,"href":"/www6vMiddleware/docs/serviceGovernance/faultTolerant/soaGracefulClose/","title":"优雅关闭","section":"容错\u0026限流","content":"\n关闭流程\r#\r关闭流程的优雅处理可以通过以下步骤实现 [gpt 总结]\n服务提供方在关闭时设置一个请求挡板，告知调用方正在关闭并不能处理新的请求。 当服务提供方收到新的业务请求时，直接返回一个特定的异常（如ShutdownException）给调用方。 调用方收到异常响应后，将该节点从健康列表中挪出，并自动将请求重试到其他节点，保证业务无损。 除了等待被动调用外，可以加上主动通知流程，提高实时性并避免通知失败的情况。 通过捕获操作系统的进程信号，如使用Java语言中的Runtime.addShutdownHook方法，在关闭钩子中进行关闭标识的设置和服务对象的安全关闭。 在调用链中加入挡板处理器，当新的请求到来时，判断关闭标识，如果正在关闭，则抛出特定异常。 为了完成正在处理的请求，可以在服务对象上添加引用计数器，在开始处理请求前加一，完成处理后减一，根据引用计数器判断是否有正在处理的请求。 服务对象在关闭过程中拒绝新的请求，并根据引用计数器等待正在处理的请求全部结束后真正关闭。 为避免无法正常退出应用，可以在ShutdownHook中添加超时时间控制，当超过指定时间仍未结束，则强制退出应用。 通过以上步骤，实现了服务提供方的优雅关闭，保证业务正常处理并最大限度地完成正在处理的请求。\n参考\r#\r《13 | 优雅关闭：如何避免服务停机带来的业务损失？》\n"},{"id":15,"href":"/www6vMiddleware/docs/message/Kafka/kafkaRebalance/","title":"Kafka消费者-Rebalance机制","section":"Kafka","content":"\nRebalance (What)\r#\rRebalance 定义\n在同一个消费者组当中，分区的所有权从一个消费者转移到另外一个消费者 原理\n重平衡的通知机制正是通过心跳线程来完成的 [7] 角色\nconsumer leader cordinator[8]\nRebalance 发生的时机有三个 (when) [1]\r#\r重平衡的 3 个触发条件：\n组成员数量发生变化。(最常遇到)\n订阅主题数量发生变化。\n订阅主题的分区数发生变化。 问题和解决方案\r#\rRebalance 的 弊端 [1]\r#\rRebalance 影响 Consumer 端 TPS\n在 Rebalance 期间，Consumer 会停下手头的事情，什么也干不了 如果你的 Group 下成员很多， Rebalance 会很慢。 Rebalance 效率不高\nGroup 下的 所有成员都要参与进来，而且通常不会考虑局部性原理 consumer rebalance 的问题\r#\rRebalance 过程也和这个类似，在 Rebalance 过程中，所有 Consumer 实例都会停止消费，等待 Rebalance 完成。 这是 Rebalance 为人诟病的一个方面。\n【消费者重平衡的时候， 所有的消费者是不能消费数据的。】 “不必要的”的Rebalance (Solution) [1]\r#\r第一类非必要 Rebalance 是因为未能及时发送心跳，导致 Consumer 被“踢出”Group 而引发的。 因此，你需要仔细地设置session.timeout.ms 和 heartbeat.interval.ms的 值。\n第二类非必要 Rebalance 是 Consumer 消费时间过长导致的。\nmax.poll.interval.ms参数值的设置显得尤为关键。\n总结\r#\rQ\u0026amp;A\r#\r消费再均衡的原理是什么？（提示：消费者协调器和消费组协调器） 参考\r#\r《17 | 消费者组重平衡能避免吗? 》 胡夕 《15丨消费者组到底是什么？》 胡夕 《25 | 消费者组重平衡全流程解析》 胡夕 Kafka的Rebalance机制可能造成的影响及解决方案 线上Kafka突发rebalance异常，如何快速解决？ 为什么消费客户端频繁出现Rebalance？ 石臻臻 Kafka消费者客户端心跳请求 石臻臻 什么是Kafka消费组协调器 石臻臻 "},{"id":16,"href":"/www6vMiddleware/docs/RMDB/%E5%8D%95%E6%9C%BA/mysqlIndex/","title":"MySQL的索引和优化","section":"单机","content":"\n索引-结构\r#\r索引分类[7]\r#\r分类 含义 特点 关键字 主键索引 针对于表中主键创建的索引 默认自动创建，只能有一个 PRIMARY 唯一索引 避免同一个表中某数据列中的值重复 可以有多个 UNIQUE 常规索引 快速定位特定数据 可以有多个 全文索引 全文索引查找的是文本中的关键词，而不是比较索引中的值 可以有多个 FULLTEXT 分类 含义 特点 聚集索引(Clustered Index) 将数据存储与索引放一块，索引结构的叶子节点保存了行数据 必须有，而且只有一个 二级索引(Secondary Index) 将数据与索引分开存储，索引结构的叶子节点关联的是对应的主键 可以存在多个 聚集索引选取规则: 如果存在主键，主键索引就是聚集索引 如果不存在主键，将使用第一个唯一（UNIQUE）索引作为聚集索引。 如果表没有主键，或没有合适的唯一索引，则InnoDB会自动生成一个rowid作为隐藏的聚集索 引。 索引结构和存储引擎 [3]\r#\r索引的数据结构： B+树能够很好地配合磁盘的读写特性，减少单次查询的磁盘访问次数\nindex MyISAM InnoDB Memory B-Tree\n（balanced 平衡的） 支持 支持 支持 Hash 不支持 不支持 支持 R-Tree 空间索引 支持 不支持 不支持 Full-text 支持 支持 不支持 复合索引的数据结构\r#\rcreate table people {\rlast_name,\rfirst_name,\rdob,\rgender,\rkey(last_name, first_name, dob)\r} 索引- 使用\r#\r索引的使用场景\r#\r索引的使用场景 例子 匹配全值 index (a,b,c) a=1 and b=2 and c=3 范围查找 index a\u0026gt;1 and b\u0026lt;3 匹配最左前缀 index(a，b，c) a OR a，b OR a、b、c OR a，c 会使用 b、c 不使用 仅对索引列进行查询（覆盖索引） index a a=1 匹配列前缀 index （a， b） a like \u0026lsquo;WEER%\u0026rsquo; Index Condition Pushdown（ICP） 减少回表IO 索引的失效 [12][7]\r#\r非复合索引\n索引失效(不会使用index的场景) 例子 解释 在索引列上进行运算操作 substring(phone,10,2) 对索引字段做函数操作，可能会破坏索引值的有序性，因此优化器就决定放弃走树搜索功能。 模糊查询, 头部模糊匹配 like \u0026ldquo;%NI\u0026rdquo; 字符串类型字段使用时，不加引号[隐式转换] lastname=1 不使用索引 lastname=\u0026lsquo;1\u0026rsquo; 使用索引 隐式类型转换， 隐式字符编码转换，等价于在索引字段上做函数操作而导致了全索引扫描。 or连接条件 index a a=3 or c=6 or d=9 如果or前的条件中的列有索引，而后面的列中没有索引，那么涉及的索引都不会被用到. 当or连接的条件，左右两侧字段都有索引时，索引才会生效。 复合索引[7]\n最左前缀原则 如果索引关联了多列（联合索引），要遵守最左前缀法则，最左前缀法则指的是查询从索引的最左列开始，并且不跳过索引中的列。如果跳跃某一列，索引将部分失效（后面的字段索引失效）。 范围查询 联合索引中，出现范围查询(\u0026gt;,\u0026lt;)，范围查询右侧的列索引失效。 explain select * from tb_user where profession = \u0026#39;软件工程\u0026#39; and age \u0026gt;= 30 and status = \u0026#39;0\u0026#39;; 索引-优化\r#\r索引维护\r#\r页分裂， 性能会受影响， 整体空间利用率降低大约50%。 页合并，页分裂的逆过程。\n自增主键\r#\r自增主键的插入数据模式，正符合了递增插入的场景。每次插入一条 新记录，都是追加操作，都不涉及到挪动其他记录，也不会触发叶子节点的分裂。 而有业务逻辑的字段做主键，则往往不容易保证有序插入，这样写数据成本相对较高。\n除了考虑性能外，我们还可以从存储空间的角度来看。假设你的表中确实有一个唯一字段，比如 字符串类型的身份证号，那应该用身份证号做主键，还是用自增字段做主键呢？ 由于每个非主键索引的叶子节点上都是主键的值。如果用身份证号做主键，那么每个二级索引的 叶子节点占用约20个字节，而如果用整型做主键，则只要4个字节，如果是长整型（bigint）则是 8个字节。显然，主键长度越小，普通索引的叶子节点就越小，普通索引占用的空间也就越小。 这样，非主键索引占用的空间最小。\n所以，从性能和存储空间方面考量，自增主键往往是更合理的选择。 [自增主键使得索引值是顺序插入的，而不是随机插入的， insert时性能更高。 顺序插入同时也减少了页分裂]\n覆盖索引(优化手段)\r#\r如果执行的语句是select ID from T where k between 3 and 5，这时只需要查ID的值，而ID的值 已经在k索引树上了，因此可以直接提供查询结果，不需要回表。也就是说，在这个查询里面， 索引k已经“覆盖了”我们的查询需求，我们称为覆盖索引.\n覆盖索引可以减少树的搜索次数，显著提升查询性能，所以使用覆盖索引是一个常用的性能优化手段. [不需要回表， 不需要回到聚集索引里查询]\n索引下推 ICP [14]\r#\r索引-性能分析[7]\r#\r查看执行频次\r#\rSHOW GLOBAL STATUS LIKE \u0026#39;Com_______\u0026#39;; 慢查询日志\r#\rshow profiles\r#\r## 查看每一条SQL的耗时情况: mysql\u0026gt; show profiles; explain\r#\rtype：表示连接类型，性能由好到差的连接类型为 NULL、system、const、eq_ref、ref、range、index、all possible_key：可能应用在这张表上的索引，一个或多个 Key：实际使用的索引，如果为 NULL，则没有使用索引 Key_len：表示索引中使用的字节数，该值为索引字段最大可能长度，并非实际使用长度，在不损失精确性的前提下，长度越短越好 rows：MySQL认为必须要执行的行数，在InnoDB引擎的表中，是一个估计值，可能并不总是准确的 参考\r#\r《深入浅出MySQL：数据库开发、优化与管理维护》\nMySQL索引背后的数据结构及算法原理\n理解MySQL——索引与优化\nxxx\n剖析Mysql的InnoDB索引 ***\n可能是全网最好的MySQL重要知识点 已失效\n黑马程序员 MySQL数据库入门到精通 P75-P82 P72 mysql_note 笔记1 MySQL 索引 笔记2\nxxx\nali canal\n《MySQL实战45讲 - 深入浅出索引（上）》 丁奇\n《MySQL实战45讲 - 深入浅出索引（下）》 丁奇\n《Java性能调优实战 - 34 | MySQL调优之索引：索引的失效与优化》 刘超 还要再整理\nMySQL索引（二）B+树在磁盘中的存储\nB+树索引并不能直接找到行，只是找到行所在的页，通过把整页读入内存，再在内存中查找。 聚集索引的存储在物理上并不是连续的，每个数据页在不同的磁盘块，通过一个双向链表来进行连接。\n五分钟搞懂MySQL索引下推\nMySQL索引原理及慢查询优化 美团 未 ***\n业界难题-“跨库分页”的四种方案 58沈剑 未\n"},{"id":17,"href":"/www6vMiddleware/docs/message/Kafka/kafkaReliability/","title":"Kafka 可靠性总结","section":"Kafka","content":"\nKafka高可靠配置\r#\r位置 配置项 可靠性 topic的配置 replication.factor\u0026gt;=3,即副本数至少是3个 复制因子\nreplication.factor(topic级别) default.replication.factor(broker级别) - 2\u0026lt;=min.insync.replicas\u0026lt;=replication.factor 最少同步副本min.insync.replicas 3副本（总）\n+ 3副本，一般最少同步2副本 + 最少同步2副本时，如2副本挂了，这时不能写，只能读.\n设置为1，单副本挂了，就会丢数据【3】 broker的配置 leader的选举条件unclean.leader.election.enable=false unclean.leader.election -\u0026gt; broker级别 1.允许不同步的副本成为首领 ，有数据不可靠的风险.\n2.不允许不同步的副本成为首领 ，降低了可用性. 3. 强烈建议不要开启它，还可以通过其他的方式来提升可用性 producer的配置 request.required.acks=-1(all)【6】 producer.type=sync【7】 如何确保消息不会丢失\r#\r生产阶段\r#\r在编写发送消息代码时，需要注意，正确处理返回值或者捕获异常，就可以保证这个阶段的消息不会丢失。\n捕获消息发送的错误，并重发消息。 异步发送时，则需要在回调方法里进行检查。这个地方是需要特别注意的，很多丢消息的原因就是，使用了异步发送，却没有在回调中检查发送结果。 存储阶段\r#\r通过配置刷盘和复制相关的参数，让消息写入到多个副本的磁盘上，来确保消息不会因为某个 Broker 宕机或者磁盘损坏而丢失。\nEg. 在 RocketMQ 中，需要将刷盘方式 flushDiskType 配置为 SYNC_FLUSH 同步刷盘\nEg. 表. kafka高可靠配置 topic的配置 消费阶段\r#\r在处理完全部消费业务逻辑之后，再发送消费确认。 检测消息丢失的方法\r#\r可以利用消息队列的有序性来验证是否有消息丢失。在 Producer 端，我们给每个发出的消息附加一个连续递增的序号，然后在 Consumer 端来检查这个序号的连续性。\nQ\u0026amp;A\r#\r怎么样才能确保Kafka极大程度上的可靠性？ Kafka在可靠性方面做了哪些改进？（HW, LeaderEpoch）\nKafka 可靠性总结 参考:\r#\rKafka设计解析（六）- Kafka高性能架构之道 郭俊 kafka数据可靠性深度解读 朱忠华 《Kafka权威指南》 第6 章可靠的数据传递 薛命灯 《消息队列高手课 - 如何确保消息不会丢失？》 李玥 "},{"id":18,"href":"/www6vMiddleware/docs/RMDB/%E5%8D%95%E6%9C%BA/mysqlTransaction/","title":"MySQL事务-总结","section":"单机","content":"\nMySQL Log和事务\r#\r{% post_link \u0026lsquo;mysqlLog\u0026rsquo; %}\n参考\r#\r拨开云雾见天日：剖析单机事务原理 CHEN川 *** 多版本并发控制(MVCC)在分布式系统中的应用 Todd 阿里云分布式缓存OCS与DB之间的数据一致性 杨成虎 乐观锁和 MVCC 的区别？ mysql可重复读和幻读实例 CWeeYii MySQL脏读、虚读、幻读 Eternity味道 MySQL 中事务的实现原理 失效 "},{"id":19,"href":"/www6vMiddleware/docs/RMDB/%E5%8D%95%E6%9C%BA/mysqlLog/","title":"MySQL Logs","section":"单机","content":"\nMySQL Log和事务[0]\r#\rredo log\r#\r有了redolog之后，当对缓冲区的数据进行增删改之后，会首先将操作的数据页的变化，记录在redo log buffer中。在事务提交时，会将redo log buffer中的数据刷新到redo log磁盘文件中。过一段时间之后，如果刷新缓冲区的脏页到磁盘时，发生错误，此时就可以借助于redo log进行数据恢复，这样就保证了事务的持久性。 因为在业务操作中，我们操作数据一般都是随机读写磁盘的，而不是顺序读写磁盘。 而redo log在往磁盘文件中写入数据，由于是日志文件，所以都是顺序写的。顺序写的效率，要远大于随机写。 这种先写日志的方式，称之为** WAL（Write-Ahead Logging）**。 undo log\r#\r回滚日志，用于记录数据被修改前的信息 , 作用包含两个 : **提供回滚(保证事务的原子性) 和MVCC(多版本并发控制) **。\nundo log和redo log记录物理日志不一样，它是逻辑日志。可以认为当delete一条记录时，undolog中会记录一条对应的insert记录，反之亦然，当update一条记录时，它记录一条对应相反的update记录。\n总结\r#\rLog 性质 记录内容 ACID redo log 物理日志[记录内容] wal 保证事务的持久性[D] undo log 物理日志[记录内容] 被修改前的信息，提供回滚 保证事务的原子性[A] ​ binlog 逻辑日志[记录操作]\nMySQL Log和可靠性\r#\rbinlog的三种格式[1]\r#\rstatement\nrow格式\nmixed格式: statement or row格式\n因为有些statement格式的binlog可能会导致主备不一致，所以要使用row格式。 但row格式的缺点是，很占空间。比如你用一个delete语句删掉10万行数据，用statement的话就是一个SQL语句被记录到binlog中，占用几十个字节的空间。但如果用row格式的binlog，就要把这10万条记录都写到binlog中。这样做，不仅会占用更大的空间，同时写binlog也要耗费IO资源，影响执行速度。 所以，MySQL就取了个折中方案，也就是有了mixed格式的binlog。mixed格式的意思是，MySQL自己会判断这条SQL语句是否可能引起主备不一致，如果有可能，就用row格式，否则就用statement格式。 也就是说，mixed格式可以利用statment格式的优点，同时又避免了数据不一致的风险.因此，如果你的线上MySQL设置的binlog格式是statement的话，那基本上就可以认为这是一个不合理的设置。你至少应该把binlog的格式设置为mixed。\nredo log 和 undo log [4]\r#\rredo Log\nWAL日志，保证事务持久性 buffer楼盘之前数据库意外宕机， 可以进行数据的恢复 undo log\n保证事务原子性， 回滚或者事务异常，可以回滚到历史版本 实现MVCC的必要条件 事务开始. 记录A=1到undo log. 修改A=3. 记录A=3到redo log.( 先写内存， 后同步到磁盘中) 记录B=2到undo log. 修改B=4. 记录B=4到redo log.( 先写内存， 后同步到磁盘中) 将redo log写入磁盘。 事务提交 参考\r#\r黑马程序员 MySQL数据库入门到精通 P138 - P140 mysql_note 笔记1 MySQL 索引 笔记2 ***\n《MySQL是怎么保证主备一致的？》 MySQL实战45讲 丁奇\n《云数据库架构》 1.1.5 1.1.7 - 阿里云\n"},{"id":20,"href":"/www6vMiddleware/docs/message/Kafka/kafkaIndex/","title":"Kafka 索引","section":"Kafka","content":"\nKafka索引\r#\r稀疏索引 LogSegment 构成\r#\r$ tree /tmp/kafka-logs/t1-1/ /tmp/kafka-logs/t1-1/ ├── 00000000000000000000.index ├── 00000000000000000000.log ## 位移索引 ├── 00000000000000000000.timeindex ## 时间戳索引 └── leader-epoch-checkpoint Index类型\r#\r位移索引 [3] 假设要查找偏移量为230的消息，查找过程如下： 首先找到baseOffset=217的日志段文件（这里使用了跳跃表的结构来加速查找） 计算相对偏移量relativeOffset=230-217=13 在索引文件中查找不大于13的最大相对偏移量对应的索引项，即[12,456] 根据12对应的物理地址456，在日志文件.log中定位到准确位置 从日志文件物理位置456继续向后查找找到相对偏移量为13，即绝对偏移量为230，物理地址为468的消息 时间戳索引 [3] 假设要查找时间戳为1540的消息，查找过程如下（这里时间戳只是一个示意值）： 将要查找的时间戳1540和每个日志段的最大时间戳逐一对比，直到找到最大时间戳不小于1540的日志段。（日志段的最大时间戳：获取时间戳索引文件最后一个索引项的时间戳，如果大于0，取该值；否则取日志段的最近修改时间） 找到对应的日志段后，在时间戳索引文件中使用二分查找找到不大于目标时间戳1540的最大索引项，即图中的[1530,12]，获取对应的相对偏移量12 在该日志段的偏移量索引文件中找到相对偏移量不大于12的索引项，即图中的[12，456] 在日志文件中从物理位置456开始查找时间戳不小于1540的消息 位移索引 vs 时间戳索引 [2] 改进版二分查找算法 [1]\r#\r在位移索引 和 时间戳索引中都使用二分查找算法\n示例 现在，最新索引项保存在 Page #13 中。如果要查找最新索引项，原版二分查找算法将会 依次访问 Page #0、7、10、12 和 13。此时，问题来了：Page 7 和 10 已经很久没有被 访问过了，它们大概率不在页缓存中，因此，一旦索引开始征用 Page #13，就会发生 Page Fault，等待那些冷页数据从磁盘中加载到页缓存。根据国外用户的测试，这种加载过程可能长达 1 秒。\n日志模块 Q\u0026amp;A\r#\r简述Kafka的日志目录结构 Kafka中有那些索引文件？ 如果我指定了一个offset，Kafka怎么查找到对应的消息？ 如果我指定了一个timestamp，Kafka怎么查找到对应的消息？ 聊一聊你对Kafka的Log Retention的理解 聊一聊你对Kafka的Log Compaction的理解 聊一聊你对Kafka底层存储的理解（页缓存、内核层、块层、设备层） 参考\r#\r《04 | 索引（上）：改进的二分查找算法在Kafka索引的应用》 《05丨索引（下）：位移索引和时间戳索引的区别是什么？》 深入理解Kafka服务端之索引文件及mmap内存映射 *** "},{"id":21,"href":"/www6vMiddleware/docs/RMDB/%E5%8D%95%E6%9C%BA/mysqlDeadLock/","title":"MySQL  锁和死锁","section":"单机","content":"\n锁\r#\r行锁， 锁优化 [3]\r#\r在InnoDB事务中，行锁是在需要的时候才加上的，但并不是不需要了就立刻释放，而是要等到事务结束时才释放。这个就是两阶段锁协议。 知道了这个设定，对我们使用事务有什么帮助呢？那就是，如果你的事务中需要锁多个行，要把最可能造成锁冲突、最可能影响并发度的锁尽量往后放.[todo 加个例子]\n行锁是通过索引实现的，如果不通过索引条件检索数据，那么 InnoDB 将对表中所有的记录进行加锁。\n行锁的具体实现算法有三种：record lock、gap lock 以及 next-key lock。\nrecord lock是专门对索引项加锁； gap lock 是对索引项之间的间隙加锁； next-key lock 则是前面两种的组合，对索引项以其之间的间隙加锁。 只在可重复读或以上隔离级别下的特定操作才会取得 gap lock 或 next-key lock，在Select 、Update 和 Delete 时，除了基于唯一索引的查询之外，其他索引查询时都会获取gap lock 或 next-key lock，即锁住其扫描的范围。 隐式锁和显示锁\r#\r显示锁 SELECT \u0026hellip; LOCK IN SHARE MODE(加共享锁); SELECT \u0026hellip; FOR UPDATE(加排他锁);\n死锁\r#\r死锁和死锁检测 [5]\r#\r当出现死锁以后，有两种策略：\n一种策略是，直接进入等待，直到超时。这个超时时间可以通过参数 innodb_lock_wait_timeout来设置。 innodb_lock_wait_timeout的默认值是50s。 实际中不用这种策略。\n另一种策略是，发起死锁检测，发现死锁后，主动回滚死锁链条中的某一个事务，让其他事 务得以继续执行。将参数 innodb_deadlock_detect 设置为on，表示开启这个逻辑。\n带来的问题：每个新来的被堵住的线程，都要判断会不会由于自己的加入导致了死锁，这是一个时间复杂度是O(n)的操作。假设有1000个并发线程要同时更新同一行，那么死锁检测操作就是100万这个量级的。虽然最终检测的结果是没有死锁，但是这期间要消耗大量的CPU资源。\n一种解决思路是控制并发度：并发控制要做在数据库服务端。如果有中间件，可以考虑在中间件实现；如果-团队有能修改MySQL源码的人，也可以做在MySQL里面。基本思路就是，对于相同行的更新，-在进入引擎之前排队。这样在InnoDB内部就不会有大量的死锁检测工作了。\n另一种解决思路是在应用层上优化:你可以考虑通过将一行改成逻辑上的多行来减少锁冲突。 比如，一个账户1条记录变10条记录。\n预防死锁 [7]\r#\r减少长事务 大事务拆成小事务 保证加锁顺序一直 业务允许的情况下，降低隔离级别 RR几倍下会有间隙锁，会提高死锁发生的概率 死锁的排查和解决 [7]\r#\r通过日志系统及时通知死锁事件 通过ELK做通知 结合业务代码与死锁日志 进行分析 通过 pt-deadlock-logger 监控死锁 查看最近一次的死锁日志\nshow engine innodb status 案例\r#\rCase [1]\r#\r原因\r#\r死锁是在并发环境下，两个或多个事务互相等待对方持有的资源而无法继续执行的情况。在上文中，死锁的产生是因为两个事务A和事务B都持有间隙(4,+∞）的gap锁，并且两个事务都在等待对方释放锁，导致循环等待而造成死锁。\n解决方案\r#\rinnodb_lock_wait_timeout 超时时间 - 通用 避免死锁最直观的方法就是在两个事务相互等待时，**当一个事务的等待时间超过设置的某一 阈值，就对这个事务进行回滚，另一个事务就可以继续执行了。**这种方法简单有效，在 InnoDB 中，参数 innodb_lock_wait_timeout 是用来设置超时时间的。\n替换 幂等性校验 - 非通用 我们还可以使用其它的方式来代替数据库实现幂等性校验。例如，使用 Redis 以及 ZooKeeper 来实现，运行效率比数据库更佳。\n参考\r#\r《35 | 记一次线上SQL死锁事故：如何避免死锁？》 刘超 《33 | MySQL调优之事务：高并发场景下的数据库事务调优》 刘超 《07 | 行锁功过：怎么减少行锁对性能的影响？》 MySQL实战45讲 丁奇 MYSQL死锁的检测与预防 "},{"id":22,"href":"/www6vMiddleware/docs/message/Kafka/kafkaZeroCopy/","title":"Kafka-ZeroCopy","section":"Kafka","content":"\nIndex 中的mmap\r#\r在 AbstractIndex 中，这个 MappedByteBuffer 就是名为 mmap 的变量。 接下来，我用注释的方式，带你深入了解下这个 mmap 的主要流程。\n@volatile protected var mmap: MappedByteBuffer = { // 第1步：创建索引文件 val newlyCreated = file.createNewFile() // 第2步：以writable指定的方式（读写方式或只读方式）打开索引文件 val raf = if (writable) new RandomAccessFile(file, \u0026#34;rw\u0026#34;) else new Rando try { if(newlyCreated) { if(maxIndexSize \u0026lt; entrySize) // 预设的索引文件大小不能太小，如果连一个索引 throw new IllegalArgumentException(\u0026#34;Invalid max index size: \u0026#34; + m // 第3步：设置索引文件长度，roundDownToExactMultiple计算的是不超过maxInde // 比如maxIndexSize=1234567，entrySize=8，那么调整后的文件长度为1234560 raf.setLength(roundDownToExactMultipl 这些代码最主要的作用就是创建 mmap 对象。AbstractIndex 其他大部分的操作都是和 mmap 相关。\nAbstractIndex：这是 Kafka 所有类型索引的抽象父类，里面的 mmap 变量是实现索引机制的核心。\nmmap+write [4][5]\r#\r4次context切换 消费者中的sendfile() [6]\r#\rkafka的mmap是对写的优化，还是读的优化？ 参考\r#\r动画讲解：Kafka为什么快之零拷贝技术 \u0026ndash; mmap\n{% post_link \u0026lsquo;zeroCopy\u0026rsquo; %} self\n动画讲解：Kafka为什么快之零拷贝技术-sendfile()函数 ***\nKafka Zero-Copy 使用分析 transferTo() 未\nlinux零拷贝原理，RocketMQ＆Kafka使用对比 * 未\nRocketMQ入门（上） 未\n"},{"id":23,"href":"/www6vMiddleware/docs/RMDB/%E5%8D%95%E6%9C%BA/mysqlMasterSlaveDelay/","title":"MySQL 主从延迟","section":"单机","content":"\n案例 [1]\r#\r案例一：主库DML请求频繁\r#\r解决思路 如果是MySQL 5.7以下的版本，可以做分片(sharding)，通过水平扩展(scale out)的方法打散写请求，提升写请求写入binlog的并行度。 MySQL 5.7以上的版本， 在MySQL 5.7，使用了基于逻辑时钟(Group Commit)的并行复制。 而在MySQL 8.0，使用了基于Write Set的并行复制。 案例二：主库执行大事务\r#\r解决思路 拆分大事务语句到若干小事务中，这样能够进行及时提交，减小主从复制延时。 案例三：主库对大表执行DDL语句\r#\r解决思路 避免业务高峰，尽量安排在业务低峰期执行 ； set sql_log_bin=0后，分别在主从库上手动执行DDL（此操作对于某些DDL操作会造成数据不一致，请务必严格测试） 参考\r#\r高可用数据库主从复制延时的解决方案 《26 | 备库为什么会延迟好几个小时？》 未 "},{"id":24,"href":"/www6vMiddleware/docs/message/Kafka/kafkaController/","title":"Kafka Controller-控制器","section":"Kafka","content":"\n选举控制器的规则:\r#\r第一个成功创建 /controller 节点的 Broker 会被指定为控制器。\n作用\r#\r主题管理(创建、删除、增加分区)\n分区重分配\nkafka-reassign-partitions\nPreferred 领导者选举\nPreferred 领导者选举主要是 Kafka 为了避免部分 Broker 负载过重而提供的一种换 Leader 的方案。\n集群成员管理(新增 Broker、Broker 主动关闭、Broker 宕机)\n包括自动检测新增 Broker、Broker 主动关闭及被动宕机。\n这种自动检测是依赖于前面提到的 Watch 功能和 ZooKeeper 临时节点组合实现的。\n数据服务\n控制器上保存了最全的集群 元数据信息，其他所有 Broker 会定期接收控制器发来的元数据更新请求，从而更新其内存 中的缓存数据。\n参考\r#\r直击Kafka的心脏——控制器 \u0026laquo;26 | 你一定不能错过的Kafka控制器\u0026raquo; 胡夕\n"},{"id":25,"href":"/www6vMiddleware/docs/message/Kafka/kafkaReplica/","title":"Kafka Replication-副本机制","section":"Kafka","content":"\nPartition\r#\r首领 leader ， 首领副本 跟随者 follower， 跟随者副本 首选首领 Kafka的副本机制\r#\rAR = ISR + OSR。\nISR 不只是追随者副本集合，它必然包括 Leader 副本。\nISR中副本有主从之分，但是读写都是主副本， 从副本只负责拉取主副本的数据。 好处（一致性方面）\n方便实现**“Read-your-writes”** 方便实现单调读（Monotonic Reads） Kafka 判断 Follower 是否与 Leader 同步的标准,不是看\u0026quot;相差的消息数\u0026quot;，而是看\u0026quot;落后的时间\u0026quot;。\n落后的时间就是 Broker 端参数 replica.lag.time.max.ms 参数值。\n这个参数的含义是Follower 副本能够落后 Leader 副本的最长时间间隔，当前默认值是 10 秒。\nUnclean 领导者选举（Unclean Leader Election）\nKafka 可靠性总结 self\nQ\u0026amp;A\r#\r失效副本是指什么？有那些应对措施？\n怎么样判定一个分区是否有副本是处于同步失效状态的呢？从Kafka 0.9.x版本开始通过唯一的一个参数replica.lag.time.max.ms（默认大小为10,000）来控制，当ISR中的一个follower副本滞后leader副本的时间超过参数replica.lag.time.max.ms指定的值时即判定为副本失效，需要将此follower副本剔出除ISR之外。\nKafka解析之失效副本 优先副本是什么？它有什么特殊的作用？ 多副本下，各个副本中的HW和LEO的演变过程 为什么Kafka不支持读写分离？ 参考：\r#\rKafka核心技术与实战 - 23丨Kafka副本机制详解 胡夕 "},{"id":26,"href":"/www6vMiddleware/docs/message/Kafka/kafkaElection/","title":"Kafka 中的选主","section":"Kafka","content":"\nKafka中的选主[1]\r#\r/ 组件 详细 kafka Controller leader 依赖zk选主, kafka只有一个Controller Partition leader[2] leader在ISR中 Consumer leader的选举 消费组内的消费者选举出一个消费组的leader zookeeper zk自身的选主 Zab协议(原子广播+奔溃恢复) 其他系统依赖zk选主 使用zk的临时节点， session结束， 临时节点消失 Q\u0026amp;A\r#\r~~Kafka中有那些地方需要选举？~~这些地方的选举策略又有哪些？ 参考\r#\rKafka科普系列 | 原来Kafka中的选举有这么多？ 朱小厮\nKafka科普系列 | 原来Kafka中的选举有这么多\n你想知道的所有关于Kafka Leader选举流程和选举策略都在这(内含12张高清大图,建议收藏) 石臻臻 *** 未\n"},{"id":27,"href":"/www6vMiddleware/docs/message/Kafka/kafkaQ-A/","title":"Kafka  Q\u0026A","section":"Kafka","content":"\n基础\r#\rKafka的用途有哪些？使用场景如何？\nKafka中的ISR、AR又代表什么？ISR的伸缩又指什么\nKafka中的HW、LEO、LSO、LW等分别代表什么？\ntopic\r#\r当你使用kafka-topics.sh创建（删除）了一个topic之后，Kafka背后会执行什么逻辑？\ntopic的分区数可不可以增加？如果可以怎么增加？如果不可以，那又是为什么？\n创建topic时如何选择合适的分区数？\nKafka目前有那些内部topic，它们都有什么特征？各自的作用又是什么？\nKafka有哪几处地方有分区分配的概念？简述大致的过程及原理\nProducer\r#\rKafka中的分区器、序列化器、拦截器是否了解？它们之间的处理顺序是什么？ Kafka生产者客户端中使用了几个线程来处理？分别是什么？ 特性\r#\r聊一聊Kafka的延时操作的原理\nKafka科普系列 | 轻松理解Kafka中的延时操作\n这里就涉及到了Kafka延迟操作的概念。Kafka在处理拉取请求时，会先读取一次日志文件，如果收集不到足够多（fetchMinBytes，由参数fetch.min.bytes配置，默认值为1）的消息，那么就会创建一个延时拉取操作（DelayedFetch）以等待拉取到足够数量的消息。当延时拉取操作执行时，会再读取一次日志文件，然后将拉取结果返回给follower副本。\n延迟操作不只是拉取消息时的特有操作，在Kafka中有多种延时操作，比如延时数据删除、延时生产等。\nKafka中的延迟队列怎么实现（这题被问的比事务那题还要多！！！听说你会Kafka，那你说说延迟队列怎么实现？）\nKafka中是怎么体现消息顺序性的？\nKafka的那些设计让它有如此高的性能？\n补齐\r#\rKafka中怎么实现死信队列和重试队列？\nKafka中怎么做消息审计？\nKafka中怎么做消息轨迹？\n监控\r#\rKafka中有那些配置参数比较有意思？聊一聊你的看法\nKafka有哪些指标需要着重关注？\n其他\r#\r在使用Kafka的过程中遇到过什么困难？怎么解决的？\n还用过什么同质类的其它产品，与Kafka相比有什么优缺点？\nKafka有什么优缺点？\nKafka总结\n"},{"id":28,"href":"/www6vMiddleware/docs/message/Kafka/kafkaTransaction/","title":"Kafka 幂等性和事务","section":"Kafka","content":"\nKafka 幂等性\r#\r为了实现生产者的幂等性， 引入了producer id（PID）和 序列号（sequence number）\nPID: producer 初始化的时候分配\n序列号： producer每发送一条消息，就会将\u0026lt;PID, 分区\u0026gt;对应的序列号的值+1.\n局限性： Kafka 幂等性只能保证单个producer 回话（session）中单分区的幂等\nKafka 事务\r#\rKafka 幂等性不能跨多个分区运作，而事务可以保证对多个分区写入操作的原子性。 事务性实现的关键\r#\r事务要求producer 开启幂等特性 enable.idempotence = true transactionalId：\n一个Producer 在 Fail 恢复后能主动 abort 上次未完成的事务（接上之前未完成的事务），然后重新开始一个事务，这种情况应该怎么办？\n之前幂等性引入的 PID 是无法解决这个问题的，因为每次 Producer 在重启时，PID 都会更新为一个新值：\nKafka 在 Producer 端引入了一个 transactionalId 来解决这个问题，这个 txn.id 是由应用来配置的； 架构和组件\r#\rtransactionalId和PID一一对应，transactionalId用户显示设置，PID由Kafka内部分配； 跨producer会话的消息幂等发送: 新的producer启动后，具有相同transactionalId的旧producer会立即失效； 跨producer会话的事务恢复: producer宕机后，新的producer可以保证未完成的旧事务要么commit，要么Abort。 TransactionCoordinator(coordinate 协调者) 事务日志 语义\r#\rKafka 的事务机制，更多的情况下被用来配合Kafka的幂等机制来实现 Kafka 的 Exactly Once 语义。 Kafka 的 Exactly Once 机制，是为了解决在**\u0026ldquo;consume - transform - produce\u0026rdquo;（流计算）**这样的计算过程中数据不重不丢，而不是我们通常理解的使用消息队列进行消息生产消费过程中的 Exactly Once。 ”consume - transform - produce“模式 总结\r#\r幂等性、事务都是0.11.0.0之后引入的特性, 以此来实现EOS（Exactly-Once semantics 精确一次性语义）\nQ\u0026amp;A\r#\rKafka中的幂等是怎么实现的 Kafka中的事务是怎么实现的（这题我去面试6家被问4次）\nKafka 幂等性和事务 参考:\r#\r消息队列高手课 - 25 | RocketMQ与Kafka中如何实现事务？ 李玥 Kafka Exactly-Once 之事务性实现 Matt\u0026rsquo;s Blog-柳年思水 \u0026laquo;深入理解Kafka：核心设计与实践原理\u0026raquo; 7.4节 "},{"id":29,"href":"/www6vMiddleware/docs/serviceGovernance/ConfigDiscovery/soaDiscovery/","title":"服务发现","section":"Config \u0026 Discovery","content":"\n机制\r#\rOverview\r#\r服务注册和发现\n模式\r#\rClient-side Discovery Server-side Discovery patterns 实现\r#\r需求 [1]\r#\rRPC 框架依赖的注册中心的服务数据的一致性其实并不需要满足 CP，只要满足 AP 即可。\nFramework\r#\retcd - CP nacos 基于raft协议 zk - CP eureka - AP 参考\r#\r《08 | 服务发现：到底是要CP还是AP？》 "},{"id":30,"href":"/www6vMiddleware/docs/serviceGovernance/security/soaAuth/","title":"服务治理-鉴权","section":"安全","content":"\n备选方案 [1]\r#\r分布式 Session OAuth2.0 JWT CAS OAuth2 和 JWT的关系[gpt4]\r#\rOAuth2和JWT都是用于实现网络应用中的授权和身份验证的技术。但是，它们在实现方式和使用场景上有所不同。\nOAuth2是一个授权框架，它允许第三方应用在用户的许可下访问其私有资源。例如，一个应用可以使用OAuth2获取用户的Facebook或Google账户信息，而无需用户提供他们的用户名和密码。\nJWT（JSON Web Token）则是一种开放标准（RFC 7519），它定义了一种紧凑且自包含的方式，用于在各方之间安全地传输信息作为JSON对象。这些信息可以被验证和信任，因为它们是数字签名的。\nOAuth2和JWT可以一起使用。例如，当一个应用使用OAuth2获取用户的授权时，它可能会接收到一个包含JWT的访问令牌。应用可以解码这个JWT，以获取关于用户的信息，如他们的用户名或电子邮件地址。同时，因为JWT是签名的，应用可以信任这些信息的准确性。\n总的来说，OAuth2和JWT都是实现网络应用授权和身份验证的重要工具，但它们在实现细节和使用方式上有所不同。\n参考\r#\r微服务之用户鉴权中心 {% post_link \u0026lsquo;securityOAuth2\u0026rsquo; %} self "},{"id":31,"href":"/www6vMiddleware/docs/serviceGovernance/Springcloud/springTransactionInvalid/","title":"Spring  Transaction  失效","section":"Spring Cloud","content":"\nSpring事务失效问题\r#\rspring事务失效 [1]\r#\r- 场景：普通方法调用事务方法时，事务会失效 - 解决：要在普通方法(一般是最外层)上加上@Transactional 代理不生效 [2]\r#\r非public修饰的方法 在AbstractFallbackTransactionAttributeSource类的computeTransactionAttribute方法中有个判断，如果目标方法不是public，则TransactionAttribute返回null，即不支持事务。\n被final、static关键字修饰的类或方法 spring事务底层使用了aop，也就是通过jdk动态代理或者cglib，帮我们生成了代理类，在代理类中实现的事务功能。但如果某个方法用final修饰了，那么在它的代理类中，就无法重写该方法，而添加事务功能。\n类方法内部调用 updateStatus方法拥有事务的能力是因为spring aop生成代理了对象，但是这种方法直接调用了this对象的方法，所以updateStatus方法不会生成事务\n解决方案 新加一个Service方法 在该Service类中注入自己 通过AopContent类 当前类没有被Spring管理\n多线程调用 spring的事务是通过数据库连接来实现的。当前线程中保存了一个map，key是数据源，value是数据库连接。 同一个事务，其实是指同一个数据库连接，只有拥有同一个数据库连接才能同时提交和回滚。如果在不同的线程，拿到的数据库连接肯定是不一样的，所以是不同的事务。\n(存储引擎)表不支持事务\n未开启事务 springboot通过DataSourceTransactionManagerAutoConfiguration类，已经默默的帮你开启了事务。 使用的还是传统的spring项目，则需要在applicationContext.xml文件中，手动配置事务相关参数。如果忘了配置，事务肯定是不会生效的。\n将注解标注在接口方法上\n错误使用@Transactional [2]\r#\r错误的传播机制 目前只有这三种传播特性才会创建新事务：REQUIRED，REQUIRES_NEW，NESTED。\n异常被内部catch 如果想要spring事务能够正常回滚，必须抛出它能够处理的异常。如果没有抛异常，则spring认为程序是正常的。\nrollbackFor属性设置错误\n@Transactional(rollbackFor = BusinessException.class) public void add(UserModel userModel) throws Exception { saveData(userModel); updateData(userModel); } 嵌套事务 可以将内部嵌套事务放在try/catch中，并且不继续往上抛异常。这样就能保证，如果内部嵌套事务中出现异常，只回滚内部事务，而不影响外部事务。\n手动抛了别的异常\n参考\r#\rSpring 踩坑之@Transactional 神奇失效 小鱼儿 spring事务（注解 @Transactional ）失效的12种场景 spring中12种@Transactional的失效场景(小结) Spring @Async/@Transactional 失效的原因及解决方案 未 "},{"id":32,"href":"/www6vMiddleware/docs/serviceGovernance/loadBalance/loadBalance/","title":"负载均衡-算法","section":"负载均衡","content":"\n负载均衡算法\r#\rLVS[1][2]\r#\r组件 类型 负载均衡算法 场景 LVS 静态 RR：roundrobin [常用] 轮询机制 WRR：Weighted RR [常用] 加权轮询，权重越大承担负载越大 SH：Source Hashing 源地址哈希 实现session sticky缺点：调度粒度大，对负载均衡效果差； DH：Destination Hashing 目标地址哈希 动态 LC：least connections 适用于长连接应用\nOverhead=activeconns*256+inactiveconns WLC：Weighted LC [常用] 默认调度方法,较常用（加上了权重）\nOverhead=(activeconns*256+inactiveconns)/weight SED：Shortest Expection Delay Overhead=(activeconns+1)*256/weight NQ：Never Queue， 第一轮均匀分配，后续SED****SED****算法改进 LBLC：Locality-Based LC 动态的 ****DH****连接算法 LBLCR：LBLC with Replication 带复制功能的LBLC Nginx [3]\r#\r组件 类型 负载均衡算法 场景 Nginx 静态 轮询 每个请求按时间顺序逐一分配到不同的后端服务器，如果后端服务器 down 掉，能自动剔除 加权轮询 指定轮询几率，weight 和访问比率成正比，用于后端服务器性能不均的情况 IP Hash 每个请求按访问 ip 的 hash 结果分配，这样每个访客固定访问一个后端服务器，可以解决 session 的问题 动态 Fair （第三方） 按后端服务器的响应时间来分配请求，响应时间短的优先分配 url_hash（第三方） 按访问 url 的 hash 结果来分配请求，使每个 url 定向到同一个后端服务器，后端服务器为缓存时比较有效 Least Connections HAproxy\r#\r组件 类型 负载均衡算法 场景 HAproxy 静态 轮询 加权轮询 IP Hash 动态 Least Connections Source LVS工作模式[11-16]\r#\rDR TUN模式 NAT模式 参考\r#\rLVS负载均衡集群服务搭建详解 LVS调度算法总结 LVS、Nginx 及 HAProxy 的区别 LVS集群的负载调度 *** 未 LVS工作模式\r#\rLVS三种模式的区别及负载均衡算法 LVS 介绍以及配置应用 *** 深入浅出 LVS 负载均衡（一）NAT、FULLNAT 模型原理 未 深入浅出 LVS 负载均衡（二）DR、TUN 模型原理 未 深入浅出 LVS 负载均衡（三）实操 NAT、TUNNEL 模型 未 深入浅出 LVS 负载均衡（四）实操 DR 模型、Keepalived DR 模型的高可用 未 "},{"id":33,"href":"/www6vMiddleware/docs/serviceGovernance/faultTolerant/throttle/ratelimitSentinel/","title":"流量治理-Sentinel","section":"限流","content":"\nSentinel\r#\r限流 API [4]\r#\r定义资源 资源：可以是任何东西，一个服务，服务里的方法，甚至是一段代码。 try (Entry entry = SphU.entry(\u0026#34;HelloWorld\u0026#34;)) { // Your business logic here. System.out.println(\u0026#34;hello world\u0026#34;); } catch (BlockException e) { // Handle rejected request. e.printStackTrace(); } // try-with-resources auto exit @SentinelResource(\u0026#34;HelloWorld\u0026#34;) public void helloWorld() { // 资源中的逻辑 System.out.println(\u0026#34;hello world\u0026#34;); } 定义规则 规则：Sentinel 支持以下几种规则： 流量控制规则、熔断降级规则、系统保护规则、来源访问控制规则和 热点参数规则。 private void initSystemRule() { List\u0026lt;SystemRule\u0026gt; rules = new ArrayList\u0026lt;\u0026gt;(); SystemRule rule = new SystemRule(); // 规则 rule.setHighestSystemLoad(10); rules.add(rule); SystemRuleManager.loadRules(rules); } FlowRuleManager.loadRules(List\u0026lt;FlowRule\u0026gt; rules); // 流控规则 DegradeRuleManager.loadRules(List\u0026lt;DegradeRule\u0026gt; rules); // 降级规则 SystemRuleManager.loadRules(List\u0026lt;SystemRule\u0026gt; rules); // 系统规则 AuthorityRuleManager.loadRules(List\u0026lt;AuthorityRule\u0026gt; rules); // 授权规则 限流 类型 [2]\r#\r直接失败 [滑动时间窗口] Warmup 预热 [令牌桶算法] 限流排队 [漏桶算法] 分布式限流 [1]\r#\r滑动窗口 [2]\r#\r核心代码 LeapArray.java\n/* * Get bucket item at given time from the array. * * (1) Bucket is absent, then just create a new bucket and CAS update to circular array. * (2) Bucket is up-to-date, then just return the bucket. * (3) Bucket is deprecated, then reset current bucket. */ while (true) { WindowWrap\u0026lt;T\u0026gt; old = array.get(idx); if (old == null) { /// 初始化一个窗口 /* * B0 B1 B2 NULL B4 * ||_______|_______|_______|_______|_______||___ * 200 400 600 800 1000 1200 timestamp * ^ * time=888 * bucket is empty, so create new and update * * If the old bucket is absent, then we create a new bucket at {@code windowStart}, * then try to update circular array via a CAS operation. Only one thread can * succeed to update, while other threads yield its time slice. */ WindowWrap\u0026lt;T\u0026gt; window = new WindowWrap\u0026lt;T\u0026gt;(windowLengthInMs, windowStart, newEmptyBucket(timeMillis)); if (array.compareAndSet(idx, null, window)) { // Successfully updated, return the created bucket. return window; } else { // Contention failed, the thread will yield its time slice to wait for bucket available. Thread.yield(); } } else if (windowStart == old.windowStart()) { /// 返回老的窗口 /* * B0 B1 B2 B3 B4 * ||_______|_______|_______|_______|_______||___ * 200 400 600 800 1000 1200 timestamp * ^ * time=888 * startTime of Bucket 3: 800, so it\u0026#39;s up-to-date * * If current {@code windowStart} is equal to the start timestamp of old bucket, * that means the time is within the bucket, so directly return the bucket. */ return old; } else if (windowStart \u0026gt; old.windowStart()) { /// 滚动: 重置老的窗口, 增加新的窗口 /* * (old) * B0 B1 B2 NULL B4 * |_______||_______|_______|_______|_______|_______||___ * ... 1200 1400 1600 1800 2000 2200 timestamp * ^ * time=1676 * startTime of Bucket 2: 400, deprecated, should be reset * * If the start timestamp of old bucket is behind provided time, that means * the bucket is deprecated. We have to reset the bucket to current {@code windowStart}. * Note that the reset and clean-up operations are hard to be atomic, * so we need a update lock to guarantee the correctness of bucket update. * * The update lock is conditional (tiny scope) and will take effect only when * bucket is deprecated, so in most cases it won\u0026#39;t lead to performance loss. */ if (updateLock.tryLock()) { try { // Successfully get the update lock, now we reset the bucket. return resetWindowTo(old, windowStart); /// 清零重置old窗口 } finally { updateLock.unlock(); } } else { // Contention failed, the thread will yield its time slice to wait for bucket available. Thread.yield(); } } else if (windowStart \u0026lt; old.windowStart()) { /// 时钟回拨 // Should not go through here, as the provided time is already behind. return new WindowWrap\u0026lt;T\u0026gt;(windowLengthInMs, windowStart, newEmptyBucket(timeMillis)); } } } Sentinel vs. Hystrix vs. resilience4j [3]\r#\rSentinel Hystrix resilience4j 隔离策略 信号量隔离（并发线程数限流） 线程池隔离/信号量隔离 信号量隔离 熔断降级策略 基于响应时间、异常比率、异常数等 异常比率模式、超时熔断 基于异常比率、响应时间 实时统计实现 滑动窗口（LeapArray） 滑动窗口（基于 RxJava） Ring Bit Buffer 动态规则配置 支持多种配置源 支持多种数据源 有限支持 扩展性 丰富的 SPI 扩展接口 插件的形式 接口的形式 基于注解的支持 支持 支持 支持 限流 基于 QPS，支持基于调用关系的限流 有限的支持 Rate Limiter 集群流量控制 支持 不支持 不支持 流量整形 支持预热模式、匀速排队模式等多种复杂场景 不支持 简单的 Rate Limiter 模式 系统自适应保护 支持 不支持 不支持 控制台 提供开箱即用的控制台，可配置规则、查看秒级监控、机器发现等 简单的监控查看 不提供控制台，可对接其它监控系统 多语言支持 Java / C++ Java Java 开源社区状态 活跃 停止维护 较活跃 参考\r#\r集群流量控制\n【图灵学院】2022最新B站独家分布式限流算法原理与应用讲解视频短合集 V\n常用限流降级组件对比 Sentinel vs. Hystrix\nsentinel （史上最全+入门教程） ***\n流控降级最佳实践 阿里 未\n{% post_link \u0026lsquo;ratelimit\u0026rsquo; %} self\n"},{"id":34,"href":"/www6vMiddleware/docs/serviceGovernance/Gray/apiGatewayGray/","title":"API 网关-灰度发布","section":"灰度发布","content":"\n灰度发布 策略 [2]\r#\r基于权重 百分比 version \u0026hellip; 基于springcloud gateway + nacos实现灰度发布[1]\r#\rspring: application: name: gateway-reactor-gray cloud: nacos: discovery: server-addr: localhost:8848 gateway: discovery: locator: enabled: true lower-case-service-id: true routes: - id: hello-consumer uri: grayLb://hello-consumer ## 灰度负载均衡 predicates: - Path=/hello/** public class GrayLoadBalancer implements ReactorServiceInstanceLoadBalancer { ... private Response\u0026lt;ServiceInstance\u0026gt; getInstanceResponse(List\u0026lt;ServiceInstance\u0026gt; instances,HttpHeaders headers) { if (instances.isEmpty()) { return getServiceInstanceEmptyResponse(); } else { return getServiceInstanceResponseWithWeight(instances); // } } /** * 根据版本进行分发 */ private Response\u0026lt;ServiceInstance\u0026gt; getServiceInstanceResponseByVersion(List\u0026lt;ServiceInstance\u0026gt; instances, HttpHeaders headers) { String versionNo = headers.getFirst(\u0026#34;version\u0026#34;); // System.out.println(versionNo); Map\u0026lt;String,String\u0026gt; versionMap = new HashMap\u0026lt;\u0026gt;(); versionMap.put(\u0026#34;version\u0026#34;,versionNo); ... } /** * 根据在nacos中配置的权重值，进行分发 */ private Response\u0026lt;ServiceInstance\u0026gt; getServiceInstanceResponseWithWeight(List\u0026lt;ServiceInstance\u0026gt; instances) { Map\u0026lt;ServiceInstance,Integer\u0026gt; weightMap = new HashMap\u0026lt;\u0026gt;(); for (ServiceInstance instance : instances) { Map\u0026lt;String,String\u0026gt; metadata = instance.getMetadata(); if(metadata.containsKey(\u0026#34;weight\u0026#34;)){ // weightMap.put(instance,Integer.valueOf(metadata.get(\u0026#34;weight\u0026#34;))); } } ... } public class GrayReactiveLoadBalancerClientFilter implements GlobalFilter, Ordered { ... @Override public Mono\u0026lt;Void\u0026gt; filter(ServerWebExchange exchange, GatewayFilterChain chain) { URI url = (URI)exchange.getAttribute(ServerWebExchangeUtils.GATEWAY_REQUEST_URL_ATTR); String schemePrefix = (String)exchange.getAttribute(ServerWebExchangeUtils.GATEWAY_SCHEME_PREFIX_ATTR); if (url != null \u0026amp;\u0026amp; (\u0026#34;grayLb\u0026#34;.equals(url.getScheme()) || \u0026#34;grayLb\u0026#34;.equals(schemePrefix))) { // ServerWebExchangeUtils.addOriginalRequestUrl(exchange, url); ... return this.choose(exchange).doOnNext((response) -\u0026gt; { // ... }).then(chain.filter(exchange)); } else { return chain.filter(exchange); } } private Mono\u0026lt;Response\u0026lt;ServiceInstance\u0026gt;\u0026gt; choose(ServerWebExchange exchange) { // URI uri = (URI)exchange.getAttribute(ServerWebExchangeUtils.GATEWAY_REQUEST_URL_ATTR); GrayLoadBalancer loadBalancer = new GrayLoadBalancer(clientFactory.getLazyProvider(uri.getHost(), ServiceInstanceListSupplier.class), uri.getHost()); if (loadBalancer == null) { throw new NotFoundException(\u0026#34;No loadbalancer available for \u0026#34; + uri.getHost()); } else { return loadBalancer.choose(this.createRequest(exchange)); // } } } 参考\r#\r基于springcloud gateway + nacos实现灰度发布（reactive版） 相关的代码 Go to Page 灰度发布 self "},{"id":35,"href":"/www6vMiddleware/docs/serviceGovernance/API-Gateway/apiGatawaySpringGateway/","title":"API 网关-SpringCloud Gateway","section":"API Gateway","content":"\nFeatures [0]\r#\rBuilt on Spring Framework 5, Project Reactor and Spring Boot 2.0 Able to match routes on any request attribute. Predicates and filters are specific to routes. Circuit Breaker integration. Spring Cloud DiscoveryClient integration Easy to write Predicates and Filters Request Rate Limiting Path Rewriting 核心概念 [1][2]\r#\r路由（Route）\nid：路由标识，要求唯一，名称任意（默认值 uuid，一般不用，需要自定义） uri：请求最终被转发到的目标地址 order： 路由优先级，数字越小，优先级越高 predicates：断言数组，即判断条件，如果返回值是boolean，则转发请求到 uri 属性指定的服务中 filters：过滤器数组，在请求传递过程中，对请求做一些修改 谓词、断言（Predicate） 允许开发人员匹配 HTTP 请求中的内容，比如请求头或请求参数，最后根据匹配结果返回一个布尔值。参照 Java8 的新特性Predicate.\n过滤器（Filter） 可以在返回请求之前或之后修改请求和响应的内容。\n路由（Route）[1][2]\r#\r服务发现-集成nacos服务注册中心 [2]\r#\r服务路由配置 spring: cloud: gateway: routes: - id: gateway-provider_1 ## 使用了lb形式，从注册中心负载均衡的获取uri uri: lb://gateway-provider ## 配置断言 predicates: - Path=/gateway/provider/** filters: - AddResponseHeader=X-Response-Foo, Bar 自动路由配置 # enabled：默认为false，设置为true表明spring cloud gateway开启服务发现和路由的功能，网关自动根据注册中心的服务名为每个服务创建一个router，将以服务名开头的请求路径转发到对应的服务 spring.cloud.gateway.discovery.locator.enabled = true # lowerCaseServiceId：启动 locator.enabled=true 自动路由时，路由的路径默认会使用大写ID，若想要使用小写ID，可将lowerCaseServiceId设置为true spring.cloud.gateway.discovery.locator.lower-case-service-id = true 动态路由-整合 Apollo [2]\r#\r/** * Apollo路由更改监听刷新 */ @Configuration public class GatewayPropertRefresher implements ApplicationContextAware, ApplicationEventPublisherAware { ... /** * 监听路由修改 */ @ApolloConfigChangeListener(interestedKeyPrefixes = \u0026#34;spring.cloud.gateway.\u0026#34;) public void onChange(ConfigChangeEvent changeEvent) { refreshGatewayProperties(changeEvent); } /** * 刷新路由信息 */ private void refreshGatewayProperties(ConfigChangeEvent changeEvent) { logger.info(\u0026#34;gateway网关配置 刷新开始！\u0026#34;); preDestroyGatewayProperties(changeEvent); //更新配置 this.applicationContext.publishEvent(new EnvironmentChangeEvent(changeEvent.changedKeys())); //更新路由 refreshGatewayRouteDefinition(); logger.info(\u0026#34;gateway网关配置 刷新完成！\u0026#34;); } ... } 动态路由-整合nacos [3]\r#\r@Component @Slf4j public class NacosDynamicRouteService implements ApplicationEventPublisherAware { private String dataId = \u0026#34;gateway-router\u0026#34;; private String group = \u0026#34;DEFAULT_GROUP\u0026#34;; @Value(\u0026#34;${spring.cloud.nacos.config.server-addr}\u0026#34;) private String serverAddr; @Autowired private RouteDefinitionWriter routeDefinitionWriter; private ApplicationEventPublisher applicationEventPublisher; private static final List\u0026lt;String\u0026gt; ROUTE_LIST = new ArrayList\u0026lt;\u0026gt;(); @PostConstruct public void dynamicRouteByNacosListener() { try { ConfigService configService = NacosFactory.createConfigService(serverAddr); configService.getConfig(dataId, group, 5000); configService.addListener(dataId, group, new Listener() { @Override public void receiveConfigInfo(String configInfo) { clearRoute(); try { if (StringUtil.isNullOrEmpty(configInfo)) {//配置被删除 return; } List\u0026lt;RouteDefinition\u0026gt; gatewayRouteDefinitions = JSONObject.parseArray(configInfo, RouteDefinition.class); for (RouteDefinition routeDefinition : gatewayRouteDefinitions) { addRoute(routeDefinition); } publish(); } catch (Exception e) { log.error(\u0026#34;receiveConfigInfo error\u0026#34; + e); } } @Override public Executor getExecutor() { return null; } }); } catch (NacosException e) { log.error(\u0026#34;dynamicRouteByNacosListener error\u0026#34; + e); } } private void clearRoute() { for (String id : ROUTE_LIST) { this.routeDefinitionWriter.delete(Mono.just(id)).subscribe(); } ROUTE_LIST.clear(); } private void addRoute(RouteDefinition definition) { try { routeDefinitionWriter.save(Mono.just(definition)).subscribe(); ROUTE_LIST.add(definition.getId()); } catch (Exception e) { log.error(\u0026#34;addRoute error\u0026#34; + e); } } 谓词、断言（Predicate）[1][2]\r#\r过滤器（Filter）[1][2]\r#\r生命周期\nPRE POST 作用范围\nGatewayFilter 局部过滤器 默认预定义 限流 GlobalFilter 全局过滤器 自定义全局过滤器 统一鉴权过滤器 稳定性\r#\r熔断降级-Hystrix [3]\r#\rserver.port: 8082 spring: application: name: gateway redis: host: localhost port: 6379 password: 123456 cloud: gateway: routes: ## - id: rateLimit_route uri: http://localhost:8000 order: 0 predicates: ## - Path=/test/** filters: ## - StripPrefix=1 - name: Hystrix args: name: fallbackCmdA fallbackUri: forward:/fallbackA hystrix.command.fallbackCmdA.execution.isolation.thread.timeoutInMilliseconds: 5000 流控和降级-Sentinel [3]\r#\r高可用网关[1]\r#\rNginx负载均衡到部署的多个Gateway\n参考\r#\rspring-cloud-gateway\n2021最新(完整版)Gateway教学-第二代微服务网关组件SpringCloud-Gateway *** V\nSpring Cloud Gateway 服务网关的部署与使用详细介绍\nSpringCloud gateway （史上最全） 尼恩\n3W字吃透：微服务网关SpringCloud gateway底层原理和实操 尼恩 未\n"},{"id":36,"href":"/www6vMiddleware/docs/serviceGovernance/API-Gateway/apiGatawayApisix/","title":"API 网关-apisix","section":"API Gateway","content":"\napisix特性\r#\rCore api聚合 灰度发布 稳定性 服务熔断 故障注入 流量复制 云原生 多云，混合云 容器友好 随意扩缩容 apisix功能\r#\r动态配置，不用reload\n路由, ssl证书，上游，插件\u0026hellip; 插件化(40个)\n身份验证, 安全, 日志, 可观察性\u0026hellip; 对接Prom，zipkin， skywalking grpc代理和协议转换(rest \u0026lt;-\u0026gt; gprc) apisix只用了nginx的网络层 apisix使用场景\r#\r处理L4, L7层流量 代替nginx处理南北流量 代替envoy处理东西流量 k8s ingress controller 参考\r#\r【云原生学院 #3】基于 Apache APISIX 的全流量 API 网关 *** "},{"id":37,"href":"/www6vMiddleware/docs/serviceGovernance/API-Gateway/apiGateway/","title":"API Gateway网关","section":"API Gateway","content":"\n特性\r#\r路由 灰度发布 反向代理,负载均衡 鉴权 限流 监控 缓存 分类\r#\r入口网关 出口网关 框架\r#\r产品 技术 apisix self lua + Nginx Kong lua + Nginx Zuul Spring Cloud Netflix Gateway self Spring Cloud Traefik Golang 实现 [3]\r#\r扩展性\n责任链模式 - Zuul filter, Envoy filter 性能\n多路 I/O 复用模型 和 线程池 可用性\n线程池 服务隔离 API Gateway+BFF\r#\rAPI Gateway + BFF [3]\r#\r流量网关 + 业务网关\nBFF 聚合网关 [2]\r#\r参考\r#\r使用 API 网关构建微服务 微服务架构：BFF和网关是如何演化出来的？ 《27 | API网关：系统的门面要如何做呢？》 百亿规模API网关服务Shepherd的设计与实现 点评 未 Go to Page self "},{"id":38,"href":"/www6vMiddleware/docs/serviceGovernance/Springcloud/springCloud/","title":"SpringCloud","section":"Spring Cloud","content":"\n参考\r#\rSpringCloud 面试题 （持续更新、吐血推荐）\n"},{"id":39,"href":"/www6vMiddleware/docs/serviceGovernance/ConfigDiscovery/config/","title":"服务治理-分布式配置","section":"Config \u0026 Discovery","content":"\n需求\r#\r对实时性要求不高 对可用性要求高 产品\r#\r产品 存储 Disconf 百度 mysql Apollo 携程 mysql QConf 360 zookeeper 微博 redis 美图 etcd spring cloud config git 参考：\r#\rSpring Boot与Kubernetes云原生微服务实践 杨波 "},{"id":40,"href":"/www6vMiddleware/docs/serviceGovernance/loadBalance/nginxOptimize/","title":"Nginx优化","section":"负载均衡","content":"\nNginx 参数优化\r#\r反向代理\r#\rproxy_cache: 10M(重要) proxy_cache_path /data/nginx_cache/ levels=1:2 keys_zone=my_zone:10m inactive=300s max_size=5g; tls ssl\r#\rssl_session_cache builtin:1000 shared:SSL:10m; /// 一天内连接上的用户， 不需要再协商秘钥 ssl_session_cache builtin:1000 shared:SSL:10m; /// 1m -\u0026gt; 4000个https连接 ssl_session_timeout 10m; /// 10分钟 ssl_protocols TLSv1.2; /// 版本号 非安全请求重定向\r#\rNo redirect: 无重定向 Redirect： 301-302 -》 转到https站点 gzip\r#\rgzip on; gzip_comp_level 5; gzip_http_version 1.1; /// 注意：gzip 在1.1上有效， http2.0上是无效的 gzip_min_length 256; gzip_types application/atom+xml ... gzip_proxied any; gzip_vary on; worker\r#\rworker_connections 16384; /// 一个worker有 16384/2=8192 ‬个链接 . 两个事件， 一个读事件， 一个写事件。 越多的connections对应更多的内存消耗。 Default: worker_connections 512; 高级选项： worker connections的内存池（pools）， 更少的的内存碎片。一般是nginx自动分配的， 不用分配。 Default: connection_pool_size 256|512 Default: request_pool_size 4k; worker_processes 设置worker进程的数量 减少进程间切换\r#\r程间切换： cpu从一个进程或线程切换到另一个进程或线程。\n主动切换和被动切换 减少主动切换 被动切换：时间片耗尽。 减少被动切换： 增大进程优先级 Nice 静态优先级: -20 \u0026ndash; 19 Priority 动态优先级： 0-139 提升CPU缓存命中率\r#\r绑定worker到指定cpu L1,L2(cpu独享) L3（共享的） worker_cpu_affinity cpumask ...; worker_cpu_affinity auto [cpumask]; lua 分配的内存（暂时没有使用）\r#\rlua_shared_dict configuration_data 5M; lua_shared_dict certificate_data 16M; // 应用场景: 集群流控, 多个worker之间的内存的共享。 http的keeplive 长链接（一个tcp的链接，上面有多个http的请求）\r#\r注意: 非tcp keeplive\nkeepalive_disable; /// 没有设置 keepalive_timeout 75s; // 默认值 keepalive_requests 100; // 默认值 一个tcp请求中可发100个http请求 测试用例\r#\rURL：logsearch.sh.pre.urtc.com.cn\ncase1\r#\rinput： 1000用户并发, 短连接， 非keepalive的\nresult： 链接数 40000+\ntps 4000+\navg 百ms\ncase2\r#\rinput： 1500用户并发，短连接， 非keepalive的\nresult： 链接数 30000+，\ntps 4000+ ，\navg 200ms+\n参考\r#\rNginx全面配置 *** 未 "},{"id":41,"href":"/www6vMiddleware/docs/serviceGovernance/security/securityOAuth2/","title":"安全-OAuth2","section":"安全","content":"\n目录\r#\rOAuth 2.0 授权类型 [1][4]\r#\r授权码模式-用的多 Authorization Code 授权码 ***\n客户端模式 Client Credentials\nThe Client Credentials grant is used when applications request an access token to access their own resources, not on behalf of a user.\nxxx Refresh Token *** 动态token\n密码模式-Legacy Password Grant\n基于OAuth2 的微服务 参考架构 [3]\r#\rOverview\r#\r网关 令牌的校验和转换，将前端传递过来的 OAuth 2.0 访问令牌，通过调用 IDP 进 行校验，并转换为包含用户和权限信息的 JWT 令牌，再将 JWT 令牌向后台微服务传 递。 IDP 服务 IDP 是 Identity Provider 的简称，主要负责 OAuth 2.0 授权协议处理，OAuth 2.0 和 JWT 令牌颁发和管理，以及用户认证等功能。IDP 使用后台的 Login-Service 进行用户认 证。 选型: Spring Security OAuth or KeyCloak(RedHat) OAuth2 与微服务进行集成\r#\r第三方 Web 应用 + 授权码模式 各大开放平台是如何使用 OAuth 2.0 的 [2]\r#\r网关集成OAuth2.0 [5]\r#\rOIDC [2]\r#\r什么是 OIDC\r#\r什么是 OIDC？ EU：End User RP：Relying Party OP：OpenID Provider ID Token UserInfo Endpoint OIDC 是 OpenID Connect 的简称，OIDC=(Identity, Authentication) + OAuth 2.0。它在 OAuth2 上构建了一个身份层，是一个基于 OAuth2 协议的身份认证标准协议。OAuth2 是一个授权协议，它无法提供完善的身份认证功能，OIDC 使用 OAuth2 的授权服务器来为第三方客户端提供用户的身份认证，并把对应的身份认证信息传递给客户端.\nOAuth2 提供了Access Token来解决授权第三方客户端访问受保护资源的问题；OIDC 在这个基础上提供了ID Token 来解决第三方客户端标识用户身份认证的问题。\nOIDC 核心概念\r#\rOIDC 核心概念 主要术语 OIDC 工作流程 ID Token 认证 基于 Authorization Code 的认证请求 获取 ID Token Implicit Flow 和 Hybrid Flow UserInfo Endpoint OIDC 示例\r#\rOIDC 示例 + 请求示例： POST /auth/realms/ccm/protocol/openid-connect/token HTTP/1.1 Host: server.example.com Content-Type: application/x-www-form-urlencoded Authorization: Basic d2ViX2FwcDp3ZWJfYXBw grant_type=**authorization_code**\u0026amp;code=7138b4b3-8c2b-4016-ad98-01c4938750c6.c110ddc8-c6c1-4a95-bd9e-cd8d84b4dd70.1eabef67-6473-4ba8-b07c-14bdbae4aaed\u0026amp;redirect_uri=https%3A%2F%2Fclient.example.org%2Fcb + 响应示例： HTTP/1.1 200 OK Content-Type: application/json Cache-Control: no-store Pragma: no-cache { **\u0026#34;access_token\u0026#34;**: \u0026#34;SlAV32hkKG\u0026#34;, \u0026#34;token_type\u0026#34;: \u0026#34;Bearer\u0026#34;, \u0026#34;refresh_token\u0026#34;: \u0026#34;8xLOxBtZp8\u0026#34;, \u0026#34;expires_in\u0026#34;: 3600, **\u0026#34;id_token\u0026#34;**: \u0026#34;eyJhbGciOiJSUzI1NiIsImtpZCI6IjFlOWdkazcifQ.ewogImlzc yI6ICJodHRwOi8vc2VydmVyLmV4YW1wbGUuY29tIiwKICJzdWIiOiAiMjQ4Mjg5 NzYxMDAxIiwKICJhdWQiOiAiczZCaGRSa3F0MyIsCiAibm9uY2UiOiAibi0wUzZ fV3pBMk1qIiwKICJleHAiOiAxMzExMjgxOTcwLAogImlhdCI6IDEzMTEyODA5Nz AKfQ.ggW8hZ1EuVLuxNuuIJKX_V8a_OMXzR0EHR9R6jgdqrOOF4daGU96Sr_P6q Jp6IcmD3HP99Obi1PRs-cwh3LO-p146waJ8IhehcwL7F09JdijmBqkvPeB2T9CJ NqeGpe-gccMg4vfKjkM8FcGvnzZUN4_KSP0aAp1tOJ1zZwgjxqGByKHiOtX7Tpd QyHE5lcMiKPXfEIQILVq0pc_E2DzL7emopWoaoZTF_m0_N0YzFC6g6EJbOEoRoS K5hoDalrcvRYLSrQAZZKflyuVCyixEoV9GfNQC3_osjzw2PAithfubEEBLuVVk4 XUVrWOLrLl0nx7RkKU8NXNHq-rvKMzqg\u0026#34; } 参考\r#\r10 分钟理解什么是 OAuth 2.0 协议 *** OAuth2.0 + OIDC 技术规范及应用场景 *** \u0026laquo;12 | 架构案例：基于OAuth 2.0/JWT的微服务参考架构\u0026raquo; 杨波 *** OAuth2.0的四种模式测试 07 网关集成OAuth2.0实现统一认证鉴权 代码 "},{"id":42,"href":"/www6vMiddleware/docs/serviceGovernance/Springcloud/springboot/","title":"SpringBoot","section":"Spring Cloud","content":"\nCore\r#\rSpring Boot定义\r#\rSpring Boot is designed to get you up and running as quickly as possible, with minimal upfront configuration of Spring. Spring Boot takes an opinionated view of building production-ready applications.\nFeatures (官方)\r#\rCreate stand-alone Spring applications Embed Tomcat, Jetty or Undertow directly (no need to deploy WAR files) Provide opinionated \u0026lsquo;starter\u0026rsquo; dependencies to simplify your build configuration Automatically configure Spring and 3rd party libraries whenever possible Provide production-ready features such as metrics, health checks, and externalized configuration Absolutely no code generation and no requirement for XML configuration 特性\r#\r自动配置 Auto Configuration 为Spring及第三方库提供自动配置; 简化了项目的构建配置;\n无需生成代码或进行xml配置; 约定优于配置(Convention Over Configuration) CoC Starter Dependency\nSpringboot CLI\n内嵌的服务器 方便地创建可独立运行的Spring应用程序; 直接内嵌的Tomcat， Jetty或者Undertow;\n生产级 提供生产级特性; Actuator（Runtime）\nAuto Configuration\r#\r底层装配技术 [3]\r#\rSpring 模式注解装配\nSpring @Enable 模块装配\n// 组件 @EnableXXX @Importer @ImportXXXSelector @Conditional @ConditionalOnClass @ConditionalOnBean ... // 开启自动配置 @EnableAutoConfiguration @SpringBootApplication Spring 条件装配装配 // 实现原理 - 有条件的加载机制 @ConditionalOnClass @ConditionalOnBean @ConditionalOnMissingBean @ConditionalOnProperty ... Spring 工厂加载机制 实现类： SpringFactoriesLoader 配置资源： META-INF/spring.factories 外部化配置加载顺序\r#\r...\r命令行参数（--server.port=9000）\r...\rSystem.getProperties()\r操作系统环境变量\r... jar包外的application-{profile}.properties 或 .yml\rjar包内的application-{profile}.properties 或 .yml\rjar包外的application.properties或 .yml\rjar包内的application.properties或 .yml Starter Dependency\r#\r直接面向功能 官方Starters spring-boot-starter-* \u0026lt;parent\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-parent\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;2.0.0.RELEASE\u0026lt;/version\u0026gt; \u0026lt;/parent\u0026gt; \u0026lt;!-- 使用方 --\u0026gt; \u0026lt;!-- 统一管理依赖 --\u0026gt;\u0026lt;!-- spring cloud的依赖 --\u0026gt; \u0026lt;dependencyManagement\u0026gt;\u0026lt;/dependencyManagement\u0026gt; \u0026lt;!-- 定义方 --\u0026gt; Bill of Materials - bom BOM本质上是一个普通的POM文件 扩展自定义starter \u0026hellip; production-ready\r#\rActuator\r#\r目的： 监控并管理应用程序 访问方式： HTTP, JMX 依赖： spring-boot-starter-actuator Actuator Endpoint\r#\rhttp访问 /actuator/ 端口与路径 management.server.address= management.server.port= 内嵌的Web容器\r#\r可选容器列表\r#\rspring-boot-starter-tomcat spring-boot-starter-jetty spring-boot-starter-undertow spring-boot-starter-reactor-netty 端口\r#\rserver.port server.address 压缩\r#\rTomcat特性配置\r#\rserver.tomcat.max-connections=10000 server.tomcat.max-http-post-size server.tomcat.max-threads 参考\r#\r《玩转Spring全家桶》 67, 68, 71, 73, 75, 79 丁雪峰 V 《黑马程序员SpringBoot教程，6小时快速入门Java微服务架构Spring Boot》 V 《mksz252 - Spring Boot 2.0深度实践之核心技术篇》 第2章 走向自动装配 V *** SpringBoot面试题 (史上最全、持续更新、吐血推荐) 尼恩 未 spring + spring mvc + tomcat 面试题（史上最全） 尼恩 未 SpringBoot 基础知识 核心知识 【收藏版】 尼恩 未 "},{"id":43,"href":"/www6vMiddleware/docs/serviceGovernance/Overview/microservice/","title":"微服务 总结","section":"Overview","content":"\n目录\r#\r微服务 定义\r#\rIn short, the microservice architectural style [1] is an approach to developing a single application as a suite of small services, each running in its own process and communicating with lightweight mechanisms, often an HTTP resource API. These services are built around business capabilities and independently deployable by fully automated deployment machinery. There is a bare minimum of centralized management of these services, which may be written in different programming languages and use different data storage technologies. \u0026ndash; [Martin Fowler]\nCore\r#\rAPI网关\r#\rserviceGovernanceSummary self\n服务容错\r#\rserviceGovernanceSummary self\n服务注册和发现\r#\rserviceGovernanceSummary self\n服务间调用\r#\rMicro Service Architecture Microservice 微服务的理论模型和现实路径\n服务契约\r#\rAPI，具体接口的 API 接入技术说明。 能力，服务能力的描述。 契约，提供这些能力所约定的一些限制条件说明。 版本，支持的最新和历史的版本说明。 调用协议\r#\r同步 HTTP REST（JAX-RS） RPC（Dubbo）\n异步消息 Kafka, RabbitMQ, Notify AMQP, MQTT, STOMP\n服务部署和发布\r#\r微服务部署：蓝绿部署、滚动部署、灰度发布、金丝雀发布\n部署模式 Single Service per Host Multiple Services per Host patterns Design\r#\r服务划分和组合\r#\r微服务不是指\u0026quot;微小\u0026quot;的服务, 而是如何\u0026quot;拆分\u0026quot;服务,然后\u0026quot;组合\u0026quot;服务.\nDDD 领域驱动设计, 上下文划分（context） 康威定律 服务分层\r#\r上层: 聚合服务（适配服务， 边界服务）\r#\r比如：pc和mobile服务对商品服务返回内容的裁剪。\r聚合商品服务和目录服务的内容。 下层: 基础服务（核心领域服务， 公共服务）\r#\r比如：电商的商品服务， 目录服务， 订单服务\rDesign-微服务设计模式\r#\rOverview\r#\rSidecar [11]\r#\r分离业务逻辑与路由，流控，熔断，幂等，服务发现，鉴权等控制组件。\n适用场景： 老系统改造扩展，Sidebar 进程与服务进程部署在同一个节点； 多语言混合分布式系统扩展；\nEg. k8s pod中日志采集sidecar\nThe Scale Cube 可伸缩性\r#\rThe Scale Cube\nX-Axis: Horizontal Duplication and Cloning of services and data Y-Axis: Functional Decomposition and Segmentation - Microservices (or micro-services) Z-Axis: Service and Data Partitioning along Customer Boundaries - Shards/Pods\nX-Axis: Replicate \u0026amp;\u0026amp; Load Balance Y-Axis: Servcie Z-Axis: Data Sharding\n微服务的优势和代价\r#\rMicroservicePremium Martin Fowler.\n生产率和复杂度之间的关系。\n在不复杂的系统中， 更适合monolithic的应用。 复杂度增长时， 微服务的生产率能持续保持，在生产率方面是可伸缩的。\n原则和缺点（挑战）\r#\r微服务架构——不是免费的午餐 有关微服务架构的争论：更简单还是更复杂？\n原则 优点 缺点 挑战 分布式服务组成的系统； 去中心化 可用性高 多服务运维难度 分布式系统的复杂性（容错，延迟，分布式事务） 按照业务而不是技术来划分组织 服务独立无依赖 系统部署依赖 事务、异步、测试面临挑战 做有生命的产品而不是项目 技术栈灵活 运营开销 Smart endpoints and dumb pipes（强服务个体和轻量级通信）; 可组合的服务 独立按需扩展和伸缩 服务间通信成本 隐式接口[接口变更成本] 自动化运维（DevOps） 系统集成测试 DevOps 要求 容错 可用性高 数据一致性 性能监控; 分布式系统的复杂性 快速演化 开发简单 重复工作 系统集成测试 SOA、微服务、云原生演进\r#\r关注点 SOA 微服务 云原生 研发过程 CMM/RUP Agile Agile 交付流程 手工/自动化 DevOps\nDevSecOps GitOps[12]\nAIOps\nNoOps(Serverless) 服务通信 Web Service（WSDL，Soap） REST/私有RPC协议（Dubbo） REST/gRPC,Envoy xDS， MSI协议等开放协议 功能扩展性-filter x AOP filter\nDubbo filter chain\nWEB filter/lisnter Envoy filter 功能扩展性-微内核 x Dubbo SPI K8s CRD, Operator 服务治理 ESB 微服务/API网关（SpringCloud），去中心化, sidecar 服务网格（ istio ， Linked） 分布式 应用运行环境 物理机/虚拟机 虚拟机/容器 Kubernete（操作系统）+ Serverless（Knative） 基础设施 IDC 公有云/私有云 无边界的云（多云/混合云、 云+边+端） 总结 重 轻, 快速 开放、融合 参考\r#\rIntroduction to Microservices 英文\nIntroduction to Microservices 中文 优缺点\n微服务（Microservice）那点事 ***\nPattern: Microservice Architecture ***\n一致性 self\n微服务：分解应用以实现可部署性和可扩展性 Chris Richardson\n《Linux/Unix设计思想》随笔 ——Linux/Unix哲学概述 未\n微服务学习资料汇总 ***\n微服务架构技术栈选型手册 未\n从 SOA 到微服务，企业分布式应用架构在云原生时代如何重塑？ 阿里 易立 ***\n云原生时代，分布式系统设计必备知识图谱（内含22个知识点） 杨泽强（竹涧） ***\n使用托管服务网格实现应用在多集群中的 GitOps 全自动化渐进式发布 郝树伟 阿里云容器服务\n​\n"},{"id":44,"href":"/www6vMiddleware/docs/serviceGovernance/loadBalance/nginx/","title":"Nginx总结","section":"负载均衡","content":"\nNginx总结\r#\rNginx架构\r#\r共享内存 Slab 分页 4K， 8K， 16K Nginx反向代理\r#\r类型\r#\r带权重的round-robin算法是基础 hash负载均衡算法 ip-hash算法 -\u0026gt; real-ip hash算法 -\u0026gt; 自定义可以hash的参数（比如?userName） 问题: 如果有upstream的机器宕机， hash算法还会路由到这台机器 解决方案：使用一致性hash(consistent),hash 环\nleast-connection算法， 如果所有节点的connection都一致， 会退化成为round-robin算法。 可扩展立方体\r#\rX-axis 基于round-robin或者least-connected算法分发请求 -\u0026gt; 相对简单 Y-axis 基于URL对功能进行分发。 -\u0026gt; 相对复杂 Z-axis 将用户IP地址或者其他信息映射到某个特定的服务或者集群 -\u0026gt; 相对简单 多种协议反向代理\r#\rtcp udp 透传 http -\u0026gt; memcached , scgi, fastcgi, uwsgi, grpc, http, websocket 反向代理流程\r#\r修改发送到upstream机器的请求的nginx指令。\n节点热更新\r#\rmaster节点热更新\r#\rworker节点热更新\r#\r域名转发到其他域名[2]\r#\rreturn 指令 rewrite proxy_pass 文件下载\r#\rnginx.conf\nlocation /userlab.dat {\rcharset gbk;\r# alias /home/hp/home/frontend/indicator/userlab.dat;\rroot /home/cms/indicator;\rif ($request_filename ~* ^.*?\\.(txt)$){\radd_header Content-Disposition \u0026#39;attachment\u0026#39;;\radd_header Content-Type: \u0026#39;APPLICATION/OCTET-STREAM\u0026#39;;}\rautoindex on;\rautoindex_exact_size off;\rautoindex_localtime on;\r} 参考\r#\r深入Nginx 思维导图\nnginx配置域名转发到其他域名的几种方法\n"},{"id":45,"href":"/www6vMiddleware/docs/serviceGovernance/faultTolerant/faultTolerant/soaTolerateFramework/","title":"容错框架","section":"容错","content":"\nHystrix实现和容错模式\r#\rHystrix实现和容错模式 熔断【熔断器模式】 三个状态 开 闭 半开 模块 熔断请求判断机制算法 维护10个bucket,每秒一个bucket,每个blucket记录成功,失败,超时,拒绝的状态。 超时【超时与重试模式】 失败（异常） 成功 拒绝 线程池拒绝【1】 信号量拒绝【2】 默认错误超过50%且10秒内超过20个请求进行中断拦截 熔断恢复 每隔5s允许部分请求通过，若请求都是健康的（RT\u0026lt;250ms）则对请求健康恢复 熔断报警和Metric上报 流控【限流模式】 控制速率 控制并发 隔离【舱壁隔离模式】 Hystrix实现 线程池隔离 【1】 信号量隔离【2】 回退【回退模式】 快速失败（Fail Fast ） 无声失败（Fail Silent ） 返回默认值（Fallback Static ） Resilience4j [1]\r#\r断路器（Circuit Breaker） 重试（Retry） 限时器（Time Limiter） 限流器（Rate Limiter） 隔板（BulkHead） 参考\r#\rHystrix\r#\r微服务熔断与隔离 楚岩 Hystrix技术解析 王新栋 \u0026laquo;亿级流量网站架构核心技术\u0026raquo; 5.8节 张开涛 Hystrix 使用与分析 zhangyijun Resilience4j\r#\rResilience4j 比 Hystrix 好在哪里？ "},{"id":46,"href":"/www6vMiddleware/docs/serviceGovernance/faultTolerant/throttle/ratelimit/","title":"限流-总结","section":"限流","content":"\n限流总结\r#\r限流算法\r#\r流控算法 原理 实现 实现复杂度 优势 缺点 计数器法 简单 缺点 临界问题,不能应对突发请求 滑动窗口 滑动时间窗口划成了多格，粒度细; 解决了计数器法的缺点; 基于时间窗口[5] 简单 令牌桶算法 Guava RateLimiter [7] 复杂 能够处理突发请求; 允许某些流量的突发，被业界采用地较多 漏桶算法 漏桶算法[6] 代码[0] 简单 队列算法 FIFO队列; 权重队列; Linux tc 队列长度很关键 分布式限流\r#\r分布式计数器\n实现 Redis(服务端)+Lua(客户端) 限流网关\n缺陷 服务之间的调用不一定走网关 参考\r#\r漏桶算法实现 限流系统如何发现系统的热点 中间件小哥 *** 接口限流算法总结 夜有所思，日有所梦 聊聊高并发系统之限流特技 张开涛 服务化体系之－限流 江南白衣 失效 《应用 6：断尾求生 —— 简单限流 》 Redis 深度历险：核心原理与应用实践 《应用 7：一毛不拔 —— 漏斗限流》 Redis 深度历险：核心原理与应用实践 有代码实现 Guava RateLimiter源码解析 林舍 manerfan 淘宝应用柔性架构的探索 自适应负载调节 "},{"id":47,"href":"/www6vMiddleware/docs/serviceGovernance/faultTolerant/faultTolerant/soaTimeout/","title":"超时和重试 总结","section":"容错","content":"\n关键词： 超时, 降级, 重试\n超时 和 重试\r#\r超时和延迟的原因: 服务端获得请求了，但超时了; 服务端没获得请求，请求失败了， 超时了; 重试方式: 指数级退避 Exponential Blackoff[3][4] 超时类型\r#\r类型 客户端调用超时 服务器端调用超时 提供端/消费端与注册中心之间超时 超时后策略\r#\r超时后策略 超时+快速失败 超时后不重试 超时+降级failback 返回托底（返回历史数据/静态数据/缓存数据）数据，等待页或者错误页 超时+熔断 超时后重试，重试不行后熔断服务 降级\r#\r降级 非核心服务在超时后可以自动降级 超时时间和超时重试次数 最佳实践\r#\r最佳实践 不设置超时 慢请求累积导致连锁反应，甚至造成应用雪崩 推荐值 稍大于压测或者线上监控看到的TP99的响应时间 超时时间太长-不恰当设置 导致本应成功的调用却失败了。超时的时候服务资源没有释放 超时时间太短- 不恰当设置 服务调用成功率降低 最重要：网络连接/读/写的超时 用户能忍受的最长超时时间 - 用户体验 最坏情况下的响应时间=重试次数*单次超时时间 依赖 service重启时大量超时的问题 服务预热功能。延迟发布 客户端的超时时间\u0026lt;服务端的超时 可以在服务端实施限流/降级 多级依赖关系 如A调用B，B调用C 超时设置应该是A\u0026gt;B\u0026gt;C,否则可能会一直重试，引起DDos攻击效果 重试\r#\r重试 客户端 心跳超时 关闭链路，然后由客户端发起重新连接的操作，保证链路能恢复到正常的状态 有负载均衡的中间件，要考虑配置心跳/存活检查 客户端调用超时 重试策略,保证服务调用成功 - failover 摘掉不存活节点 尝试其他分组服务 尝试其他机房服务 服务端 读服务天然适合重试 写服务大多不能重试 幂等 Zookeeper客户端会话超时 - 服务注册反注册 Zookeeper服务端，将该会话对应的Node删除，删除事件通知到所有监听该Node的消费者 重试次数太多 导致多倍请求流量，模拟了DDos攻击 参考\r#\r《亿级流量网站架构核心技术》 张开涛 Hedwig文档 网络重试中的 指数退避抖动 算法 Exponential Backoff And Jitter AWS 中的错误重试和指数退避 "},{"id":48,"href":"/www6vMiddleware/docs/serviceGovernance/threadModel/jsfThreadModel/","title":"京东服务框架JSF服务提供者线程模型","section":"线程模型","content":"\n京东服务框架JSF\r#\rJSF是京东基础架构组的服务化中间件产品，全名是Jingdong Service Framework（中文名：杰夫）。 JSF整体是依据netty来构建的，本文从代码层面简单介绍一下JSF服务端的线程模型。\n1.JSF的服务端线程模型整体上是 boss线程池 + worker线程池 + 业务线程池。boss线程池和worker线程池称为Reactor线程池。\r#\r三类线程池各自的参数详见下图1。\nworker线程池和业务线程池之间的关系详见下图2，在图中可以看到业务线程和worker线程是解耦的，请求放入业务线程后，IO线程即worker线程就返回了，业务线程和I/O线程隔离。 在没有解耦IO线程和业务ChannelHandler的情况时，如果在业务ChannelHandler中进行数据库等同步I/O操作，很有可能会导致IO线程中的pipeline链路被阻塞。\n2. 图3是boss线程池， 线程数为Max(4,cpu/2)，用户不可以配置\r#\r3. 图4是worker线程池， 线程数为Max(8,cpu+1)，用户可以配置\r#\r4.图5和图6是业务线程池的构建，cached线程池大小是20-200，默认queue的大小是0。 任务来了直接分配线程，直到线程池满，得不到执行线程抛异常。\r#\r图7中一个服务端口对应一个业务线程池。\n5. 在ChannelPipeline中ServerHandler根据服务端的配置获取对应的业务线程池，然后在ServerHandler的handlerRequest中提交业务任务，默认的任务是JSFTask。\r#\r具体实现如图8,9,10.\n可以看到，JSF服务提供者线程模型整体还是按照boss+worker+biz这种netty官方推荐的方式构建的。\n参考：\r#\r京东 jsf 源代码和文档 Netty案例集锦之多线程篇（续） 李林锋 "},{"id":49,"href":"/www6vMiddleware/docs/serviceGovernance/faultTolerant/faultTolerant/soaTolerate/","title":"分布式服务框架 容错机制","section":"容错","content":"\n关键词： 容错, 降级, 隔离, 超时, 重试, 高可用, 监控, 开关\nOverview\r#\r超时重试机制[self 1][self 2] 限流 熔断机制 隔离 降级（本地缓存） 流量调度、负载均衡 微服务熔断与隔离 降级\r#\r降级策略 场景 实现 降低一致性约束 [1] 关闭非核心业务 人工开关 （非核心服务）, 强制降级,简化功能 开关存放位置:配置文件,数据库, Redis/Zk 关闭非核心业务 自动开关(非核心服务), 超时降级 1. 统计失败次数降级-不稳定的api\n2. 限流降级-大促秒杀\n3. 实现-熔断器 超时和重试 Retry\r#\r超时和重试 网络连接/读/写的超时时间（重要） 服务 读服务 - 可重试 写服务 - 幂等可重试 服务 客户端超时与重试 服务端超时 - 业务超时 任务型 服务调用型 超时后策略 failover 其它分组 其它机房 failcache 托底默认数据 等待页/错误页 降级 超时时间 太短 调用成功率降低 太长 后续正常请求挤压 经验值 稍微大于tp99的响应时间 集群容错\r#\r集群容错 Fail over（重试其他节点） 超时异常 Fail fast（快速失败） Fail cache（重试故障节点）（hedwig） 网路异常 Fail back（回退） 隔离 BulkHead\r#\r隔离 线程池隔离(hystirx) vm隔离（资源隔离） 物理机隔离 集群隔离 分组隔离 机房隔离 框架\r#\r框架 淘宝Dubbo 一号店Hedwig 京东JSF 点评pegion 唯品会OSP 状态监测\r#\r状态监测 服务注册中心状态监测（hedwig） 服务提供者和消费者之间的链路有效性检测（pegion） 服务健康检查（打分） 反推回消费者的路由表 流量控制（算法） Rate Limiter\r#\r流量控制（算法）　限流算法 令牌桶（控制入口） 漏桶（控制出口） 计数器(hedwig) 接口的总请求数（hedwig客户端） 接口的时间窗口请求数（hedwig服务端） 平滑限流,整形（netty） 整体流控 静态流控(整体qps固定) 预先分配 动态配额分配置（推） 动态配额申请制（拉） 动态流控 分级流控-拒绝流量 连接控制 并发控制（线程的并发执行数） 参考\r#\rself\r#\r{% post_link \u0026lsquo;soaTolerate\u0026rsquo; %} self {% post_link \u0026lsquo;soaTimeout\u0026rsquo; %} self "},{"id":50,"href":"/www6vMiddleware/docs/serviceGovernance/Overview/soaFeature/","title":"分布式服务框架功能","section":"Overview","content":"\n负载均衡 RR Least Connections Least Time “Power of Two Choices” 参考\r#\rNGINX and the “Power of Two Choices” Load-Balancing Algorithm 【直播回放】海量并发微服务框架设计 重要公式\n"},{"id":51,"href":"/www6vMiddleware/docs/serviceGovernance/Springcloud/springTransaction/","title":"Spring事务","section":"Spring Cloud","content":"\n三种事务模型\r#\r三种事务模型 本地事务模型 事务全部交给数据库来管理 编程式事务模型 事务的提交和回滚操作完全交给开发人员 TransactionTemplate TransactionCallback中执行业务代码 事务代码和业务代码可以实现分离的原理【1】 声明式事务模型【AOP】 事务的提交和回滚操作全部交给Spring来管理 事务拦截器TransactionInterceptor 事务管理器transactionManager【2】 事务配置的提供者transactionAttributes【3】\n业务方法+传播属性 代理的对象target\n业务对象 参考\r#\r分布式事务系列（1.1）Spring事务管理器PlatformTransactionManager 乒乓狂魔 分布式事务系列（1.2）Spring的事务体系 乒乓狂魔 "}]