[{"id":0,"href":"/demo/chaptor1/my-first-doc/","title":"My First Doc","section":"章节一","content":"\r一级标题\r#\r二级标题\r#\r三级标题\r#\r"},{"id":1,"href":"/demo/chaptor1/","title":"章节一","section":"Demoes","content":"\r一级标题\r#\r二级标题\r#\r三级标题\r#\r"},{"id":2,"href":"/demo/chaptor3/","title":"章节三","section":"Demoes","content":"\r一级标题\r#\r二级标题\r#\r三级标题\r#\r"},{"id":3,"href":"/demo/chaptor2/","title":"章节二","section":"Demoes","content":"\r一级标题\r#\r二级标题\r#\r三级标题\r#\r"},{"id":4,"href":"/docs/serviceGovernance/faultTolerant/soaGracefulStart/","title":"优雅启动","section":"容错\u0026限流","content":"\n优雅启动 实现 [1]\r#\r调用方发起的RPC 调用流程是怎样的，调用方应用通过服务发现能够获取到服务提供方的 IP 地址，然后每次发送请求前，都需要通过负载均衡算法从连接池中选择一个可用连接。那这样的话，我们是不是就可以让负载均衡在选择连接的时候，区分一下是否是刚启动不久的应用？对于刚启动的应用，我们可以让它被选择到的概率特别低，但这个概率会随着时间的推移慢慢变大，从而实现一个动态增加流量的过程。\n首先对于调用方来说，我们要知道服务提供方启动的时间，这个怎么获取呢？我这里给出两 种方法，一种是服务提供方在启动的时候，把自己启动的时间告诉注册中心；另外一种就是 注册中心收到的服务提供方的请求注册时间。\n调用方通过服务发现获取服务提供方的IP地址，并通过负载均衡算法选择一个可用连接进行RPC调用。为了实现动态增加流量的过程，可以让负载均衡在选择连接时区分是否是刚启动不久的应用。可以通过以下两种方法获取服务提供方的启动时间：一种是服务提供方在启动时告知注册中心自己的启动时间，另一种是注册中心记录服务提供方的注册时间。[gpt 总结]\n延迟加载 [1]\r#\r上述问题的解决方法是将应用启动过程中注册服务的步骤延迟到应用启动完成后，以避免在应用启动未完成时接受请求。此外，可以在应用启动完成后，预先加载和初始化相关资源，如缓存数据，以降低请求处理错误的概率。 [gpt总结]\n参考\r#\r《14 | 优雅启动：如何避免流量打到没有启动完成的节点？》 "},{"id":5,"href":"/docs/serviceGovernance/faultTolerant/soaGracefulClose/","title":"优雅关闭","section":"容错\u0026限流","content":"\n关闭流程\r#\r关闭流程的优雅处理可以通过以下步骤实现 [gpt 总结]\n服务提供方在关闭时设置一个请求挡板，告知调用方正在关闭并不能处理新的请求。 当服务提供方收到新的业务请求时，直接返回一个特定的异常（如ShutdownException）给调用方。 调用方收到异常响应后，将该节点从健康列表中挪出，并自动将请求重试到其他节点，保证业务无损。 除了等待被动调用外，可以加上主动通知流程，提高实时性并避免通知失败的情况。 通过捕获操作系统的进程信号，如使用Java语言中的Runtime.addShutdownHook方法，在关闭钩子中进行关闭标识的设置和服务对象的安全关闭。 在调用链中加入挡板处理器，当新的请求到来时，判断关闭标识，如果正在关闭，则抛出特定异常。 为了完成正在处理的请求，可以在服务对象上添加引用计数器，在开始处理请求前加一，完成处理后减一，根据引用计数器判断是否有正在处理的请求。 服务对象在关闭过程中拒绝新的请求，并根据引用计数器等待正在处理的请求全部结束后真正关闭。 为避免无法正常退出应用，可以在ShutdownHook中添加超时时间控制，当超过指定时间仍未结束，则强制退出应用。 通过以上步骤，实现了服务提供方的优雅关闭，保证业务正常处理并最大限度地完成正在处理的请求。\n参考\r#\r《13 | 优雅关闭：如何避免服务停机带来的业务损失？》\n"},{"id":6,"href":"/docs/serviceGovernance/ConfigDiscovery/soaDiscovery/","title":"服务发现","section":"Config \u0026 Discovery","content":"\n机制\r#\rOverview\r#\r服务注册和发现\n模式\r#\rClient-side Discovery Server-side Discovery patterns 实现\r#\r需求 [1]\r#\rRPC 框架依赖的注册中心的服务数据的一致性其实并不需要满足 CP，只要满足 AP 即可。\nFramework\r#\retcd - CP nacos 基于raft协议 zk - CP eureka - AP 参考\r#\r《08 | 服务发现：到底是要CP还是AP？》 "},{"id":7,"href":"/docs/serviceGovernance/security/soaAuth/","title":"服务治理-鉴权","section":"安全","content":"\n备选方案 [1]\r#\r分布式 Session OAuth2.0 JWT CAS OAuth2 和 JWT的关系[gpt4]\r#\rOAuth2和JWT都是用于实现网络应用中的授权和身份验证的技术。但是，它们在实现方式和使用场景上有所不同。\nOAuth2是一个授权框架，它允许第三方应用在用户的许可下访问其私有资源。例如，一个应用可以使用OAuth2获取用户的Facebook或Google账户信息，而无需用户提供他们的用户名和密码。\nJWT（JSON Web Token）则是一种开放标准（RFC 7519），它定义了一种紧凑且自包含的方式，用于在各方之间安全地传输信息作为JSON对象。这些信息可以被验证和信任，因为它们是数字签名的。\nOAuth2和JWT可以一起使用。例如，当一个应用使用OAuth2获取用户的授权时，它可能会接收到一个包含JWT的访问令牌。应用可以解码这个JWT，以获取关于用户的信息，如他们的用户名或电子邮件地址。同时，因为JWT是签名的，应用可以信任这些信息的准确性。\n总的来说，OAuth2和JWT都是实现网络应用授权和身份验证的重要工具，但它们在实现细节和使用方式上有所不同。\n参考\r#\r微服务之用户鉴权中心 {% post_link \u0026lsquo;securityOAuth2\u0026rsquo; %} self "},{"id":8,"href":"/docs/serviceGovernance/Springcloud/springTransactionInvalid/","title":"Spring  Transaction  失效","section":"Spring Cloud","content":"\nSpring事务失效问题\r#\rspring事务失效 [1]\r#\r- 场景：普通方法调用事务方法时，事务会失效 - 解决：要在普通方法(一般是最外层)上加上@Transactional 代理不生效 [2]\r#\r非public修饰的方法 在AbstractFallbackTransactionAttributeSource类的computeTransactionAttribute方法中有个判断，如果目标方法不是public，则TransactionAttribute返回null，即不支持事务。\n被final、static关键字修饰的类或方法 spring事务底层使用了aop，也就是通过jdk动态代理或者cglib，帮我们生成了代理类，在代理类中实现的事务功能。但如果某个方法用final修饰了，那么在它的代理类中，就无法重写该方法，而添加事务功能。\n类方法内部调用 updateStatus方法拥有事务的能力是因为spring aop生成代理了对象，但是这种方法直接调用了this对象的方法，所以updateStatus方法不会生成事务\n解决方案 新加一个Service方法 在该Service类中注入自己 通过AopContent类 当前类没有被Spring管理\n多线程调用 spring的事务是通过数据库连接来实现的。当前线程中保存了一个map，key是数据源，value是数据库连接。 同一个事务，其实是指同一个数据库连接，只有拥有同一个数据库连接才能同时提交和回滚。如果在不同的线程，拿到的数据库连接肯定是不一样的，所以是不同的事务。\n(存储引擎)表不支持事务\n未开启事务 springboot通过DataSourceTransactionManagerAutoConfiguration类，已经默默的帮你开启了事务。 使用的还是传统的spring项目，则需要在applicationContext.xml文件中，手动配置事务相关参数。如果忘了配置，事务肯定是不会生效的。\n将注解标注在接口方法上\n错误使用@Transactional [2]\r#\r错误的传播机制 目前只有这三种传播特性才会创建新事务：REQUIRED，REQUIRES_NEW，NESTED。\n异常被内部catch 如果想要spring事务能够正常回滚，必须抛出它能够处理的异常。如果没有抛异常，则spring认为程序是正常的。\nrollbackFor属性设置错误\n@Transactional(rollbackFor = BusinessException.class) public void add(UserModel userModel) throws Exception { saveData(userModel); updateData(userModel); } 嵌套事务 可以将内部嵌套事务放在try/catch中，并且不继续往上抛异常。这样就能保证，如果内部嵌套事务中出现异常，只回滚内部事务，而不影响外部事务。\n手动抛了别的异常\n参考\r#\rSpring 踩坑之@Transactional 神奇失效 小鱼儿 spring事务（注解 @Transactional ）失效的12种场景 spring中12种@Transactional的失效场景(小结) Spring @Async/@Transactional 失效的原因及解决方案 未 "},{"id":9,"href":"/docs/serviceGovernance/loadBalance/loadBalance/","title":"负载均衡-算法","section":"负载均衡","content":"\n负载均衡算法\r#\rLVS[1][2]\r#\r组件 类型 负载均衡算法 场景 LVS 静态 RR：roundrobin [常用] 轮询机制 WRR：Weighted RR [常用] 加权轮询，权重越大承担负载越大 SH：Source Hashing 源地址哈希 实现session sticky缺点：调度粒度大，对负载均衡效果差； DH：Destination Hashing 目标地址哈希 动态 LC：least connections 适用于长连接应用\nOverhead=activeconns*256+inactiveconns WLC：Weighted LC [常用] 默认调度方法,较常用（加上了权重）\nOverhead=(activeconns*256+inactiveconns)/weight SED：Shortest Expection Delay Overhead=(activeconns+1)*256/weight NQ：Never Queue， 第一轮均匀分配，后续SED****SED****算法改进 LBLC：Locality-Based LC 动态的 ****DH****连接算法 LBLCR：LBLC with Replication 带复制功能的LBLC Nginx [3]\r#\r组件 类型 负载均衡算法 场景 Nginx 静态 轮询 每个请求按时间顺序逐一分配到不同的后端服务器，如果后端服务器 down 掉，能自动剔除 加权轮询 指定轮询几率，weight 和访问比率成正比，用于后端服务器性能不均的情况 IP Hash 每个请求按访问 ip 的 hash 结果分配，这样每个访客固定访问一个后端服务器，可以解决 session 的问题 动态 Fair （第三方） 按后端服务器的响应时间来分配请求，响应时间短的优先分配 url_hash（第三方） 按访问 url 的 hash 结果来分配请求，使每个 url 定向到同一个后端服务器，后端服务器为缓存时比较有效 Least Connections HAproxy\r#\r组件 类型 负载均衡算法 场景 HAproxy 静态 轮询 加权轮询 IP Hash 动态 Least Connections Source LVS工作模式[11-16]\r#\rDR TUN模式 NAT模式 参考\r#\rLVS负载均衡集群服务搭建详解 LVS调度算法总结 LVS、Nginx 及 HAProxy 的区别 LVS集群的负载调度 *** 未 LVS工作模式\r#\rLVS三种模式的区别及负载均衡算法 LVS 介绍以及配置应用 *** 深入浅出 LVS 负载均衡（一）NAT、FULLNAT 模型原理 未 深入浅出 LVS 负载均衡（二）DR、TUN 模型原理 未 深入浅出 LVS 负载均衡（三）实操 NAT、TUNNEL 模型 未 深入浅出 LVS 负载均衡（四）实操 DR 模型、Keepalived DR 模型的高可用 未 "},{"id":10,"href":"/docs/serviceGovernance/faultTolerant/throttle/ratelimitSentinel/","title":"流量治理-Sentinel","section":"限流","content":"\nSentinel\r#\r限流 API [4]\r#\r定义资源 资源：可以是任何东西，一个服务，服务里的方法，甚至是一段代码。 try (Entry entry = SphU.entry(\u0026#34;HelloWorld\u0026#34;)) { // Your business logic here. System.out.println(\u0026#34;hello world\u0026#34;); } catch (BlockException e) { // Handle rejected request. e.printStackTrace(); } // try-with-resources auto exit @SentinelResource(\u0026#34;HelloWorld\u0026#34;) public void helloWorld() { // 资源中的逻辑 System.out.println(\u0026#34;hello world\u0026#34;); } 定义规则 规则：Sentinel 支持以下几种规则： 流量控制规则、熔断降级规则、系统保护规则、来源访问控制规则和 热点参数规则。 private void initSystemRule() { List\u0026lt;SystemRule\u0026gt; rules = new ArrayList\u0026lt;\u0026gt;(); SystemRule rule = new SystemRule(); // 规则 rule.setHighestSystemLoad(10); rules.add(rule); SystemRuleManager.loadRules(rules); } FlowRuleManager.loadRules(List\u0026lt;FlowRule\u0026gt; rules); // 流控规则 DegradeRuleManager.loadRules(List\u0026lt;DegradeRule\u0026gt; rules); // 降级规则 SystemRuleManager.loadRules(List\u0026lt;SystemRule\u0026gt; rules); // 系统规则 AuthorityRuleManager.loadRules(List\u0026lt;AuthorityRule\u0026gt; rules); // 授权规则 限流 类型 [2]\r#\r直接失败 [滑动时间窗口] Warmup 预热 [令牌桶算法] 限流排队 [漏桶算法] 分布式限流 [1]\r#\r滑动窗口 [2]\r#\r核心代码 LeapArray.java\n/* * Get bucket item at given time from the array. * * (1) Bucket is absent, then just create a new bucket and CAS update to circular array. * (2) Bucket is up-to-date, then just return the bucket. * (3) Bucket is deprecated, then reset current bucket. */ while (true) { WindowWrap\u0026lt;T\u0026gt; old = array.get(idx); if (old == null) { /// 初始化一个窗口 /* * B0 B1 B2 NULL B4 * ||_______|_______|_______|_______|_______||___ * 200 400 600 800 1000 1200 timestamp * ^ * time=888 * bucket is empty, so create new and update * * If the old bucket is absent, then we create a new bucket at {@code windowStart}, * then try to update circular array via a CAS operation. Only one thread can * succeed to update, while other threads yield its time slice. */ WindowWrap\u0026lt;T\u0026gt; window = new WindowWrap\u0026lt;T\u0026gt;(windowLengthInMs, windowStart, newEmptyBucket(timeMillis)); if (array.compareAndSet(idx, null, window)) { // Successfully updated, return the created bucket. return window; } else { // Contention failed, the thread will yield its time slice to wait for bucket available. Thread.yield(); } } else if (windowStart == old.windowStart()) { /// 返回老的窗口 /* * B0 B1 B2 B3 B4 * ||_______|_______|_______|_______|_______||___ * 200 400 600 800 1000 1200 timestamp * ^ * time=888 * startTime of Bucket 3: 800, so it\u0026#39;s up-to-date * * If current {@code windowStart} is equal to the start timestamp of old bucket, * that means the time is within the bucket, so directly return the bucket. */ return old; } else if (windowStart \u0026gt; old.windowStart()) { /// 滚动: 重置老的窗口, 增加新的窗口 /* * (old) * B0 B1 B2 NULL B4 * |_______||_______|_______|_______|_______|_______||___ * ... 1200 1400 1600 1800 2000 2200 timestamp * ^ * time=1676 * startTime of Bucket 2: 400, deprecated, should be reset * * If the start timestamp of old bucket is behind provided time, that means * the bucket is deprecated. We have to reset the bucket to current {@code windowStart}. * Note that the reset and clean-up operations are hard to be atomic, * so we need a update lock to guarantee the correctness of bucket update. * * The update lock is conditional (tiny scope) and will take effect only when * bucket is deprecated, so in most cases it won\u0026#39;t lead to performance loss. */ if (updateLock.tryLock()) { try { // Successfully get the update lock, now we reset the bucket. return resetWindowTo(old, windowStart); /// 清零重置old窗口 } finally { updateLock.unlock(); } } else { // Contention failed, the thread will yield its time slice to wait for bucket available. Thread.yield(); } } else if (windowStart \u0026lt; old.windowStart()) { /// 时钟回拨 // Should not go through here, as the provided time is already behind. return new WindowWrap\u0026lt;T\u0026gt;(windowLengthInMs, windowStart, newEmptyBucket(timeMillis)); } } } Sentinel vs. Hystrix vs. resilience4j [3]\r#\rSentinel Hystrix resilience4j 隔离策略 信号量隔离（并发线程数限流） 线程池隔离/信号量隔离 信号量隔离 熔断降级策略 基于响应时间、异常比率、异常数等 异常比率模式、超时熔断 基于异常比率、响应时间 实时统计实现 滑动窗口（LeapArray） 滑动窗口（基于 RxJava） Ring Bit Buffer 动态规则配置 支持\r多种配置源 支持多种数据源 有限支持 扩展性 丰富的 SPI 扩展接口 插件的形式 接口的形式 基于注解的支持 支持 支持 支持 限流 基于 QPS，支持基于调用关系的限流 有限的支持 Rate Limiter 集群流量控制 支持 不支持 不支持 流量整形 支持预热模式、匀速排队模式等多种复杂场景 不支持 简单的 Rate Limiter 模式 系统自适应保护 支持 不支持 不支持 控制台 提供开箱即用的控制台，可配置规则、查看秒级监控、机器发现等 简单的监控查看 不提供控制台，可对接其它监控系统 多语言支持 Java / C++ Java Java 开源社区状态 活跃 停止维护 较活跃 参考\r#\r集群流量控制\n【图灵学院】2022最新B站独家分布式限流算法原理与应用讲解视频短合集 V\n常用限流降级组件对比 Sentinel vs. Hystrix\nsentinel （史上最全+入门教程） ***\n流控降级最佳实践 阿里 未\n{% post_link \u0026lsquo;ratelimit\u0026rsquo; %} self\n"},{"id":11,"href":"/docs/serviceGovernance/Gray/apiGatewayGray/","title":"API 网关-灰度发布","section":"灰度发布","content":"\n灰度发布 策略 [2]\r#\r基于权重 百分比 version \u0026hellip; 基于springcloud gateway + nacos实现灰度发布[1]\r#\rspring: application: name: gateway-reactor-gray cloud: nacos: discovery: server-addr: localhost:8848 gateway: discovery: locator: enabled: true lower-case-service-id: true routes: - id: hello-consumer uri: grayLb://hello-consumer ## 灰度负载均衡 predicates: - Path=/hello/** public class GrayLoadBalancer implements ReactorServiceInstanceLoadBalancer { ... private Response\u0026lt;ServiceInstance\u0026gt; getInstanceResponse(List\u0026lt;ServiceInstance\u0026gt; instances,HttpHeaders headers) { if (instances.isEmpty()) { return getServiceInstanceEmptyResponse(); } else { return getServiceInstanceResponseWithWeight(instances); // } } /** * 根据版本进行分发 */ private Response\u0026lt;ServiceInstance\u0026gt; getServiceInstanceResponseByVersion(List\u0026lt;ServiceInstance\u0026gt; instances, HttpHeaders headers) { String versionNo = headers.getFirst(\u0026#34;version\u0026#34;); // System.out.println(versionNo); Map\u0026lt;String,String\u0026gt; versionMap = new HashMap\u0026lt;\u0026gt;(); versionMap.put(\u0026#34;version\u0026#34;,versionNo); ... } /** * 根据在nacos中配置的权重值，进行分发 */ private Response\u0026lt;ServiceInstance\u0026gt; getServiceInstanceResponseWithWeight(List\u0026lt;ServiceInstance\u0026gt; instances) { Map\u0026lt;ServiceInstance,Integer\u0026gt; weightMap = new HashMap\u0026lt;\u0026gt;(); for (ServiceInstance instance : instances) { Map\u0026lt;String,String\u0026gt; metadata = instance.getMetadata(); if(metadata.containsKey(\u0026#34;weight\u0026#34;)){ // weightMap.put(instance,Integer.valueOf(metadata.get(\u0026#34;weight\u0026#34;))); } } ... } public class GrayReactiveLoadBalancerClientFilter implements GlobalFilter, Ordered { ... @Override public Mono\u0026lt;Void\u0026gt; filter(ServerWebExchange exchange, GatewayFilterChain chain) { URI url = (URI)exchange.getAttribute(ServerWebExchangeUtils.GATEWAY_REQUEST_URL_ATTR); String schemePrefix = (String)exchange.getAttribute(ServerWebExchangeUtils.GATEWAY_SCHEME_PREFIX_ATTR); if (url != null \u0026amp;\u0026amp; (\u0026#34;grayLb\u0026#34;.equals(url.getScheme()) || \u0026#34;grayLb\u0026#34;.equals(schemePrefix))) { // ServerWebExchangeUtils.addOriginalRequestUrl(exchange, url); ... return this.choose(exchange).doOnNext((response) -\u0026gt; { // ... }).then(chain.filter(exchange)); } else { return chain.filter(exchange); } } private Mono\u0026lt;Response\u0026lt;ServiceInstance\u0026gt;\u0026gt; choose(ServerWebExchange exchange) { // URI uri = (URI)exchange.getAttribute(ServerWebExchangeUtils.GATEWAY_REQUEST_URL_ATTR); GrayLoadBalancer loadBalancer = new GrayLoadBalancer(clientFactory.getLazyProvider(uri.getHost(), ServiceInstanceListSupplier.class), uri.getHost()); if (loadBalancer == null) { throw new NotFoundException(\u0026#34;No loadbalancer available for \u0026#34; + uri.getHost()); } else { return loadBalancer.choose(this.createRequest(exchange)); // } } } 参考\r#\r基于springcloud gateway + nacos实现灰度发布（reactive版） 相关的代码 Go to Page 灰度发布 self "},{"id":12,"href":"/docs/serviceGovernance/API-Gateway/apiGatawaySpringGateway/","title":"API 网关-SpringCloud Gateway","section":"API Gateway","content":"\nFeatures [0]\r#\rBuilt on Spring Framework 5, Project Reactor and Spring Boot 2.0 Able to match routes on any request attribute. Predicates and filters are specific to routes. Circuit Breaker integration. Spring Cloud DiscoveryClient integration Easy to write Predicates and Filters Request Rate Limiting Path Rewriting 核心概念 [1][2]\r#\r路由（Route）\nid：路由标识，要求唯一，名称任意（默认值 uuid，一般不用，需要自定义） uri：请求最终被转发到的目标地址 order： 路由优先级，数字越小，优先级越高 predicates：断言数组，即判断条件，如果返回值是boolean，则转发请求到 uri 属性指定的服务中 filters：过滤器数组，在请求传递过程中，对请求做一些修改 谓词、断言（Predicate） 允许开发人员匹配 HTTP 请求中的内容，比如请求头或请求参数，最后根据匹配结果返回一个布尔值。参照 Java8 的新特性Predicate.\n过滤器（Filter） 可以在返回请求之前或之后修改请求和响应的内容。\n路由（Route）[1][2]\r#\r服务发现-集成nacos服务注册中心 [2]\r#\r服务路由配置 spring: cloud: gateway: routes: - id: gateway-provider_1 ## 使用了lb形式，从注册中心负载均衡的获取uri uri: lb://gateway-provider ## 配置断言 predicates: - Path=/gateway/provider/** filters: - AddResponseHeader=X-Response-Foo, Bar 自动路由配置 # enabled：默认为false，设置为true表明spring cloud gateway开启服务发现和路由的功能，网关自动根据注册中心的服务名为每个服务创建一个router，将以服务名开头的请求路径转发到对应的服务 spring.cloud.gateway.discovery.locator.enabled = true # lowerCaseServiceId：启动 locator.enabled=true 自动路由时，路由的路径默认会使用大写ID，若想要使用小写ID，可将lowerCaseServiceId设置为true spring.cloud.gateway.discovery.locator.lower-case-service-id = true 动态路由-整合 Apollo [2]\r#\r/** * Apollo路由更改监听刷新 */ @Configuration public class GatewayPropertRefresher implements ApplicationContextAware, ApplicationEventPublisherAware { ... /** * 监听路由修改 */ @ApolloConfigChangeListener(interestedKeyPrefixes = \u0026#34;spring.cloud.gateway.\u0026#34;) public void onChange(ConfigChangeEvent changeEvent) { refreshGatewayProperties(changeEvent); } /** * 刷新路由信息 */ private void refreshGatewayProperties(ConfigChangeEvent changeEvent) { logger.info(\u0026#34;gateway网关配置 刷新开始！\u0026#34;); preDestroyGatewayProperties(changeEvent); //更新配置 this.applicationContext.publishEvent(new EnvironmentChangeEvent(changeEvent.changedKeys())); //更新路由 refreshGatewayRouteDefinition(); logger.info(\u0026#34;gateway网关配置 刷新完成！\u0026#34;); } ... } 动态路由-整合nacos [3]\r#\r@Component @Slf4j public class NacosDynamicRouteService implements ApplicationEventPublisherAware { private String dataId = \u0026#34;gateway-router\u0026#34;; private String group = \u0026#34;DEFAULT_GROUP\u0026#34;; @Value(\u0026#34;${spring.cloud.nacos.config.server-addr}\u0026#34;) private String serverAddr; @Autowired private RouteDefinitionWriter routeDefinitionWriter; private ApplicationEventPublisher applicationEventPublisher; private static final List\u0026lt;String\u0026gt; ROUTE_LIST = new ArrayList\u0026lt;\u0026gt;(); @PostConstruct public void dynamicRouteByNacosListener() { try { ConfigService configService = NacosFactory.createConfigService(serverAddr); configService.getConfig(dataId, group, 5000); configService.addListener(dataId, group, new Listener() { @Override public void receiveConfigInfo(String configInfo) { clearRoute(); try { if (StringUtil.isNullOrEmpty(configInfo)) {//配置被删除 return; } List\u0026lt;RouteDefinition\u0026gt; gatewayRouteDefinitions = JSONObject.parseArray(configInfo, RouteDefinition.class); for (RouteDefinition routeDefinition : gatewayRouteDefinitions) { addRoute(routeDefinition); } publish(); } catch (Exception e) { log.error(\u0026#34;receiveConfigInfo error\u0026#34; + e); } } @Override public Executor getExecutor() { return null; } }); } catch (NacosException e) { log.error(\u0026#34;dynamicRouteByNacosListener error\u0026#34; + e); } } private void clearRoute() { for (String id : ROUTE_LIST) { this.routeDefinitionWriter.delete(Mono.just(id)).subscribe(); } ROUTE_LIST.clear(); } private void addRoute(RouteDefinition definition) { try { routeDefinitionWriter.save(Mono.just(definition)).subscribe(); ROUTE_LIST.add(definition.getId()); } catch (Exception e) { log.error(\u0026#34;addRoute error\u0026#34; + e); } } 谓词、断言（Predicate）[1][2]\r#\r过滤器（Filter）[1][2]\r#\r生命周期\nPRE POST 作用范围\nGatewayFilter 局部过滤器 默认预定义 限流 GlobalFilter 全局过滤器 自定义全局过滤器 统一鉴权过滤器 稳定性\r#\r熔断降级-Hystrix [3]\r#\rserver.port: 8082 spring: application: name: gateway redis: host: localhost port: 6379 password: 123456 cloud: gateway: routes: ## - id: rateLimit_route uri: http://localhost:8000 order: 0 predicates: ## - Path=/test/** filters: ## - StripPrefix=1 - name: Hystrix args: name: fallbackCmdA fallbackUri: forward:/fallbackA hystrix.command.fallbackCmdA.execution.isolation.thread.timeoutInMilliseconds: 5000 流控和降级-Sentinel [3]\r#\r高可用网关[1]\r#\rNginx负载均衡到部署的多个Gateway\n参考\r#\rspring-cloud-gateway\n2021最新(完整版)Gateway教学-第二代微服务网关组件SpringCloud-Gateway *** V\nSpring Cloud Gateway 服务网关的部署与使用详细介绍\nSpringCloud gateway （史上最全） 尼恩\n3W字吃透：微服务网关SpringCloud gateway底层原理和实操 尼恩 未\n"},{"id":13,"href":"/docs/serviceGovernance/API-Gateway/apiGatawayApisix/","title":"API 网关-apisix","section":"API Gateway","content":"\napisix特性\r#\rCore api聚合 灰度发布 稳定性 服务熔断 故障注入 流量复制 云原生 多云，混合云 容器友好 随意扩缩容 apisix功能\r#\r动态配置，不用reload\n路由, ssl证书，上游，插件\u0026hellip; 插件化(40个)\n身份验证, 安全, 日志, 可观察性\u0026hellip; 对接Prom，zipkin， skywalking grpc代理和协议转换(rest \u0026lt;-\u0026gt; gprc) apisix只用了nginx的网络层 apisix使用场景\r#\r处理L4, L7层流量 代替nginx处理南北流量 代替envoy处理东西流量 k8s ingress controller 参考\r#\r【云原生学院 #3】基于 Apache APISIX 的全流量 API 网关 *** "},{"id":14,"href":"/docs/serviceGovernance/API-Gateway/apiGateway/","title":"API Gateway网关","section":"API Gateway","content":"\n特性\r#\r路由 灰度发布 反向代理,负载均衡 鉴权 限流 监控 缓存 分类\r#\r入口网关 出口网关 框架\r#\r产品 技术 apisix self lua + Nginx Kong lua + Nginx Zuul Spring Cloud Netflix Gateway self Spring Cloud Traefik Golang 实现 [3]\r#\r扩展性\n责任链模式 - Zuul filter, Envoy filter 性能\n多路 I/O 复用模型 和 线程池 可用性\n线程池 服务隔离 API Gateway+BFF\r#\rAPI Gateway + BFF [3]\r#\r流量网关 + 业务网关\nBFF 聚合网关 [2]\r#\r参考\r#\r使用 API 网关构建微服务 微服务架构：BFF和网关是如何演化出来的？ 《27 | API网关：系统的门面要如何做呢？》 百亿规模API网关服务Shepherd的设计与实现 点评 未 Go to Page self "},{"id":15,"href":"/docs/serviceGovernance/Springcloud/springCloud/","title":"SpringCloud","section":"Spring Cloud","content":"\n参考\r#\rSpringCloud 面试题 （持续更新、吐血推荐）\n"},{"id":16,"href":"/docs/serviceGovernance/ConfigDiscovery/config/","title":"服务治理-分布式配置","section":"Config \u0026 Discovery","content":"\n需求\r#\r对实时性要求不高 对可用性要求高 产品\r#\r产品 存储 Disconf 百度 mysql Apollo 携程 mysql QConf 360 zookeeper 微博 redis 美图 etcd spring cloud config git 参考：\r#\rSpring Boot与Kubernetes云原生微服务实践 杨波 "},{"id":17,"href":"/docs/serviceGovernance/loadBalance/nginxOptimize/","title":"Nginx优化","section":"负载均衡","content":"\nNginx 参数优化\r#\r反向代理\r#\rproxy_cache: 10M(重要) proxy_cache_path /data/nginx_cache/ levels=1:2 keys_zone=my_zone:10m inactive=300s max_size=5g; tls ssl\r#\rssl_session_cache builtin:1000 shared:SSL:10m; /// 一天内连接上的用户， 不需要再协商秘钥 ssl_session_cache builtin:1000 shared:SSL:10m; /// 1m -\u0026gt; 4000个https连接 ssl_session_timeout 10m; /// 10分钟 ssl_protocols TLSv1.2; /// 版本号 非安全请求重定向\r#\rNo redirect: 无重定向 Redirect： 301-302 -》 转到https站点 gzip\r#\rgzip on; gzip_comp_level 5; gzip_http_version 1.1; /// 注意：gzip 在1.1上有效， http2.0上是无效的 gzip_min_length 256; gzip_types application/atom+xml ... gzip_proxied any; gzip_vary on; worker\r#\rworker_connections 16384; /// 一个worker有 16384/2=8192 ‬个链接 . 两个事件， 一个读事件， 一个写事件。 越多的connections对应更多的内存消耗。 Default: worker_connections 512; 高级选项： worker connections的内存池（pools）， 更少的的内存碎片。一般是nginx自动分配的， 不用分配。 Default: connection_pool_size 256|512 Default: request_pool_size 4k; worker_processes 设置worker进程的数量 减少进程间切换\r#\r程间切换： cpu从一个进程或线程切换到另一个进程或线程。\n主动切换和被动切换 减少主动切换 被动切换：时间片耗尽。 减少被动切换： 增大进程优先级 Nice 静态优先级: -20 \u0026ndash; 19 Priority 动态优先级： 0-139 提升CPU缓存命中率\r#\r绑定worker到指定cpu L1,L2(cpu独享) L3（共享的） worker_cpu_affinity cpumask ...; worker_cpu_affinity auto [cpumask]; lua 分配的内存（暂时没有使用）\r#\rlua_shared_dict configuration_data 5M; lua_shared_dict certificate_data 16M; // 应用场景: 集群流控, 多个worker之间的内存的共享。 http的keeplive 长链接（一个tcp的链接，上面有多个http的请求）\r#\r注意: 非tcp keeplive\nkeepalive_disable; /// 没有设置 keepalive_timeout 75s; // 默认值 keepalive_requests 100; // 默认值 一个tcp请求中可发100个http请求 测试用例\r#\rURL：logsearch.sh.pre.urtc.com.cn\ncase1\r#\rinput： 1000用户并发, 短连接， 非keepalive的\nresult： 链接数 40000+\ntps 4000+\navg 百ms\ncase2\r#\rinput： 1500用户并发，短连接， 非keepalive的\nresult： 链接数 30000+，\ntps 4000+ ，\navg 200ms+\n参考\r#\rNginx全面配置 *** 未 "},{"id":18,"href":"/docs/serviceGovernance/security/securityOAuth2/","title":"安全-OAuth2","section":"安全","content":"\n目录\r#\rOAuth 2.0 授权类型 [1][4]\r#\r授权码模式-用的多 Authorization Code 授权码 ***\n客户端模式 Client Credentials\nThe Client Credentials grant is used when applications request an access token to access their own resources, not on behalf of a user.\nxxx Refresh Token *** 动态token\n密码模式-Legacy Password Grant\n基于OAuth2 的微服务 参考架构 [3]\r#\rOverview\r#\r网关 令牌的校验和转换，将前端传递过来的 OAuth 2.0 访问令牌，通过调用 IDP 进 行校验，并转换为包含用户和权限信息的 JWT 令牌，再将 JWT 令牌向后台微服务传 递。 IDP 服务 IDP 是 Identity Provider 的简称，主要负责 OAuth 2.0 授权协议处理，OAuth 2.0 和 JWT 令牌颁发和管理，以及用户认证等功能。IDP 使用后台的 Login-Service 进行用户认 证。 选型: Spring Security OAuth or KeyCloak(RedHat) OAuth2 与微服务进行集成\r#\r第三方 Web 应用 + 授权码模式 各大开放平台是如何使用 OAuth 2.0 的 [2]\r#\r网关集成OAuth2.0 [5]\r#\rOIDC [2]\r#\r什么是 OIDC\r#\r什么是 OIDC？ EU：End User RP：Relying Party OP：OpenID Provider ID Token UserInfo Endpoint OIDC 是 OpenID Connect 的简称，OIDC=(Identity, Authentication) + OAuth 2.0。它在 OAuth2 上构建了一个身份层，是一个基于 OAuth2 协议的身份认证标准协议。OAuth2 是一个授权协议，它无法提供完善的身份认证功能，OIDC 使用 OAuth2 的授权服务器来为第三方客户端提供用户的身份认证，并把对应的身份认证信息传递给客户端.\nOAuth2 提供了Access Token来解决授权第三方客户端访问受保护资源的问题；OIDC 在这个基础上提供了ID Token 来解决第三方客户端标识用户身份认证的问题。\nOIDC 核心概念\r#\rOIDC 核心概念 主要术语 OIDC 工作流程 ID Token 认证 基于 Authorization Code 的认证请求 获取 ID Token Implicit Flow 和 Hybrid Flow UserInfo Endpoint OIDC 示例\r#\rOIDC 示例 + 请求示例： POST /auth/realms/ccm/protocol/openid-connect/token HTTP/1.1 Host: server.example.com Content-Type: application/x-www-form-urlencoded Authorization: Basic d2ViX2FwcDp3ZWJfYXBw grant_type=**authorization_code**\u0026amp;code=7138b4b3-8c2b-4016-ad98-01c4938750c6.c110ddc8-c6c1-4a95-bd9e-cd8d84b4dd70.1eabef67-6473-4ba8-b07c-14bdbae4aaed\u0026amp;redirect_uri=https%3A%2F%2Fclient.example.org%2Fcb + 响应示例： HTTP/1.1 200 OK Content-Type: application/json Cache-Control: no-store Pragma: no-cache { **\u0026#34;access_token\u0026#34;**: \u0026#34;SlAV32hkKG\u0026#34;, \u0026#34;token_type\u0026#34;: \u0026#34;Bearer\u0026#34;, \u0026#34;refresh_token\u0026#34;: \u0026#34;8xLOxBtZp8\u0026#34;, \u0026#34;expires_in\u0026#34;: 3600, **\u0026#34;id_token\u0026#34;**: \u0026#34;eyJhbGciOiJSUzI1NiIsImtpZCI6IjFlOWdkazcifQ.ewogImlzc yI6ICJodHRwOi8vc2VydmVyLmV4YW1wbGUuY29tIiwKICJzdWIiOiAiMjQ4Mjg5 NzYxMDAxIiwKICJhdWQiOiAiczZCaGRSa3F0MyIsCiAibm9uY2UiOiAibi0wUzZ fV3pBMk1qIiwKICJleHAiOiAxMzExMjgxOTcwLAogImlhdCI6IDEzMTEyODA5Nz AKfQ.ggW8hZ1EuVLuxNuuIJKX_V8a_OMXzR0EHR9R6jgdqrOOF4daGU96Sr_P6q Jp6IcmD3HP99Obi1PRs-cwh3LO-p146waJ8IhehcwL7F09JdijmBqkvPeB2T9CJ NqeGpe-gccMg4vfKjkM8FcGvnzZUN4_KSP0aAp1tOJ1zZwgjxqGByKHiOtX7Tpd QyHE5lcMiKPXfEIQILVq0pc_E2DzL7emopWoaoZTF_m0_N0YzFC6g6EJbOEoRoS K5hoDalrcvRYLSrQAZZKflyuVCyixEoV9GfNQC3_osjzw2PAithfubEEBLuVVk4 XUVrWOLrLl0nx7RkKU8NXNHq-rvKMzqg\u0026#34; } 参考\r#\r10 分钟理解什么是 OAuth 2.0 协议 *** OAuth2.0 + OIDC 技术规范及应用场景 *** \u0026laquo;12 | 架构案例：基于OAuth 2.0/JWT的微服务参考架构\u0026raquo; 杨波 *** OAuth2.0的四种模式测试 07 网关集成OAuth2.0实现统一认证鉴权 代码 "},{"id":19,"href":"/docs/serviceGovernance/Springcloud/springboot/","title":"SpringBoot","section":"Spring Cloud","content":"\nCore\r#\rSpring Boot定义\r#\rSpring Boot is designed to get you up and running as quickly as possible, with minimal upfront configuration of Spring. Spring Boot takes an opinionated view of building production-ready applications.\nFeatures (官方)\r#\rCreate stand-alone Spring applications Embed Tomcat, Jetty or Undertow directly (no need to deploy WAR files) Provide opinionated \u0026lsquo;starter\u0026rsquo; dependencies to simplify your build configuration Automatically configure Spring and 3rd party libraries whenever possible Provide production-ready features such as metrics, health checks, and externalized configuration Absolutely no code generation and no requirement for XML configuration 特性\r#\r自动配置 Auto Configuration 为Spring及第三方库提供自动配置; 简化了项目的构建配置;\n无需生成代码或进行xml配置; 约定优于配置(Convention Over Configuration) CoC Starter Dependency\nSpringboot CLI\n内嵌的服务器 方便地创建可独立运行的Spring应用程序; 直接内嵌的Tomcat， Jetty或者Undertow;\n生产级 提供生产级特性; Actuator（Runtime）\nAuto Configuration\r#\r底层装配技术 [3]\r#\rSpring 模式注解装配\nSpring @Enable 模块装配\n// 组件 @EnableXXX @Importer @ImportXXXSelector @Conditional @ConditionalOnClass @ConditionalOnBean ... // 开启自动配置 @EnableAutoConfiguration @SpringBootApplication Spring 条件装配装配 // 实现原理 - 有条件的加载机制 @ConditionalOnClass @ConditionalOnBean @ConditionalOnMissingBean @ConditionalOnProperty ... Spring 工厂加载机制 实现类： SpringFactoriesLoader 配置资源： META-INF/spring.factories 外部化配置加载顺序\r#\r...\r命令行参数（--server.port=9000）\r...\rSystem.getProperties()\r操作系统环境变量\r... jar包外的application-{profile}.properties 或 .yml\rjar包内的application-{profile}.properties 或 .yml\rjar包外的application.properties或 .yml\rjar包内的application.properties或 .yml Starter Dependency\r#\r直接面向功能 官方Starters spring-boot-starter-* \u0026lt;parent\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-parent\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;2.0.0.RELEASE\u0026lt;/version\u0026gt; \u0026lt;/parent\u0026gt; \u0026lt;!-- 使用方 --\u0026gt; \u0026lt;!-- 统一管理依赖 --\u0026gt;\u0026lt;!-- spring cloud的依赖 --\u0026gt; \u0026lt;dependencyManagement\u0026gt;\u0026lt;/dependencyManagement\u0026gt; \u0026lt;!-- 定义方 --\u0026gt; Bill of Materials - bom BOM本质上是一个普通的POM文件 扩展自定义starter \u0026hellip; production-ready\r#\rActuator\r#\r目的： 监控并管理应用程序 访问方式： HTTP, JMX 依赖： spring-boot-starter-actuator Actuator Endpoint\r#\rhttp访问 /actuator/ 端口与路径 management.server.address= management.server.port= 内嵌的Web容器\r#\r可选容器列表\r#\rspring-boot-starter-tomcat spring-boot-starter-jetty spring-boot-starter-undertow spring-boot-starter-reactor-netty 端口\r#\rserver.port server.address 压缩\r#\rTomcat特性配置\r#\rserver.tomcat.max-connections=10000 server.tomcat.max-http-post-size server.tomcat.max-threads 参考\r#\r《玩转Spring全家桶》 67, 68, 71, 73, 75, 79 丁雪峰 V 《黑马程序员SpringBoot教程，6小时快速入门Java微服务架构Spring Boot》 V 《mksz252 - Spring Boot 2.0深度实践之核心技术篇》 第2章 走向自动装配 V *** SpringBoot面试题 (史上最全、持续更新、吐血推荐) 尼恩 未 spring + spring mvc + tomcat 面试题（史上最全） 尼恩 未 SpringBoot 基础知识 核心知识 【收藏版】 尼恩 未 "},{"id":20,"href":"/docs/serviceGovernance/Overview/microservice/","title":"微服务 总结","section":"Overview","content":"\n目录\r#\r微服务 定义\r#\rIn short, the microservice architectural style [1] is an approach to developing a single application as a suite of small services, each running in its own process and communicating with lightweight mechanisms, often an HTTP resource API. These services are built around business capabilities and independently deployable by fully automated deployment machinery. There is a bare minimum of centralized management of these services, which may be written in different programming languages and use different data storage technologies. \u0026ndash; [Martin Fowler]\nCore\r#\rAPI网关\r#\rserviceGovernanceSummary self\n服务容错\r#\rserviceGovernanceSummary self\n服务注册和发现\r#\rserviceGovernanceSummary self\n服务间调用\r#\rMicro Service Architecture Microservice 微服务的理论模型和现实路径\n服务契约\r#\rAPI，具体接口的 API 接入技术说明。 能力，服务能力的描述。 契约，提供这些能力所约定的一些限制条件说明。 版本，支持的最新和历史的版本说明。 调用协议\r#\r同步 HTTP REST（JAX-RS） RPC（Dubbo）\n异步消息 Kafka, RabbitMQ, Notify AMQP, MQTT, STOMP\n服务部署和发布\r#\r微服务部署：蓝绿部署、滚动部署、灰度发布、金丝雀发布\n部署模式 Single Service per Host Multiple Services per Host patterns Design\r#\r服务划分和组合\r#\r微服务不是指\u0026quot;微小\u0026quot;的服务, 而是如何\u0026quot;拆分\u0026quot;服务,然后\u0026quot;组合\u0026quot;服务.\nDDD 领域驱动设计, 上下文划分（context） 康威定律 服务分层\r#\r上层: 聚合服务（适配服务， 边界服务）\r#\r比如：pc和mobile服务对商品服务返回内容的裁剪。\r聚合商品服务和目录服务的内容。 下层: 基础服务（核心领域服务， 公共服务）\r#\r比如：电商的商品服务， 目录服务， 订单服务\rDesign-微服务设计模式\r#\rOverview\r#\rSidecar [11]\r#\r分离业务逻辑与路由，流控，熔断，幂等，服务发现，鉴权等控制组件。\n适用场景： 老系统改造扩展，Sidebar 进程与服务进程部署在同一个节点； 多语言混合分布式系统扩展；\nEg. k8s pod中日志采集sidecar\nThe Scale Cube 可伸缩性\r#\rThe Scale Cube\nX-Axis: Horizontal Duplication and Cloning of services and data Y-Axis: Functional Decomposition and Segmentation - Microservices (or micro-services) Z-Axis: Service and Data Partitioning along Customer Boundaries - Shards/Pods\nX-Axis: Replicate \u0026amp;\u0026amp; Load Balance Y-Axis: Servcie Z-Axis: Data Sharding\n微服务的优势和代价\r#\rMicroservicePremium Martin Fowler.\n生产率和复杂度之间的关系。\n在不复杂的系统中， 更适合monolithic的应用。 复杂度增长时， 微服务的生产率能持续保持，在生产率方面是可伸缩的。\n原则和缺点（挑战）\r#\r微服务架构——不是免费的午餐 有关微服务架构的争论：更简单还是更复杂？\n原则 优点 缺点 挑战 分布式服务组成的系统； 去中心化 可用性高 多服务运维难度 分布式系统的复杂性（容错，延迟，分布式事务） 按照业务而不是技术来划分组织 服务独立无依赖 系统部署依赖 事务、异步、测试面临挑战 做有生命的产品而不是项目 技术栈灵活 运营开销 Smart endpoints and dumb pipes（强服务个体和轻量级通信）; 可组合的服务 独立按需扩展和伸缩 服务间通信成本 隐式接口[接口变更成本] 自动化运维（DevOps） 系统集成测试 DevOps 要求 容错 可用性高 数据一致性 性能监控; 分布式系统的复杂性 快速演化 开发简单 重复工作 系统集成测试 SOA、微服务、云原生演进\r#\r关注点 SOA 微服务 云原生 研发过程 CMM/RUP Agile Agile 交付流程 手工/自动化 DevOps\nDevSecOps GitOps[12]\nAIOps\nNoOps(Serverless) 服务通信 Web Service（WSDL，Soap） REST/私有RPC协议（Dubbo） REST/gRPC,Envoy xDS， MSI协议等开放协议 功能扩展性-filter x AOP filter\nDubbo filter chain\nWEB filter/lisnter Envoy filter 功能扩展性-微内核 x Dubbo SPI K8s CRD, Operator 服务治理 ESB 微服务/API网关（SpringCloud），去中心化, sidecar 服务网格（ istio ， Linked） 分布式 应用运行环境 物理机/虚拟机 虚拟机/容器 Kubernete（操作系统）+ Serverless（Knative） 基础设施 IDC 公有云/私有云 无边界的云（多云/混合云、 云+边+端） 总结 重 轻, 快速 开放、融合 参考\r#\rIntroduction to Microservices 英文\nIntroduction to Microservices 中文 优缺点\n微服务（Microservice）那点事 ***\nPattern: Microservice Architecture ***\n一致性 self\n微服务：分解应用以实现可部署性和可扩展性 Chris Richardson\n《Linux/Unix设计思想》随笔 ——Linux/Unix哲学概述 未\n微服务学习资料汇总 ***\n微服务架构技术栈选型手册 未\n从 SOA 到微服务，企业分布式应用架构在云原生时代如何重塑？ 阿里 易立 ***\n云原生时代，分布式系统设计必备知识图谱（内含22个知识点） 杨泽强（竹涧） ***\n使用托管服务网格实现应用在多集群中的 GitOps 全自动化渐进式发布 郝树伟 阿里云容器服务\n​\n"},{"id":21,"href":"/docs/serviceGovernance/loadBalance/nginx/","title":"Nginx总结","section":"负载均衡","content":"\nNginx总结\r#\rNginx架构\r#\r共享内存 Slab 分页 4K， 8K， 16K Nginx反向代理\r#\r类型\r#\r带权重的round-robin算法是基础 hash负载均衡算法 ip-hash算法 -\u0026gt; real-ip hash算法 -\u0026gt; 自定义可以hash的参数（比如?userName） 问题: 如果有upstream的机器宕机， hash算法还会路由到这台机器 解决方案：使用一致性hash(consistent),hash 环\nleast-connection算法， 如果所有节点的connection都一致， 会退化成为round-robin算法。 可扩展立方体\r#\rX-axis 基于round-robin或者least-connected算法分发请求 -\u0026gt; 相对简单 Y-axis 基于URL对功能进行分发。 -\u0026gt; 相对复杂 Z-axis 将用户IP地址或者其他信息映射到某个特定的服务或者集群 -\u0026gt; 相对简单 多种协议反向代理\r#\rtcp udp 透传 http -\u0026gt; memcached , scgi, fastcgi, uwsgi, grpc, http, websocket 反向代理流程\r#\r修改发送到upstream机器的请求的nginx指令。\n节点热更新\r#\rmaster节点热更新\r#\rworker节点热更新\r#\r域名转发到其他域名[2]\r#\rreturn 指令 rewrite proxy_pass 文件下载\r#\rnginx.conf\nlocation /userlab.dat {\rcharset gbk;\r# alias /home/hp/home/frontend/indicator/userlab.dat;\rroot /home/cms/indicator;\rif ($request_filename ~* ^.*?\\.(txt)$){\radd_header Content-Disposition \u0026#39;attachment\u0026#39;;\radd_header Content-Type: \u0026#39;APPLICATION/OCTET-STREAM\u0026#39;;}\rautoindex on;\rautoindex_exact_size off;\rautoindex_localtime on;\r} 参考\r#\r深入Nginx 思维导图\nnginx配置域名转发到其他域名的几种方法\n"},{"id":22,"href":"/docs/serviceGovernance/faultTolerant/faultTolerant/soaTolerateFramework/","title":"容错框架","section":"容错","content":"\nHystrix实现和容错模式\r#\rHystrix实现和容错模式 熔断【熔断器模式】 三个状态 开 闭 半开 模块 熔断请求判断机制算法 维护10个bucket,每秒一个bucket,每个blucket记录成功,失败,超时,拒绝的状态。 超时【超时与重试模式】 失败（异常） 成功 拒绝 线程池拒绝【1】 信号量拒绝【2】 默认错误超过50%且10秒内超过20个请求进行中断拦截 熔断恢复 每隔5s允许部分请求通过，若请求都是健康的（RT\u0026lt;250ms）则对请求健康恢复 熔断报警和Metric上报 流控【限流模式】 控制速率 控制并发 隔离【舱壁隔离模式】 Hystrix实现 线程池隔离 【1】 信号量隔离【2】 回退【回退模式】 快速失败（Fail Fast ） 无声失败（Fail Silent ） 返回默认值（Fallback Static ） Resilience4j [1]\r#\r断路器（Circuit Breaker） 重试（Retry） 限时器（Time Limiter） 限流器（Rate Limiter） 隔板（BulkHead） 参考\r#\rHystrix\r#\r微服务熔断与隔离 楚岩 Hystrix技术解析 王新栋 \u0026laquo;亿级流量网站架构核心技术\u0026raquo; 5.8节 张开涛 Hystrix 使用与分析 zhangyijun Resilience4j\r#\rResilience4j 比 Hystrix 好在哪里？ "},{"id":23,"href":"/docs/serviceGovernance/faultTolerant/throttle/ratelimit/","title":"限流-总结","section":"限流","content":"\n限流总结\r#\r限流算法\r#\r流控算法 原理 实现 实现复杂度 优势 缺点 计数器法 简单 缺点 临界问题,不能应对突发请求 滑动窗口 滑动时间窗口划成了多格，粒度细; 解决了计数器法的缺点; 基于时间窗口[5] 简单 令牌桶算法 Guava RateLimiter [7] 复杂 能够处理突发请求; 允许某些流量的突发，被业界采用地较多 漏桶算法 漏桶算法[6] 代码[0] 简单 队列算法 FIFO队列; 权重队列; Linux tc 队列长度很关键 分布式限流\r#\r分布式计数器\n实现 Redis(服务端)+Lua(客户端) 限流网关\n缺陷 服务之间的调用不一定走网关 参考\r#\r漏桶算法实现 限流系统如何发现系统的热点 中间件小哥 *** 接口限流算法总结 夜有所思，日有所梦 聊聊高并发系统之限流特技 张开涛 服务化体系之－限流 江南白衣 失效 《应用 6：断尾求生 —— 简单限流 》 Redis 深度历险：核心原理与应用实践 《应用 7：一毛不拔 —— 漏斗限流》 Redis 深度历险：核心原理与应用实践 有代码实现 Guava RateLimiter源码解析 林舍 manerfan 淘宝应用柔性架构的探索 自适应负载调节 "},{"id":24,"href":"/docs/serviceGovernance/faultTolerant/faultTolerant/soaTimeout/","title":"超时和重试 总结","section":"容错","content":"\n关键词： 超时, 降级, 重试\n超时 和 重试\r#\r超时和延迟的原因: 服务端获得请求了，但超时了; 服务端没获得请求，请求失败了， 超时了; 重试方式: 指数级退避 Exponential Blackoff[3][4] 超时类型\r#\r类型 客户端调用超时 服务器端调用超时 提供端/消费端与注册中心之间超时 超时后策略\r#\r超时后策略 超时+快速失败 超时后不重试 超时+降级failback 返回托底（返回历史数据/静态数据/缓存数据）数据，等待页或者错误页 超时+熔断 超时后重试，重试不行后熔断服务 降级\r#\r降级 非核心服务在超时后可以自动降级 超时时间和超时重试次数 最佳实践\r#\r最佳实践 不设置超时 慢请求累积导致连锁反应，甚至造成应用雪崩 推荐值 稍大于压测或者线上监控看到的TP99的响应时间 超时时间太长-不恰当设置 导致本应成功的调用却失败了。超时的时候服务资源没有释放 超时时间太短- 不恰当设置 服务调用成功率降低 最重要：网络连接/读/写的超时 用户能忍受的最长超时时间 - 用户体验 最坏情况下的响应时间=重试次数*单次超时时间 依赖 service重启时大量超时的问题 服务预热功能。延迟发布 客户端的超时时间\u0026lt;服务端的超时 可以在服务端实施限流/降级 多级依赖关系 如A调用B，B调用C 超时设置应该是A\u0026gt;B\u0026gt;C,否则可能会一直重试，引起DDos攻击效果 重试\r#\r重试 客户端 心跳超时 关闭链路，然后由客户端发起重新连接的操作，保证链路能恢复到正常的状态 有负载均衡的中间件，要考虑配置心跳/存活检查 客户端调用超时 重试策略,保证服务调用成功 - failover 摘掉不存活节点 尝试其他分组服务 尝试其他机房服务 服务端 读服务天然适合重试 写服务大多不能重试 幂等 Zookeeper客户端会话超时 - 服务注册反注册 Zookeeper服务端，将该会话对应的Node删除，删除事件通知到所有监听该Node的消费者 重试次数太多 导致多倍请求流量，模拟了DDos攻击 参考\r#\r《亿级流量网站架构核心技术》 张开涛 Hedwig文档 网络重试中的 指数退避抖动 算法 Exponential Backoff And Jitter AWS 中的错误重试和指数退避 "},{"id":25,"href":"/docs/serviceGovernance/threadModel/jsfThreadModel/","title":"京东服务框架JSF服务提供者线程模型","section":"线程模型","content":"\n京东服务框架JSF\r#\rJSF是京东基础架构组的服务化中间件产品，全名是Jingdong Service Framework（中文名：杰夫）。 JSF整体是依据netty来构建的，本文从代码层面简单介绍一下JSF服务端的线程模型。\n1.JSF的服务端线程模型整体上是 boss线程池 + worker线程池 + 业务线程池。boss线程池和worker线程池称为Reactor线程池。\r#\r三类线程池各自的参数详见下图1。\nworker线程池和业务线程池之间的关系详见下图2，在图中可以看到业务线程和worker线程是解耦的，请求放入业务线程后，IO线程即worker线程就返回了，业务线程和I/O线程隔离。 在没有解耦IO线程和业务ChannelHandler的情况时，如果在业务ChannelHandler中进行数据库等同步I/O操作，很有可能会导致IO线程中的pipeline链路被阻塞。\n2. 图3是boss线程池， 线程数为Max(4,cpu/2)，用户不可以配置\r#\r3. 图4是worker线程池， 线程数为Max(8,cpu+1)，用户可以配置\r#\r4.图5和图6是业务线程池的构建，cached线程池大小是20-200，默认queue的大小是0。 任务来了直接分配线程，直到线程池满，得不到执行线程抛异常。\r#\r图7中一个服务端口对应一个业务线程池。\n5. 在ChannelPipeline中ServerHandler根据服务端的配置获取对应的业务线程池，然后在ServerHandler的handlerRequest中提交业务任务，默认的任务是JSFTask。\r#\r具体实现如图8,9,10.\n可以看到，JSF服务提供者线程模型整体还是按照boss+worker+biz这种netty官方推荐的方式构建的。\n参考：\r#\r京东 jsf 源代码和文档 Netty案例集锦之多线程篇（续） 李林锋 "},{"id":26,"href":"/docs/serviceGovernance/faultTolerant/faultTolerant/soaTolerate/","title":"分布式服务框架 容错机制","section":"容错","content":"\n关键词： 容错, 降级, 隔离, 超时, 重试, 高可用, 监控, 开关\nOverview\r#\r超时重试机制[self 1][self 2] 限流 熔断机制 隔离 降级（本地缓存） 流量调度、负载均衡 微服务熔断与隔离 降级\r#\r降级策略 场景 实现 降低一致性约束 [1] 关闭非核心业务 人工开关 （非核心服务）, 强制降级,简化功能 开关存放位置:配置文件,数据库, Redis/Zk 关闭非核心业务 自动开关(非核心服务), 超时降级 1. 统计失败次数降级-不稳定的api\n2. 限流降级-大促秒杀\n3. 实现-熔断器 超时和重试 Retry\r#\r超时和重试 网络连接/读/写的超时时间（重要） 服务 读服务 - 可重试 写服务 - 幂等可重试 服务 客户端超时与重试 服务端超时 - 业务超时 任务型 服务调用型 超时后策略 failover 其它分组 其它机房 failcache 托底默认数据 等待页/错误页 降级 超时时间 太短 调用成功率降低 太长 后续正常请求挤压 经验值 稍微大于tp99的响应时间 集群容错\r#\r集群容错 Fail over（重试其他节点） 超时异常 Fail fast（快速失败） Fail cache（重试故障节点）（hedwig） 网路异常 Fail back（回退） 隔离 BulkHead\r#\r隔离 线程池隔离(hystirx) vm隔离（资源隔离） 物理机隔离 集群隔离 分组隔离 机房隔离 框架\r#\r框架 淘宝Dubbo 一号店Hedwig 京东JSF 点评pegion 唯品会OSP 状态监测\r#\r状态监测 服务注册中心状态监测（hedwig） 服务提供者和消费者之间的链路有效性检测（pegion） 服务健康检查（打分） 反推回消费者的路由表 流量控制（算法） Rate Limiter\r#\r流量控制（算法）　限流算法 令牌桶（控制入口） 漏桶（控制出口） 计数器(hedwig) 接口的总请求数（hedwig客户端） 接口的时间窗口请求数（hedwig服务端） 平滑限流,整形（netty） 整体流控 静态流控(整体qps固定) 预先分配 动态配额分配置（推） 动态配额申请制（拉） 动态流控 分级流控-拒绝流量 连接控制 并发控制（线程的并发执行数） 参考\r#\rself\r#\r{% post_link \u0026lsquo;soaTolerate\u0026rsquo; %} self {% post_link \u0026lsquo;soaTimeout\u0026rsquo; %} self "},{"id":27,"href":"/docs/serviceGovernance/Overview/soaFeature/","title":"分布式服务框架功能","section":"Overview","content":"\n负载均衡 RR Least Connections Least Time “Power of Two Choices” 参考\r#\rNGINX and the “Power of Two Choices” Load-Balancing Algorithm 【直播回放】海量并发微服务框架设计 重要公式\n"},{"id":28,"href":"/docs/serviceGovernance/Springcloud/springTransaction/","title":"Spring事务","section":"Spring Cloud","content":"\n三种事务模型\r#\r三种事务模型 本地事务模型 事务全部交给数据库来管理 编程式事务模型 事务的提交和回滚操作完全交给开发人员 TransactionTemplate TransactionCallback中执行业务代码 事务代码和业务代码可以实现分离的原理【1】 声明式事务模型【AOP】 事务的提交和回滚操作全部交给Spring来管理 事务拦截器TransactionInterceptor 事务管理器transactionManager【2】 事务配置的提供者transactionAttributes【3】\n业务方法+传播属性 代理的对象target\n业务对象 参考\r#\r分布式事务系列（1.1）Spring事务管理器PlatformTransactionManager 乒乓狂魔 分布式事务系列（1.2）Spring的事务体系 乒乓狂魔 "}]