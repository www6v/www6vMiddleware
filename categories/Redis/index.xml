<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Redis on 中间件</title>
    <link>https://www6v.github.io/www6vMiddleware/categories/Redis/</link>
    <description>Recent content in Redis on 中间件</description>
    <generator>Hugo</generator>
    <language>en</language>
    <lastBuildDate>Mon, 10 Jul 2023 15:48:29 +0000</lastBuildDate>
    <atom:link href="https://www6v.github.io/www6vMiddleware/categories/Redis/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Redis Rehash机制</title>
      <link>https://www6v.github.io/www6vMiddleware/docs/Redis&#43;%E7%BC%93%E5%AD%98/Redis-%E5%9F%BA%E7%A1%80/%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B/redisRehash/</link>
      <pubDate>Sun, 20 Jun 2021 22:50:50 +0000</pubDate>
      <guid>https://www6v.github.io/www6vMiddleware/docs/Redis&#43;%E7%BC%93%E5%AD%98/Redis-%E5%9F%BA%E7%A1%80/%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B/redisRehash/</guid>
      <description>&#xA;什么时候触发 rehash？&#xD;#&#xD;，_dictExpandIfNeeded 函数中定义了三个扩容条件。 下面的代码就展示了 _dictExpandIfNeeded 函数对这三个条件的定义，你可以看下。 条件一：ht[0]的大小为 0。 条件二：ht[0]承载的元素个数已经超过了 ht[0]的大小，同时 Hash 表可以进行扩容。 条件三：ht[0]承载的元素个数，是 ht[0]的大小的 dict_force_resize_ratio 倍，其中， dict_force_resize_ratio 的默认值是 5。&#xA;rehash 扩容扩多大？&#xD;#&#xD;对 Hash表扩容的思路也很简单，就是如果当前表的已用空间大小为 size，那么就将表扩容到 size*2 的大小。&#xA;rehash 如何执行？&#xD;#&#xD;其实这是因为，Hash 表在执行 rehash 时，由于 Hash 表空间扩大，原本映射到某一位置 的键可能会被映射到一个新的位置上，因此，很多键就需要从原来的位置拷贝到新的位 置。而在键拷贝时，由于 Redis 主线程无法执行其他请求，所以键拷贝会阻塞主线程，这 样就会产生 rehash 开销。&#xA;而为了降低 rehash 开销，Redis 就提出了渐进式 rehash 的方法。&#xA;dictRehash 的主要执行流程&#xD;#&#xD;</description>
    </item>
    <item>
      <title>Redis 架构</title>
      <link>https://www6v.github.io/www6vMiddleware/docs/Redis&#43;%E7%BC%93%E5%AD%98/Redis-%E5%9F%BA%E7%A1%80/Arch-Redis-Cluster/redisArch/</link>
      <pubDate>Tue, 25 May 2021 18:35:49 +0000</pubDate>
      <guid>https://www6v.github.io/www6vMiddleware/docs/Redis&#43;%E7%BC%93%E5%AD%98/Redis-%E5%9F%BA%E7%A1%80/Arch-Redis-Cluster/redisArch/</guid>
      <description>目录&#xD;#&#xD;Redis架构演进[1]&#xD;#&#xD;数据怕丢失 -&amp;gt; 持久化（RDB/AOF） 恢复时间久 -&amp;gt; 主从副本（副本随时可切） 故障手动切换慢 -&amp;gt; 哨兵集群（自动切换） 读存在压力 -&amp;gt; 扩容副本（读写分离） 写存在压力/容量瓶颈 -&amp;gt; 分片集群 分片集群社区方案 -&amp;gt; Twemproxy、Codis（Redis 节点之间无通信，需要部署哨兵，可横向扩容） 分片集群官方方案 -&amp;gt; Redis Cluster （Redis 节点之间 Gossip 协议，无需部署哨兵，可横向扩容） 业务侧升级困难 -&amp;gt; Proxy + Redis Cluster（不侵入业务侧） 主从架构&#xD;#&#xD;主从同步 异步方式来同步数据 最终一致性 分类 增量同步 （同步的是指令） 1.指令记录在master本地的内存 buffer 2.异步将 buffer 中的指令同步到从节点 类似 AOF 快照同步（同步的是内容，全量同步） bgsave存磁盘rdb，然后rdb发到slave，slave装载 优化: 2.8.18 版开始支持无盘复制 哨兵集群 sentinel&#xD;#&#xD;master-slave异步复制, 所以会丢消息&#xA;参数: # 至少有一个slave复制 min-slaves-to-write 1 # slave节点最大10s的延迟 min-slaves-max-lag 10 Redis cluster&#xD;#&#xD;整体架构</description>
    </item>
    <item>
      <title>Redis 总结</title>
      <link>https://www6v.github.io/www6vMiddleware/docs/Redis&#43;%E7%BC%93%E5%AD%98/Redis-%E5%9F%BA%E7%A1%80/overview/redis/</link>
      <pubDate>Sat, 12 Nov 2016 23:29:16 +0000</pubDate>
      <guid>https://www6v.github.io/www6vMiddleware/docs/Redis&#43;%E7%BC%93%E5%AD%98/Redis-%E5%9F%BA%E7%A1%80/overview/redis/</guid>
      <description>事务&#xD;#&#xD;- 原子性 一致性 隔离性 持久性 redis 一定的原子性，但不支持回滚 × √ 通过一定策略可以保证持久性 redis 没有进行回滚，不具备原子性.操作之后写AOF日志 aof可以保证，但从应用层看没有回滚和原子性，所以并不能保证一致性 单线程天然隔离 纯内存(×)RDB Bgsave(√) RDB 异步执行(×) mysql √ √ √ √ mysql undo log 锁 锁 redo log hash命令&#xD;#&#xD;redis hash的结构：一维数组+二维链表（和java的hashmap结构一样）&#xA;redis rehash: 渐进式rehash Java rehash： 一次性将旧数组下挂接的元素全部转移到新数组下面&#xA;IO模型和性能&#xD;#&#xD;非阻塞IO： read， write时不阻塞&#xA;事件轮询和多路复用[8]&#xA;redis性能 最低配置: 4GB， 2核， 链接数2w， QPS 16w&#xA;redis性能高的原因&#xA;高效的数据结构 多路复用IO模型 事件机制 总结:Reactor + 队列 [10] 大体上可以说 Redis 的工作模式是，reactor 模式配合一个队列，用一个 serverAccept 线程来处理建立请求的链接， 并且通过 IO 多路复用模型，让内核来监听这些 socket，一旦某些 socket 的读写事件准备就绪后就对应的事件压入队列中， 然后 worker 工作，由文件事件分派器从中获取事件交于对应的处理器去执行，当某个事件执行完成后文件事件分派器才会从队列中获取下一个事件进行处理。 可以类比在 netty 中，我们一般会设置 bossGroup 和 workerGroup 默认情况下 bossGroup 为 1，workerGroup = 2 * cpu 数量， 这样可以由多个线程来处理读写就绪的事件，但是其中不能有比较耗时的操作如果有的话需要将其放入线程池中，不然会降低其吐吞量。 在 Redis 中我们可以看做这二者的值都是 1。</description>
    </item>
    <item>
      <title>Redis Error-MOVED和ASK指令</title>
      <link>https://www6v.github.io/www6vMiddleware/docs/Redis&#43;%E7%BC%93%E5%AD%98/Redis-%E5%9F%BA%E7%A1%80/Arch-Redis-Cluster/redisError/</link>
      <pubDate>Mon, 28 Mar 2022 10:47:56 +0000</pubDate>
      <guid>https://www6v.github.io/www6vMiddleware/docs/Redis&#43;%E7%BC%93%E5%AD%98/Redis-%E5%9F%BA%E7%A1%80/Arch-Redis-Cluster/redisError/</guid>
      <description>{% details 相关代码 %} cluster.c&#xA;/* Return the pointer to the cluster node that is able to serve the command. * For the function to succeed the command should only target either: * * 1) A single key (even multiple times like LPOPRPUSH mylist mylist). * 2) Multiple keys in the same hash slot, while the slot is stable (no * resharding in progress). * * On success the function returns the node that is able to serve the request.</description>
    </item>
    <item>
      <title>Redis 的IO模型</title>
      <link>https://www6v.github.io/www6vMiddleware/docs/Redis&#43;%E7%BC%93%E5%AD%98/Redis-%E5%9F%BA%E7%A1%80/overview/redisIO/</link>
      <pubDate>Tue, 18 Jan 2022 21:28:08 +0000</pubDate>
      <guid>https://www6v.github.io/www6vMiddleware/docs/Redis&#43;%E7%BC%93%E5%AD%98/Redis-%E5%9F%BA%E7%A1%80/overview/redisIO/</guid>
      <description>关键词： 单线程，事件， socket， 多路复用&#xD;#&#xD;Redis 的IO模型&#xD;#&#xD;Redis 是单线程，主要是指 Redis 的网络 IO 和键值对读写是由一个线程来完成的，这也是 Redis 对外提供键值存储服务的主要流程。 但 Redis 的其他功能，比如持久化、异步删除、集群数据同步等，其实是由额外的线程执 行的。&#xA;多路复用&#xD;#&#xD;Linux 中的 IO 多路复用机制是指一个线程处理多个 IO 流，就是我们经常听到的 select/epoll 机制。简单来说，在 Redis 只运行单线程的情况下，该机制允许内核中，同 时存在多个监听套接字和已连接套接字。内核会一直监听这些套接字上的连接请求或数据 请求。一旦有请求到达，就会交给 Redis 线程处理，这就实现了一个 Redis 线程处理多个 IO 流的效果。&#xA;为了在请求到达时能通知到 Redis 线程，select/epoll 提供了基于事件的回调机制，即针 对不同事件的发生，调用相应的处理函数。&#xA;epoll的API&#xD;#&#xD;int epoll_create(int size); int epoll_ctl(int epfd, int op, int fd, struct epoll_event *event); // 事件注册 int epoll_wait(int epfd, struct epoll_event * events, int maxevents, int timeout); // 事件分配、事件处理</description>
    </item>
    <item>
      <title>Redis数据结构</title>
      <link>https://www6v.github.io/www6vMiddleware/docs/Redis&#43;%E7%BC%93%E5%AD%98/Redis-%E5%9F%BA%E7%A1%80/%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B/redisDataStructure/</link>
      <pubDate>Wed, 05 May 2021 22:25:55 +0000</pubDate>
      <guid>https://www6v.github.io/www6vMiddleware/docs/Redis&#43;%E7%BC%93%E5%AD%98/Redis-%E5%9F%BA%E7%A1%80/%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B/redisDataStructure/</guid>
      <description>数据结构和实现&#xD;#&#xD;数据结构 基础 优化 特点 String SDS List 双向列表 压缩列表 Hash hash表 压缩列表 渐进式rehash SortedSet 跳表 压缩列表 Set 整数数组 全局hash表 &amp;amp;&amp;amp; 渐进式 rehash&#xD;#&#xD;参考：&#xD;#&#xD;02 | 数据结构:快速的Redis有哪些慢操作?</description>
    </item>
    <item>
      <title>Redis Cluster</title>
      <link>https://www6v.github.io/www6vMiddleware/docs/Redis&#43;%E7%BC%93%E5%AD%98/Redis-%E5%9F%BA%E7%A1%80/Arch-Redis-Cluster/redisCluster/</link>
      <pubDate>Mon, 11 Jul 2022 06:45:41 +0000</pubDate>
      <guid>https://www6v.github.io/www6vMiddleware/docs/Redis&#43;%E7%BC%93%E5%AD%98/Redis-%E5%9F%BA%E7%A1%80/Arch-Redis-Cluster/redisCluster/</guid>
      <description>目录&#xD;#&#xD;Cluster 功能 [1.1]&#xD;#&#xD;Redis Cluster支持多个master，每个master又可以挂载多个slave&#xA;读写分离 支持数据的高可用 故障转移， 高可用 由于Cluster自带Sentinel的故障转移机制，内置了高可用的支持， 无需再去使用哨兵功能&#xA;由对应的集群来负责维护节点、插槽和数据之间的关系&#xA;Slot&#xD;#&#xD;Redis集群有16384个哈希槽每个key通过CRC16校验后对16384取模来决定放置哪个槽，集群的每个节点负责一部分hash槽.&#xA;分片方式&#xD;#&#xD;crc（key）% 16384 映射关系&#xD;#&#xD;key （→ CRC） 分片 分片 (→ 映射关系) 实例&#xA;slot分配&#xD;#&#xD;自动分配slot create() 手动分配slot meet() addSlot() 指令&#xD;#&#xD;MOVED指令， ASK 指令 最大槽数是16384的原因 [1.3]&#xD;#&#xD;[ redis 作者解答] why redis-cluster use 16384 slots? #2576 antirez&#xA;[中文翻译] 正常的心跳数据包带有节点的完整配置，可以用幂等方式用旧的节点替换旧节点，以便更新旧的配置。 这意味着它们包含原始节点的插槽配置，该节点使用2k的空间和16k的插槽，但是会使用8k的空间（使用65k的插槽）。同时，由于其他设计折衷，Redis集群不太可能扩展到1000个以上的主节点。 因此16k处于正确的范围内，以确保每个主机具有足够的插槽，最多可容纳1000个矩阵，但数量足够少，可以轻松地将插槽配置作为原始位图传播。请注意，在小型群集中，位图将难以压缩，因为当N较小时，位图将设置的slot / N位占设置位的很大百分比。&#xA;[解读]&#xA;消息头太大， 发送的心跳包过于庞大 如果槽位为65536，发送心跳信息的消息头达8k，发送的心跳包过于庞大。 在消息头中最占空间的是myslots[CLUSTER_SLOTS/8]。当槽位为65536时，这块的大小是:65536÷8÷1024=8kb&#xA;在消息头中最占空间的是myslots[CLUSTER_SLOTS/8]。当槽位为16384时，这块的大小是:16384∶8∶1024=2kb</description>
    </item>
    <item>
      <title>Redis Cluster Spec</title>
      <link>https://www6v.github.io/www6vMiddleware/docs/Redis&#43;%E7%BC%93%E5%AD%98/Redis-%E5%9F%BA%E7%A1%80/Arch-Redis-Cluster/redisClusterSpec/</link>
      <pubDate>Mon, 11 Jul 2022 13:15:05 +0000</pubDate>
      <guid>https://www6v.github.io/www6vMiddleware/docs/Redis&#43;%E7%BC%93%E5%AD%98/Redis-%E5%9F%BA%E7%A1%80/Arch-Redis-Cluster/redisClusterSpec/</guid>
      <description>目录&#xD;#&#xD;设计目标和基本原理[bing]&#xD;#&#xD;高性能和线性扩展&#xD;#&#xD;Redis集群可以支持到1000个节点，使用异步复制和无代理的架构，避免了值合并的开销。&#xA;可接受的写安全性&#xD;#&#xD;Redis集群尽力保留与大多数主节点连接的客户端的写操作，但在分区窗口期内可能会丢失已确认的写操作。&#xA;可用性&#xD;#&#xD;Redis集群可以在大多数主节点可达且每个不可达主节点至少有一个可达副本的情况下存活，并且可以通过副本迁移来提高抗故障能力。&#xA;哈希槽分配&#xD;#&#xD;Redis集群将16384个哈希槽分配给不同的主节点，每个主节点负责存储和服务一部分哈希槽。客户端可以通过计算键的CRC16值对16384取模来得到对应的哈希槽。也可以使用哈希标签来强制将多个键分配到同一个哈希槽，以支持多键操作。&#xA;节点间通信&#xD;#&#xD;Redis集群节点之间使用一个TCP端口和一个二进制协议进行通信，称为集群总线。每个节点都与其他所有节点连接，使用gossip协议来传播集群的信息，如新节点、故障节点、配置变化等。&#xA;客户端重定向&#xD;#&#xD;Redis集群节点不会代理请求，而是根据自己的哈希槽映射表，将客户端重定向到正确的节点。客户端可能收到MOVED或ASK错误，表示需要重新发送请求到另一个节点。MOVED表示哈希槽被永久地分配给了另一个节点，ASK表示哈希槽正在被迁移，需要发送ASKING命令后再发送请求。&#xA;哈希槽迁移&#xD;#&#xD;Redis集群支持在运行时添加和删除节点，这是通过将哈希槽从一个节点移动到另一个节点来实现的。迁移过程中，源节点会将接收到的关于该哈希槽的请求重定向到目标节点，或者直接处理已存在键的请求。目标节点会接收到源节点通过MIGRATE命令发送过来的键，并在迁移完成后更新自己的配置。&#xA;故障检测和副本提升&#xD;#&#xD;Redis集群使用心跳包和gossip协议来检测节点是否可达，并使用PFAIL和FAIL两种标志来表示故障状态。当一个主节点被大多数主节点标记为FAIL时，它的一个副本会发起选举并请求投票。如果获得了大多数主节点的授权，该副本会提升为主节点，并生成一个新的配置版本号（configEpoch）。&#xA;副本选举和配置传播的机制[bing]&#xD;#&#xD;副本选举&#xD;#&#xD;当一个主节点失效时，它的一个副本会尝试发起选举，向其他主节点发送授权请求。如果获得了大多数主节点的回复，它就赢得了选举，并获得了一个新的唯一的配置版本号（configEpoch）。它会开始以主节点的身份广播心跳包，并通知其他节点更新配置。&#xA;配置传播&#xD;#&#xD;当一个节点收到一个心跳包或UPDATE消息时，它会根据一些规则来更新自己的哈希槽映射表。如果一个哈希槽是未分配的，或者有一个新的节点使用更高的configEpoch来声明它，那么接收者会将该哈希槽绑定到新的节点。这样可以保证最后一次故障转移胜出，并且所有节点最终会达成一致。&#xA;节点重置和遗忘&#xD;#&#xD;当一个节点需要从一个集群中移除或加入到另一个集群时，可以使用CLUSTER RESET命令来重置它的状态。这个命令有两种模式：软重置和硬重置。软重置会保留当前的configEpoch，而硬重置会将其设置为0。当一个节点被移除后，其他节点需要使用CLUSTER FORGET命令来删除它在节点表中的条目，并设置一个60秒的禁止期，防止因为gossip协议而重新添加它。&#xA;发布订阅&#xD;#&#xD;Redis集群支持发布订阅功能，客户端可以向任何节点发送SUBSCRIBE或PUBLISH命令。集群会将发布的消息转发到所有其他节点。Redis 7.0及以后版本还支持分片发布订阅功能，其中分片频道根据与键相同的算法分配到哈希槽。分片消息必须发送到拥有该哈希槽的节点，集群会将发布的分片消息转发到该哈希槽所在的分片中的所有节点。&#xA;CRC16算法&#xD;#&#xD;这篇文章最后给出了计算键对应哈希槽的CRC16算法的C语言实现代码。这个算法使用了1021作为多项式，并且不反转输入输出字节。&#xA;参考&#xD;#&#xD;Redis cluster specification ***</description>
    </item>
    <item>
      <title>Redis 集群  容灾（同城多活）</title>
      <link>https://www6v.github.io/www6vMiddleware/docs/Redis&#43;%E7%BC%93%E5%AD%98/Redis-%E5%9F%BA%E7%A1%80/Arch-Redis-Cluster/redisHA/</link>
      <pubDate>Sun, 31 Jul 2022 11:37:41 +0000</pubDate>
      <guid>https://www6v.github.io/www6vMiddleware/docs/Redis&#43;%E7%BC%93%E5%AD%98/Redis-%E5%9F%BA%E7%A1%80/Arch-Redis-Cluster/redisHA/</guid>
      <description>目录&#xD;#&#xD;1. 背景&#xD;#&#xD;Redis 集群自身已经具备了高可用的特性，即使几个Redis节点异常或者挂掉，Redis 集群也会实现故障自动转移，对应用方来说也可以在很短时间内恢复故障。 但是，如果发生了机房故障(断电、断网等极端情况)，Redis集群节点全部挂掉（过半主节点挂掉），会造成集群服务不可用，对于核心业务来说是不可接受的。 为了应对机房故障情况，保障在这种极端情况下，核心业务仍然可以正常访问 Redis 服务，本文将给出适合我司的 Redis 跨机房高可用解决方案。 2. 目标&#xD;#&#xD;保障单机房整体故障时 Redis 缓存服务正常运行。 单机房故障 RTO：30s，RPO：1s 3. 解决方案&#xD;#&#xD;3.1 核心能力&#xD;#&#xD;客户端流量路由：支持按一定的策略，把流量分流到不同机房；机房故障后，流量自动流向其他机房。 服务端故障转移：支持机房故障后，当前机房原来主节点的从节点，通过选举自动倒换成新的主节点。 管理平台正常服务：任一机房故障，Renault 管理平台使用不受影响。 3.2 工作模式&#xD;#&#xD;组件在机房高可用场景下一般有多种工作模式，典型的有单集群模式及多集群模式。本节描述组件在各种工作模式下的部署方式及工作机制。&#xA;部署方案 方案说明 跨机房混合部署 将Redis集群主节点平均分配到各个机房，主从节点在不同机房 各机房独立部署集群 + 数据单向同步 各机房均独立部署集群，集群为热备模式，写请求均写入同一个集群，然后同步到其他集群 各机房独立部署集群 + 数据双向同步 每个机房部署一套Redis集群，同步核心业务写请求 数据同步方法：&#xA;数据同步方案 方案说明 客户端双写 客户端同时写入到各个集群 客户端代理 Netflix开源实现的Dynomite，通过代理层接受数据后写入各个需要同步的节点&#xA;改造难度大&#xA;客户端需要优化添加Dyno Client服务端每个节点需要部署Dyno Node&#xA;read/write性能较原生差异较大，主要体现在write上，之间的差异随着node节点数越多越严重 伪从节点 基于Redis的Master-Slave复制协议，实现低延时、高可用的Redis多数据中心、跨公网数据复制携程开源系统：https://github.com/ctripcorp/x-pipe阿里RedisShake同步工具 写事件监听+MQ跨集群消息同步 读写在本机房，监听写事件 + MQ消息同步到其他机房需要开启事件通知（PUB），修改Redis配置文件中的 notify-keyspace-events 配置（默认的redis并没有开启这个功能）需要独立服务订阅写事件（SUB），并同步到其他集群依赖MQ组件 不考虑客户端代理、发布订阅写事件</description>
    </item>
    <item>
      <title>Redis 混合持久化</title>
      <link>https://www6v.github.io/www6vMiddleware/docs/Redis&#43;%E7%BC%93%E5%AD%98/Redis-%E5%9F%BA%E7%A1%80/%E6%8C%81%E4%B9%85%E5%8C%96/redisBothAofAndRDB/</link>
      <pubDate>Mon, 10 Jul 2023 15:48:29 +0000</pubDate>
      <guid>https://www6v.github.io/www6vMiddleware/docs/Redis&#43;%E7%BC%93%E5%AD%98/Redis-%E5%9F%BA%E7%A1%80/%E6%8C%81%E4%B9%85%E5%8C%96/redisBothAofAndRDB/</guid>
      <description>&#xA;Redis 混合持久化&#xD;#&#xD;数据恢复顺序和加载流程 [2][3]&#xD;#&#xD;在这种情况下， 当redis重启的时候会优先载入AOF文件来恢复原始的数据 ，因为在通常情况下AOF文件保存的数据集要比RDB文件保存的数据集要完整。&#xA;RDB和AOF共存时会优先加载AOF文件&#xA;【主从切换 优先加载 RDB -&amp;gt; 速度】 【redis重启 优先加载 AOF -&amp;gt; 数据完整性】&#xA;开启&#xD;#&#xD;aof-use-rdb-preamble no -&amp;gt; yes 原理 [3]&#xD;#&#xD;RDB镜像做全量持久化，AOF做增量持久化 先使用RDB进行快照存储，然后使用AOF持久化记录所有的写操作，当重写策略满足或手动触发重写的时候，将最新的数据存储为新的RDB记录。 这样的话，重启服务的时候会从RDB和AOF两部分恢复数据，既保证了数据完整性，又提高了恢复数据的性能。简单来说:混合持久化方式产生的文件一部分是RDB格式，一部分是AOF格式。&#xA;AOF+RDB混合[1]&#xD;#&#xD;而混合使用 RDB 和 AOF，正好可以取两者之长，避两者之短，以较小的性能开销保证数据可靠性和性能。&#xA;参考&#xD;#&#xD;《05丨内存快照：宕机后，Redis如何实现快速恢复？》 redis++：Redis持久化 rdb &amp;amp; aof 工作原理及流程图 （三） RDB-AOF混合持久化 尚硅谷Redis零基础到进阶，最强redis7教程，阳哥亲自带练（附redis面试题） </description>
    </item>
    <item>
      <title>Redis 主从复制</title>
      <link>https://www6v.github.io/www6vMiddleware/docs/Redis&#43;%E7%BC%93%E5%AD%98/Redis-%E5%9F%BA%E7%A1%80/%E6%8C%81%E4%B9%85%E5%8C%96/redisReplica/</link>
      <pubDate>Sun, 10 Jul 2022 19:04:46 +0000</pubDate>
      <guid>https://www6v.github.io/www6vMiddleware/docs/Redis&#43;%E7%BC%93%E5%AD%98/Redis-%E5%9F%BA%E7%A1%80/%E6%8C%81%E4%B9%85%E5%8C%96/redisReplica/</guid>
      <description>&#xA;主从复制流程&#xD;#&#xD;主从库第一次同步的流程&#xD;#&#xD;主从库增量复制流程&#xD;#&#xD;repl_backlog_buffer 是一个环形缓冲区，主库会记录自己写到的位置，从库则会记录自己 已经读到的位置。&#xA;缺点 [3]&#xD;#&#xD;主从延迟 复制偏移量：master_repl_offset | slave_repl_offset master挂了怎么办？ 默认情况下，不会在slave节点中自动选一个master 每次都要人工干预 需要Redis哨兵(sentinel) 参考&#xD;#&#xD;《06 | 数据同步：主从库如何实现数据一致？》 redis主从复制、主从延迟知几何 复制原理和工作流程 61_redis主从复制之工作流程总结 V 62_redis主从复制之痛点和改进需求 V </description>
    </item>
    <item>
      <title>Redis AOF</title>
      <link>https://www6v.github.io/www6vMiddleware/docs/Redis&#43;%E7%BC%93%E5%AD%98/Redis-%E5%9F%BA%E7%A1%80/%E6%8C%81%E4%B9%85%E5%8C%96/redisAOF/</link>
      <pubDate>Tue, 18 Jan 2022 22:21:15 +0000</pubDate>
      <guid>https://www6v.github.io/www6vMiddleware/docs/Redis&#43;%E7%BC%93%E5%AD%98/Redis-%E5%9F%BA%E7%A1%80/%E6%8C%81%E4%B9%85%E5%8C%96/redisAOF/</guid>
      <description>AOF&#xD;#&#xD;定义[1]&#xD;#&#xD;[AOF不是WAL，是先操作，后记录日志。]&#xA;传统数据库的日志，例如 redo log(重做日志)，记录的是修改后的数据，而AOF里记录的是Redis收到的每一条命令，这些命令是以文本形式保存的。&#xA;AOF 日志正好相反，它是写后日志，“写后”的意思是 Redis 是先执行命令，把数据写入内存，然后才记录日志。&#xA;而写后日志这种方式，就是先让系统执行命令，只有命令能执行成功，才会被记录到日志中，否则，系统就会直接向客户端报错。 所以，Redis 使用写后日志这一方式的一大好处是，可以避免出现记录错误命令的情况。&#xA;AOF 还有一个好处：它是在命令执行后才记录日志，所以不会阻塞当前的写操作。&#xA;AOF 是 写前日志&#xA;两个潜在的风险 [1]&#xD;#&#xD;如果刚执行完一个命令，还没有来得及记日志就宕机了，那么这个命令和相应的数 据就有丢失的风险. AOF 日志也是在主线程中执行的，如果在把日志文件写入磁盘时，磁盘写压力大，就 会导致写盘很慢，进而导致后续的操作也无法执行了. 三种写回策略 [1]&#xD;#&#xD;AOF 配置项 - appendfsync 的三个可选值 Always，同步写回：每个写命令执行完，立马同步地将日志写回磁盘； Everysec，每秒写回：每个写命令执行完，只是先把日志写到 AOF 文件的内存缓冲区，每隔一秒把缓冲区中的内容写入磁盘； No，操作系统控制的写回：每个写命令执行完，只是先把日志写到 AOF 文件的内存缓冲区，由操作系统决定何时将缓冲区内容写回磁盘。 关闭AOF落盘 [2]&#xD;#&#xD;AOF落盘会带来一定写性能损耗，如果将Redis实例应用于纯缓存场景中，对数据持久化没有需求，您可以按照本章节的说明，修改appendonly参数的值，关闭AOF落盘。&#xA;AOF Rewrite过程&#xD;#&#xD;功能 压缩AOF文件的大小&#xA;AOF Rewrite过程 [1] 非阻塞的重写&#xA;一个拷贝，两处日志 [1] 触发机制 [4]&#xA;手动触发 bgrewriteaof 命令 自动触发 AOF文件大小 参考&#xD;#&#xD;《04 | AOF日志:宕机了，Redis如何避免数据丢失?</description>
    </item>
    <item>
      <title>Redis 事务</title>
      <link>https://www6v.github.io/www6vMiddleware/docs/Redis&#43;%E7%BC%93%E5%AD%98/Redis-%E5%9F%BA%E7%A1%80/%E4%BA%8B%E5%8A%A1/redisTransaction/</link>
      <pubDate>Tue, 18 Jan 2022 21:54:01 +0000</pubDate>
      <guid>https://www6v.github.io/www6vMiddleware/docs/Redis&#43;%E7%BC%93%E5%AD%98/Redis-%E5%9F%BA%E7%A1%80/%E4%BA%8B%E5%8A%A1/redisTransaction/</guid>
      <description>事务的 ACID 属性是我们使用事务进行正确操作的基本要求。&#xA;Redis 的事务机制可以保证一致性和隔离性，但是无法保证持久性。&#xA;不过，因为 Redis 本身是内存数据库，持久性并不是一个必须的属性，我们更加关注的还是原子性、 一致性和隔离性这三个属性。&#xA;原子性的情况比较复杂，只有当事务中使用的命令语法有误时，原子性得不到保证，在其它情况下，事务都可以原子性执行。&#xA;事务 是否能保证 一致性 C 能保证 隔离性 I 能保证 原子性 A 能保证(命令语法无误时) 持久性 D 不能保证 【redis cluster 没有事务】&#xA;参考&#xD;#&#xD;31 | 事务机制:Redis能实现ACID属性吗?&#xA;[redis]redis集群不支持事务multi、exec 失效</description>
    </item>
    <item>
      <title>Redis RDB源码</title>
      <link>https://www6v.github.io/www6vMiddleware/docs/Redis&#43;%E7%BC%93%E5%AD%98/Redis-%E5%9F%BA%E7%A1%80/%E6%8C%81%E4%B9%85%E5%8C%96/rdb/</link>
      <pubDate>Wed, 08 Dec 2021 20:28:02 +0000</pubDate>
      <guid>https://www6v.github.io/www6vMiddleware/docs/Redis&#43;%E7%BC%93%E5%AD%98/Redis-%E5%9F%BA%E7%A1%80/%E6%8C%81%E4%B9%85%E5%8C%96/rdb/</guid>
      <description>/// 对应了 Redis 的 save 命 令，会在 save 命令的实现函数 saveCommand(在 rdb.c 文件中)中被调用 /* Save the DB on disk. Return C_ERR on error, C_OK on success. */ int rdbSave(char *filename, rdbSaveInfo *rsi) { char tmpfile[256]; char cwd[MAXPATHLEN]; /* Current working dir path for error messages. */ FILE *fp; rio rdb; int error = 0; snprintf(tmpfile,256,&amp;#34;temp-%d.rdb&amp;#34;, (int) getpid()); fp = fopen(tmpfile,&amp;#34;w&amp;#34;); if (!fp) { char *cwdp = getcwd(cwd,MAXPATHLEN); serverLog(LL_WARNING, &amp;#34;Failed opening the RDB file %s (in server root dir %s) &amp;#34; &amp;#34;for saving: %s&amp;#34;, filename, cwdp ?</description>
    </item>
    <item>
      <title>Redis AOF Rewrite</title>
      <link>https://www6v.github.io/www6vMiddleware/docs/Redis&#43;%E7%BC%93%E5%AD%98/Redis-%E5%9F%BA%E7%A1%80/%E6%8C%81%E4%B9%85%E5%8C%96/aofRewrite/</link>
      <pubDate>Sun, 21 Nov 2021 19:35:54 +0000</pubDate>
      <guid>https://www6v.github.io/www6vMiddleware/docs/Redis&#43;%E7%BC%93%E5%AD%98/Redis-%E5%9F%BA%E7%A1%80/%E6%8C%81%E4%B9%85%E5%8C%96/aofRewrite/</guid>
      <description>一. AOF 重写函数与触发时机&#xD;#&#xD;我们就了解了 AOF 重写的四个触发时机，这里我也给你总结下，方便你回 顾复习。&#xA;时机一:bgrewriteaof 命令被执行。&#xD;#&#xD;时机二:主从复制完成 RDB 文件解析和加载(无论是否成功)。&#xD;#&#xD;而对于 restartAOFAfterSYNC 函数来说，它会在主从节点的复制过程中被调用。简单来 说，就是当主从节点在进行复制时，如果从节点的 AOF 选项被打开，那么在加载解析 RDB 文件时，AOF 选项就会被关闭。然后，无论从节点是否成功加载了 RDB 文件， restartAOFAfterSYNC 函数都会被调用，用来恢复被关闭的 AOF 功能。&#xD;那么在这个过程中，restartAOFAfterSYNC 函数就会调用 startAppendOnly 函数，并进 一步调用 rewriteAppendOnlyFileBackground 函数，来执行一次 AOF 重写。&#xD;时机三:AOF 重写被设置为待调度执行。&#xD;#&#xD;时机四:AOF 被启用，同时 AOF 文件的大小比例超出阈值，以及 AOF 文件的大小绝对 值超出阈值。&#xD;#&#xD;auto-aof-rewrite-percentage:AOF 文件大小超出基础大小的比例，默认值为 100%，即超出 1 倍大小。 auto-aof-rewrite-min-size:AOF 文件大小绝对值的最小值，默认为 64MB。&#xA;另外，这里你还需要注意，在这四个时机下，其实都不能有正在执行的 RDB 子进程和 AOF 重写子进程，否则的话，AOF 重写就无法执行了。&#xA;二. AOF 重写的基本过程&#xD;#&#xD;int rewriteAppendOnlyFileBackground(void) { .</description>
    </item>
    <item>
      <title>Redis RDB</title>
      <link>https://www6v.github.io/www6vMiddleware/docs/Redis&#43;%E7%BC%93%E5%AD%98/Redis-%E5%9F%BA%E7%A1%80/%E6%8C%81%E4%B9%85%E5%8C%96/redisRDB/</link>
      <pubDate>Sat, 02 Jan 2021 21:41:43 +0000</pubDate>
      <guid>https://www6v.github.io/www6vMiddleware/docs/Redis&#43;%E7%BC%93%E5%AD%98/Redis-%E5%9F%BA%E7%A1%80/%E6%8C%81%E4%B9%85%E5%8C%96/redisRDB/</guid>
      <description>&#xA;RDB&#xD;#&#xD;功能 [1]&#xD;#&#xD;只需要把 RDB 文件直接读入内存，可以快速恢复数据库。这就避免了 AOF 需要顺序、逐一重新执行操作命令带来的低效性能问题。&#xA;Redis 设计了 bgsave 和写时复制方式，尽可能减少了内存快照对正常读写的影响，但是，频繁快照仍然是不太能接受的。&#xA;【 总结: bgsave 异步 + 写时复制（copy-on-write）】&#xA;触发机制 [2]&#xD;#&#xD;手动触发 bgsave [3] save 废弃 [3] 自动触发 save的相关配置 从节点全量复制，主节点执行bgsave生成RDB并发送给从节点 其他 优点/缺点[2]&#xD;#&#xD;优点 加载RDB恢复数据远远快于AOF的方式 缺点 没办法做到实时持久化 建议 [1]&#xD;#&#xD;数据不能丢失时，内存快照和 AOF 的混合使用是一个很好的选择； 如果允许分钟级别的数据丢失，可以只使用 RDB； 如果只用 AOF，优先使用 everysec 的配置选项，因为它在可靠性和性能之间取了一个平衡。 参考&#xD;#&#xD;《05丨内存快照：宕机后，Redis如何实现快速恢复？》 《redis开发与运维》 第5章 {% post_link &amp;lsquo;rdb&amp;rsquo; %} self </description>
    </item>
  </channel>
</rss>
