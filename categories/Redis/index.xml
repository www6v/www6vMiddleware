<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Redis on 中间件</title>
    <link>https://www6v.github.io/www6vMiddleware/categories/Redis/</link>
    <description>Recent content in Redis on 中间件</description>
    <generator>Hugo</generator>
    <language>en</language>
    <lastBuildDate>Mon, 10 Jul 2023 15:48:29 +0000</lastBuildDate>
    <atom:link href="https://www6v.github.io/www6vMiddleware/categories/Redis/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Redis LazyFree</title>
      <link>https://www6v.github.io/www6vMiddleware/docs/Redis&#43;%E7%BC%93%E5%AD%98/Redis-%E5%9F%BA%E7%A1%80/%E8%B5%84%E6%BA%90%E5%9B%9E%E6%94%B6/redisLazyFree/</link>
      <pubDate>Wed, 01 Jun 2022 10:46:16 +0000</pubDate>
      <guid>https://www6v.github.io/www6vMiddleware/docs/Redis&#43;%E7%BC%93%E5%AD%98/Redis-%E5%9F%BA%E7%A1%80/%E8%B5%84%E6%BA%90%E5%9B%9E%E6%94%B6/redisLazyFree/</guid>
      <description>场景 [1]&#xD;#&#xD;场景一：客户端执行的显示删除/清除命令，比如 del，flushdb 等； 场景二：某些指令带有的隐式删除命令，比如 move , rename 等； 场景三：到达过期时间的数据需要删除； 场景四：使用内存达到 maxmemory 后被选出来要淘汰的数据需要删除； 场景五：在主从同步全量同步阶段，从库收到主库的 RDB 文件后要先删除现有的数据再加载 RDB 文件； 相关配置&#xD;#&#xD;惰性删除相 关的配置项 lazyfree-lazy-eviction：对应缓存淘汰时的数据删除场景。 lazyfree-lazy-expire：对应过期 key 的删除场景。 lazyfree-lazy-server-del：对应会隐式进行删除操作的 server 命令执行场景。 replica-lazy-flush：对应从节点完成全量同步后，删除原有旧数据的场景。 源代码&#xD;#&#xD;evict.c int freeMemoryIfNeeded(void) { /*......*/ /* Finally remove the selected key. */ if (bestkey) { db = server.db+bestdbid; robj *keyobj = createStringObject(bestkey,sdslen(bestkey)); propagateExpire(db,keyobj,server.lazyfree_lazy_eviction); ### 1 /* We compute the amount of memory freed by db*Delete() alone.</description>
    </item>
    <item>
      <title>Redis 使用场景UseCase</title>
      <link>https://www6v.github.io/www6vMiddleware/docs/Redis&#43;%E7%BC%93%E5%AD%98/Redis-%E5%BA%94%E7%94%A8/redisUseCase/</link>
      <pubDate>Tue, 29 Jun 2021 21:21:30 +0000</pubDate>
      <guid>https://www6v.github.io/www6vMiddleware/docs/Redis&#43;%E7%BC%93%E5%AD%98/Redis-%E5%BA%94%E7%94%A8/redisUseCase/</guid>
      <description>缓存 分布式锁 计数器 限流 购物车 用户消息时间线timeline 消息队列 点赞、签到、打卡 商品标签 用户关注、推荐模型 排行榜 参考&#xD;#&#xD;Redis 16 个常见的使用场景</description>
    </item>
    <item>
      <title>Redis Rehash机制</title>
      <link>https://www6v.github.io/www6vMiddleware/docs/Redis&#43;%E7%BC%93%E5%AD%98/Redis-%E5%9F%BA%E7%A1%80/%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B/redisRehash/</link>
      <pubDate>Sun, 20 Jun 2021 22:50:50 +0000</pubDate>
      <guid>https://www6v.github.io/www6vMiddleware/docs/Redis&#43;%E7%BC%93%E5%AD%98/Redis-%E5%9F%BA%E7%A1%80/%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B/redisRehash/</guid>
      <description>&#xA;什么时候触发 rehash？&#xD;#&#xD;，_dictExpandIfNeeded 函数中定义了三个扩容条件。 下面的代码就展示了 _dictExpandIfNeeded 函数对这三个条件的定义，你可以看下。 条件一：ht[0]的大小为 0。 条件二：ht[0]承载的元素个数已经超过了 ht[0]的大小，同时 Hash 表可以进行扩容。 条件三：ht[0]承载的元素个数，是 ht[0]的大小的 dict_force_resize_ratio 倍，其中， dict_force_resize_ratio 的默认值是 5。&#xA;rehash 扩容扩多大？&#xD;#&#xD;对 Hash表扩容的思路也很简单，就是如果当前表的已用空间大小为 size，那么就将表扩容到 size*2 的大小。&#xA;rehash 如何执行？&#xD;#&#xD;其实这是因为，Hash 表在执行 rehash 时，由于 Hash 表空间扩大，原本映射到某一位置 的键可能会被映射到一个新的位置上，因此，很多键就需要从原来的位置拷贝到新的位 置。而在键拷贝时，由于 Redis 主线程无法执行其他请求，所以键拷贝会阻塞主线程，这 样就会产生 rehash 开销。&#xA;而为了降低 rehash 开销，Redis 就提出了渐进式 rehash 的方法。&#xA;dictRehash 的主要执行流程&#xD;#&#xD;</description>
    </item>
    <item>
      <title>Redis 架构 *</title>
      <link>https://www6v.github.io/www6vMiddleware/docs/Redis&#43;%E7%BC%93%E5%AD%98/Redis-%E5%9F%BA%E7%A1%80/Arch-Redis-Cluster/redisArch/</link>
      <pubDate>Tue, 25 May 2021 18:35:49 +0000</pubDate>
      <guid>https://www6v.github.io/www6vMiddleware/docs/Redis&#43;%E7%BC%93%E5%AD%98/Redis-%E5%9F%BA%E7%A1%80/Arch-Redis-Cluster/redisArch/</guid>
      <description>目录&#xD;#&#xD;Redis架构演进[1]&#xD;#&#xD;数据怕丢失 -&amp;gt; 持久化（RDB/AOF） 恢复时间久 -&amp;gt; 主从副本（副本随时可切） 故障手动切换慢 -&amp;gt; 哨兵集群（自动切换） 读存在压力 -&amp;gt; 扩容副本（读写分离） 写存在压力/容量瓶颈 -&amp;gt; 分片集群 分片集群社区方案 -&amp;gt; Twemproxy、Codis（Redis 节点之间无通信，需要部署哨兵，可横向扩容） 分片集群官方方案 -&amp;gt; Redis Cluster （Redis 节点之间 Gossip 协议，无需部署哨兵，可横向扩容） 业务侧升级困难 -&amp;gt; Proxy + Redis Cluster（不侵入业务侧） 主从架构&#xD;#&#xD;主从同步 异步方式来同步数据 最终一致性 分类 增量同步 （同步的是指令） 1.指令记录在master本地的内存 buffer 2.异步将 buffer 中的指令同步到从节点 类似 AOF 快照同步（同步的是内容，全量同步） bgsave存磁盘rdb，然后rdb发到slave，slave装载 优化: 2.8.18 版开始支持无盘复制 哨兵集群 sentinel&#xD;#&#xD;master-slave异步复制, 所以会丢消息&#xA;参数: # 至少有一个slave复制 min-slaves-to-write 1 # slave节点最大10s的延迟 min-slaves-max-lag 10 Redis cluster&#xD;#&#xD;整体架构</description>
    </item>
    <item>
      <title>Redis 大Key *</title>
      <link>https://www6v.github.io/www6vMiddleware/docs/Redis&#43;%E7%BC%93%E5%AD%98/Redis-%E6%95%85%E9%9A%9C%E4%BC%98%E5%8C%96/%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98/redisBigKey/</link>
      <pubDate>Fri, 21 May 2021 07:33:33 +0000</pubDate>
      <guid>https://www6v.github.io/www6vMiddleware/docs/Redis&#43;%E7%BC%93%E5%AD%98/Redis-%E6%95%85%E9%9A%9C%E4%BC%98%E5%8C%96/%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98/redisBigKey/</guid>
      <description>Redis 大Key&#xD;#&#xD;什么是 Bigkey [5]&#xD;#&#xD;【字符串类型】： 单个string类型的value值超过1MB，就可以认为是Bigkey。 【非字符串类型】：哈希、列表、集合、有序集合等， 它们的元素个数超过2000个，就可以认为是Bigkey。&#xA;问题&#xD;#&#xD;问题1 [1]&#xA;大key在数据迁移[遇到过]、扩容、删除[遇到过]时会有卡顿。 问题2 [3]&#xA;执行大key命令的客户端本身，耗时明显增加，甚至超时 执行大key相关读取或者删除操作时，会严重占用带宽和CPU，影响其他客户端 大key本身的存储带来分布式系统中分片数据不平衡，CPU使用率也不平衡 大key有时候也是热key，读取操作频繁，影响面会很大 执行大key删除时，在低版本redis中可能阻塞线程 [遇到过] 建议 [6]&#xD;#&#xD;bigKey 容量&#xA;string类型控制在10KB以内 hash、list、set、zset元素个数不要超过5000 非字符串的bigkey，不要使用del删除，使用hscan、sscan、zscan方式渐进式删除&#xA;防止bigkey过期时间自动删除问题(例如一个200万的zset设置1小时过期，会触发del操作，造成阻塞，而且该操作不会不出现在慢查询中(latency可查))，查找方法和删除方法&#xA;查找 大Key&#xD;#&#xD;&amp;ndash;bigkeys参数, 用scan扫描大key [1][2][5] $ redis-cli --bigkeys # Scanning the entire keyspace to find biggest keys as well as # average sizes per key type. You can use -i 0.1 to sleep 0.1 sec # per 100 SCAN commands (not usually needed).</description>
    </item>
    <item>
      <title>Redis 总结 *</title>
      <link>https://www6v.github.io/www6vMiddleware/docs/Redis&#43;%E7%BC%93%E5%AD%98/Redis-%E5%9F%BA%E7%A1%80/overview/redis/</link>
      <pubDate>Sat, 12 Nov 2016 23:29:16 +0000</pubDate>
      <guid>https://www6v.github.io/www6vMiddleware/docs/Redis&#43;%E7%BC%93%E5%AD%98/Redis-%E5%9F%BA%E7%A1%80/overview/redis/</guid>
      <description>事务&#xD;#&#xD;- 原子性 一致性 隔离性 持久性 redis 一定的原子性，但不支持回滚 × √ 通过一定策略可以保证持久性 redis 没有进行回滚，不具备原子性.操作之后写AOF日志 aof可以保证，但从应用层看没有回滚和原子性，所以并不能保证一致性 单线程天然隔离 纯内存(×)RDB Bgsave(√) RDB 异步执行(×) mysql √ √ √ √ mysql undo log 锁 锁 redo log hash命令&#xD;#&#xD;redis hash的结构：一维数组+二维链表（和java的hashmap结构一样）&#xA;redis rehash: 渐进式rehash Java rehash： 一次性将旧数组下挂接的元素全部转移到新数组下面&#xA;IO模型和性能&#xD;#&#xD;非阻塞IO： read， write时不阻塞&#xA;事件轮询和多路复用[8]&#xA;redis性能 最低配置: 4GB， 2核， 链接数2w， QPS 16w&#xA;redis性能高的原因&#xA;高效的数据结构 多路复用IO模型 事件机制 总结:Reactor + 队列 [10] 大体上可以说 Redis 的工作模式是，reactor 模式配合一个队列，用一个 serverAccept 线程来处理建立请求的链接， 并且通过 IO 多路复用模型，让内核来监听这些 socket，一旦某些 socket 的读写事件准备就绪后就对应的事件压入队列中， 然后 worker 工作，由文件事件分派器从中获取事件交于对应的处理器去执行，当某个事件执行完成后文件事件分派器才会从队列中获取下一个事件进行处理。 可以类比在 netty 中，我们一般会设置 bossGroup 和 workerGroup 默认情况下 bossGroup 为 1，workerGroup = 2 * cpu 数量， 这样可以由多个线程来处理读写就绪的事件，但是其中不能有比较耗时的操作如果有的话需要将其放入线程池中，不然会降低其吐吞量。 在 Redis 中我们可以看做这二者的值都是 1。</description>
    </item>
    <item>
      <title>Redis 分布式锁</title>
      <link>https://www6v.github.io/www6vMiddleware/docs/%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81/redisDistKey/</link>
      <pubDate>Thu, 05 May 2022 14:56:48 +0000</pubDate>
      <guid>https://www6v.github.io/www6vMiddleware/docs/%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81/redisDistKey/</guid>
      <description>一. 基于redis的分布式锁&#xD;#&#xD;锁的特性:&#xD;#&#xD;排它性 超时释放锁 redis expire 高可用，锁集群容错[图2]， 安全性[7]， 可重入锁, 避免死锁[8] 乐观锁, 悲观锁[10][图2] 参考：&#xD;#&#xD;分布式系统互斥性与幂等性问题的分析与解决 点评 蒋谞 漫画：什么是分布式锁？ 程序员小灰 《从Paxos到Zookeeper分布式一致性原理与实践》 倪超 6.1.7节 Redlock：Redis分布式锁最牛逼的实现 阿飞的博客 SOFAJRaft-RheaKV 分布式锁实现剖析 | SOFAJRaft 实现原理 SOFALab 米麒麟 未 Go to Page self 分布式服务总结 分布式锁&#xA;通过栅栏(fencing)使得锁更安全, fencing token How to do distributed locking Martin Kleppmann Redis实现分布式锁，以及可重入锁思路&#xA;唯一id I. uuid II. 分布式线程中标识唯一线程：MAC地址 + jvm进程ID + 线程ID Redis分布式锁实现秒杀业务(乐观锁、悲观锁) 最后 乐观锁: jedis的watch方法 from redis 《Redis 深度历险：核心原理与应用实践》 钱文品 3.</description>
    </item>
    <item>
      <title>Redis Error-MOVED和ASK指令</title>
      <link>https://www6v.github.io/www6vMiddleware/docs/Redis&#43;%E7%BC%93%E5%AD%98/Redis-%E5%9F%BA%E7%A1%80/Arch-Redis-Cluster/redisError/</link>
      <pubDate>Mon, 28 Mar 2022 10:47:56 +0000</pubDate>
      <guid>https://www6v.github.io/www6vMiddleware/docs/Redis&#43;%E7%BC%93%E5%AD%98/Redis-%E5%9F%BA%E7%A1%80/Arch-Redis-Cluster/redisError/</guid>
      <description>{% details 相关代码 %} cluster.c&#xA;/* Return the pointer to the cluster node that is able to serve the command. * For the function to succeed the command should only target either: * * 1) A single key (even multiple times like LPOPRPUSH mylist mylist). * 2) Multiple keys in the same hash slot, while the slot is stable (no * resharding in progress). * * On success the function returns the node that is able to serve the request.</description>
    </item>
    <item>
      <title>Redis 的IO模型</title>
      <link>https://www6v.github.io/www6vMiddleware/docs/Redis&#43;%E7%BC%93%E5%AD%98/Redis-%E5%9F%BA%E7%A1%80/overview/redisIO/</link>
      <pubDate>Tue, 18 Jan 2022 21:28:08 +0000</pubDate>
      <guid>https://www6v.github.io/www6vMiddleware/docs/Redis&#43;%E7%BC%93%E5%AD%98/Redis-%E5%9F%BA%E7%A1%80/overview/redisIO/</guid>
      <description>关键词： 单线程，事件， socket， 多路复用&#xD;#&#xD;Redis 的IO模型&#xD;#&#xD;Redis 是单线程，主要是指 Redis 的网络 IO 和键值对读写是由一个线程来完成的，这也是 Redis 对外提供键值存储服务的主要流程。 但 Redis 的其他功能，比如持久化、异步删除、集群数据同步等，其实是由额外的线程执 行的。&#xA;多路复用&#xD;#&#xD;Linux 中的 IO 多路复用机制是指一个线程处理多个 IO 流，就是我们经常听到的 select/epoll 机制。简单来说，在 Redis 只运行单线程的情况下，该机制允许内核中，同 时存在多个监听套接字和已连接套接字。内核会一直监听这些套接字上的连接请求或数据 请求。一旦有请求到达，就会交给 Redis 线程处理，这就实现了一个 Redis 线程处理多个 IO 流的效果。&#xA;为了在请求到达时能通知到 Redis 线程，select/epoll 提供了基于事件的回调机制，即针 对不同事件的发生，调用相应的处理函数。&#xA;epoll的API&#xD;#&#xD;int epoll_create(int size); int epoll_ctl(int epfd, int op, int fd, struct epoll_event *event); // 事件注册 int epoll_wait(int epfd, struct epoll_event * events, int maxevents, int timeout); // 事件分配、事件处理</description>
    </item>
    <item>
      <title>Redis 回收策略</title>
      <link>https://www6v.github.io/www6vMiddleware/docs/Redis&#43;%E7%BC%93%E5%AD%98/Redis-%E5%9F%BA%E7%A1%80/%E8%B5%84%E6%BA%90%E5%9B%9E%E6%94%B6/redisDelete/</link>
      <pubDate>Wed, 02 Jun 2021 11:42:46 +0000</pubDate>
      <guid>https://www6v.github.io/www6vMiddleware/docs/Redis&#43;%E7%BC%93%E5%AD%98/Redis-%E5%9F%BA%E7%A1%80/%E8%B5%84%E6%BA%90%E5%9B%9E%E6%94%B6/redisDelete/</guid>
      <description>&#xA;回收策略&#xD;#&#xD;回收策略 redis kafka 基于时间 过期删除策略 1. 定时删除(对内存最友好， 对CPU时间最不友好) 2. 惰性删除(对CPU时间最友好， 对内存最不友好) 3.定期删除(整合和折中) 基于大小 内存淘汰策略 1. noeviction 2.lru 3. random 4. ttl 其他 x 近似LRU算法[11] 参考&#xD;#&#xD;七问Redis，才知道我与技术大牛的差距在哪里 ***&#xA;经典面试题：Redis 内存满了怎么办？&#xA;回收策略&#xD;#&#xD;Redis内存回收机制，把我整懵了&amp;hellip; Kafka日志清理之Log Deletion 《Redis 开发与运维》 8.2.3 未 </description>
    </item>
    <item>
      <title>Redis 优化建议</title>
      <link>https://www6v.github.io/www6vMiddleware/docs/Redis&#43;%E7%BC%93%E5%AD%98/Redis-%E6%95%85%E9%9A%9C%E4%BC%98%E5%8C%96/%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98/redisOptimize/</link>
      <pubDate>Mon, 24 May 2021 16:12:00 +0000</pubDate>
      <guid>https://www6v.github.io/www6vMiddleware/docs/Redis&#43;%E7%BC%93%E5%AD%98/Redis-%E6%95%85%E9%9A%9C%E4%BC%98%E5%8C%96/%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98/redisOptimize/</guid>
      <description>&#xA;优化建议&#xD;#&#xD;优化建议[2]&#xD;#&#xD;对象内存优化&#xA;客户端缓冲优化&#xA;碎片优化&#xA;子进程内存优化&#xA;序列化 + 压缩 Renault（序列化： Json or Hession，压缩： Hession自带压缩 ）&#xA;参考&#xD;#&#xD;加餐（六）| Redis的使用规范小建议 Redis 内存优化在 vivo 的探索与实践 vivo </description>
    </item>
    <item>
      <title>Redis数据结构</title>
      <link>https://www6v.github.io/www6vMiddleware/docs/Redis&#43;%E7%BC%93%E5%AD%98/Redis-%E5%9F%BA%E7%A1%80/%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B/redisDataStructure/</link>
      <pubDate>Wed, 05 May 2021 22:25:55 +0000</pubDate>
      <guid>https://www6v.github.io/www6vMiddleware/docs/Redis&#43;%E7%BC%93%E5%AD%98/Redis-%E5%9F%BA%E7%A1%80/%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B/redisDataStructure/</guid>
      <description>数据结构和实现&#xD;#&#xD;数据结构 基础 优化 特点 String SDS List 双向列表 压缩列表 Hash hash表 压缩列表 渐进式rehash SortedSet 跳表 压缩列表 Set 整数数组 全局hash表 &amp;amp;&amp;amp; 渐进式 rehash&#xD;#&#xD;参考：&#xD;#&#xD;02 | 数据结构:快速的Redis有哪些慢操作?</description>
    </item>
    <item>
      <title>Redis LRU算法</title>
      <link>https://www6v.github.io/www6vMiddleware/docs/Redis&#43;%E7%BC%93%E5%AD%98/Redis-%E5%9F%BA%E7%A1%80/%E8%B5%84%E6%BA%90%E5%9B%9E%E6%94%B6/redisLRU/</link>
      <pubDate>Sat, 16 Jul 2022 16:31:51 +0000</pubDate>
      <guid>https://www6v.github.io/www6vMiddleware/docs/Redis&#43;%E7%BC%93%E5%AD%98/Redis-%E5%9F%BA%E7%A1%80/%E8%B5%84%E6%BA%90%E5%9B%9E%E6%94%B6/redisLRU/</guid>
      <description>LRU 算法的实现&#xD;#&#xD;Redis 对近似 LRU 算法的实现分成了三个部分&#xA;全局 LRU 时钟值的计算&#xD;#&#xD;这部分包括，Redis 源码为了实现近似 LRU 算法的效果，是 如何计算全局 LRU 时钟值的，以用来判断数据访问的时效性；&#xA;全局 LRU 时钟值就是通过 getLRUClock 函数计算得到的。 如果一个数据前后两次访问的时间间隔小于 1 秒，那么这 两次访问的时间戳就是一样的。 serverCron 函数作为时间事件的回调函数，本身会按照一定的频率周期性执行，其频率值 是由 Redis 配置文件 redis.conf 中的 hz 配置项决定的。hz 配置项的默认值是 10，这表 示 serverCron 函数会每 100 毫秒（1 秒 /10 = 100 毫秒）运行一次。 这样，在 serverCron 函数中，全局 LRU 时钟值就会按照这个函数的执行频率，定期调用 getLRUClock 函数进行更新，如下所示：&#xA;int serverCron(struct aeEventLoop *eventLoop, long long id, void *clientData) ... unsigned long lruclock = getLRUClock(); //默认情况下，每100毫秒调用getLRUClock函数更 atomicSet(server.</description>
    </item>
    <item>
      <title>Redis Cluster</title>
      <link>https://www6v.github.io/www6vMiddleware/docs/Redis&#43;%E7%BC%93%E5%AD%98/Redis-%E5%9F%BA%E7%A1%80/Arch-Redis-Cluster/redisCluster/</link>
      <pubDate>Mon, 11 Jul 2022 06:45:41 +0000</pubDate>
      <guid>https://www6v.github.io/www6vMiddleware/docs/Redis&#43;%E7%BC%93%E5%AD%98/Redis-%E5%9F%BA%E7%A1%80/Arch-Redis-Cluster/redisCluster/</guid>
      <description>目录&#xD;#&#xD;Cluster 功能 [1.1]&#xD;#&#xD;Redis Cluster支持多个master，每个master又可以挂载多个slave&#xA;读写分离 支持数据的高可用 故障转移， 高可用 由于Cluster自带Sentinel的故障转移机制，内置了高可用的支持， 无需再去使用哨兵功能&#xA;由对应的集群来负责维护节点、插槽和数据之间的关系&#xA;Slot&#xD;#&#xD;Redis集群有16384个哈希槽每个key通过CRC16校验后对16384取模来决定放置哪个槽，集群的每个节点负责一部分hash槽.&#xA;分片方式&#xD;#&#xD;crc（key）% 16384 映射关系&#xD;#&#xD;key （→ CRC） 分片 分片 (→ 映射关系) 实例&#xA;slot分配&#xD;#&#xD;自动分配slot create() 手动分配slot meet() addSlot() 指令&#xD;#&#xD;MOVED指令， ASK 指令 最大槽数是16384的原因 [1.3]&#xD;#&#xD;[ redis 作者解答] why redis-cluster use 16384 slots? #2576 antirez&#xA;[中文翻译] 正常的心跳数据包带有节点的完整配置，可以用幂等方式用旧的节点替换旧节点，以便更新旧的配置。 这意味着它们包含原始节点的插槽配置，该节点使用2k的空间和16k的插槽，但是会使用8k的空间（使用65k的插槽）。同时，由于其他设计折衷，Redis集群不太可能扩展到1000个以上的主节点。 因此16k处于正确的范围内，以确保每个主机具有足够的插槽，最多可容纳1000个矩阵，但数量足够少，可以轻松地将插槽配置作为原始位图传播。请注意，在小型群集中，位图将难以压缩，因为当N较小时，位图将设置的slot / N位占设置位的很大百分比。&#xA;[解读]&#xA;消息头太大， 发送的心跳包过于庞大 如果槽位为65536，发送心跳信息的消息头达8k，发送的心跳包过于庞大。 在消息头中最占空间的是myslots[CLUSTER_SLOTS/8]。当槽位为65536时，这块的大小是:65536÷8÷1024=8kb&#xA;在消息头中最占空间的是myslots[CLUSTER_SLOTS/8]。当槽位为16384时，这块的大小是:16384∶8∶1024=2kb</description>
    </item>
    <item>
      <title>Redis SLO</title>
      <link>https://www6v.github.io/www6vMiddleware/docs/Redis&#43;%E7%BC%93%E5%AD%98/Redis-%E5%BA%94%E7%94%A8/redisSLO/</link>
      <pubDate>Wed, 27 Apr 2022 21:54:37 +0000</pubDate>
      <guid>https://www6v.github.io/www6vMiddleware/docs/Redis&#43;%E7%BC%93%E5%AD%98/Redis-%E5%BA%94%E7%94%A8/redisSLO/</guid>
      <description>&#xA;SLO&#xD;#&#xD;命中率 Hit Ratio 每秒命中数量 每秒未命中数量 吞吐 Throughput 操作数 延迟 命令执行平均耗时 容量 expiring/not expiring keys expired/evicted keys 内存使用率 Memory Utilization 活动连接数 Active Connections 参考&#xD;#&#xD;部署一个redis exporter监控所有的Redis实例 6 Crucial Redis Monitoring Metrics You Need To Watch </description>
    </item>
    <item>
      <title>Redis雪崩、击穿、穿透 *</title>
      <link>https://www6v.github.io/www6vMiddleware/docs/Redis&#43;%E7%BC%93%E5%AD%98/Redis-%E6%95%85%E9%9A%9C%E4%BC%98%E5%8C%96/%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98/redisReliability-1/</link>
      <pubDate>Mon, 28 Mar 2022 22:00:34 +0000</pubDate>
      <guid>https://www6v.github.io/www6vMiddleware/docs/Redis&#43;%E7%BC%93%E5%AD%98/Redis-%E6%95%85%E9%9A%9C%E4%BC%98%E5%8C%96/%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98/redisReliability-1/</guid>
      <description>&#xA;问题&amp;amp;方案 [1]&#xD;#&#xD;“有损”方案&#xD;#&#xD;服务熔断、服务降级、请求限流这些方法都是属于**“有损”方案**，在保证数据库和整体系统稳定的同时，会对业务应用带来负面影响。 预防式方案&#xD;#&#xD;建议是，尽量使用预防式方案 针对缓存雪崩，合理地设置数据过期时间，以及搭建高可靠缓存集群； 针对缓存击穿，在缓存访问非常频繁的热点数据时，不要设置过期时间； 针对缓存穿透，提前在入口前端实现恶意请求检测，或者规范数据库的数据删除操作，避免误删除。 缓存击穿&#xD;#&#xD;缓存击穿 原因&#xD;#&#xD;热点数据过期 大量并发请求&#xA;解决方案&#xD;#&#xD;唯一DB请求，共享结果 分布式锁&#xA;缓存穿透&#xD;#&#xD;原因&#xD;#&#xD;指缓存和数据库中都没有的数据，而用户不断发起请求，如发起为id为“-1”的数据或id为特别大不存在的数据。 提交不在数据库中的查询，会击穿缓存，直接到达数据库。&#xA;解决方案&#xD;#&#xD;回种空值 使用bloomfilter 缓存穿透-狗桩效应[3]&#xD;#&#xD;原因&#xD;#&#xD;当有一个极热点的缓存项，它一旦失效会有大量请求穿透到数据库，这会对数据库造成瞬时极大的压力，我们把这个场景叫做**“dog-pile effect”（狗桩效应）**&#xA;解决方案&#xD;#&#xD;后台线程定时加载 在代码中，控制在某一个热点缓存项失效之后启动一个后台线程，穿透到数据库，将数 据加载到缓存中，在缓存未加载之前，所有访问这个缓存的请求都不再穿透而直接返回。&#xA;设置分布式锁 通过在 Memcached 或者 Redis 中设置分布式锁，只有获取到锁的请求才能够穿透到数 据库。&#xA;参考&#xD;#&#xD;《26丨缓存异常（下）：如何解决缓存雪崩、击穿、穿透难题？》 【直播回放】海量并发微服务框架设计 V 《15 | 缓存的使用姿势（三）：缓存穿透了怎么办？》 </description>
    </item>
    <item>
      <title>Redis Cluster Spec</title>
      <link>https://www6v.github.io/www6vMiddleware/docs/Redis&#43;%E7%BC%93%E5%AD%98/Redis-%E5%9F%BA%E7%A1%80/Arch-Redis-Cluster/redisClusterSpec/</link>
      <pubDate>Mon, 11 Jul 2022 13:15:05 +0000</pubDate>
      <guid>https://www6v.github.io/www6vMiddleware/docs/Redis&#43;%E7%BC%93%E5%AD%98/Redis-%E5%9F%BA%E7%A1%80/Arch-Redis-Cluster/redisClusterSpec/</guid>
      <description>目录&#xD;#&#xD;设计目标和基本原理[bing]&#xD;#&#xD;高性能和线性扩展&#xD;#&#xD;Redis集群可以支持到1000个节点，使用异步复制和无代理的架构，避免了值合并的开销。&#xA;可接受的写安全性&#xD;#&#xD;Redis集群尽力保留与大多数主节点连接的客户端的写操作，但在分区窗口期内可能会丢失已确认的写操作。&#xA;可用性&#xD;#&#xD;Redis集群可以在大多数主节点可达且每个不可达主节点至少有一个可达副本的情况下存活，并且可以通过副本迁移来提高抗故障能力。&#xA;哈希槽分配&#xD;#&#xD;Redis集群将16384个哈希槽分配给不同的主节点，每个主节点负责存储和服务一部分哈希槽。客户端可以通过计算键的CRC16值对16384取模来得到对应的哈希槽。也可以使用哈希标签来强制将多个键分配到同一个哈希槽，以支持多键操作。&#xA;节点间通信&#xD;#&#xD;Redis集群节点之间使用一个TCP端口和一个二进制协议进行通信，称为集群总线。每个节点都与其他所有节点连接，使用gossip协议来传播集群的信息，如新节点、故障节点、配置变化等。&#xA;客户端重定向&#xD;#&#xD;Redis集群节点不会代理请求，而是根据自己的哈希槽映射表，将客户端重定向到正确的节点。客户端可能收到MOVED或ASK错误，表示需要重新发送请求到另一个节点。MOVED表示哈希槽被永久地分配给了另一个节点，ASK表示哈希槽正在被迁移，需要发送ASKING命令后再发送请求。&#xA;哈希槽迁移&#xD;#&#xD;Redis集群支持在运行时添加和删除节点，这是通过将哈希槽从一个节点移动到另一个节点来实现的。迁移过程中，源节点会将接收到的关于该哈希槽的请求重定向到目标节点，或者直接处理已存在键的请求。目标节点会接收到源节点通过MIGRATE命令发送过来的键，并在迁移完成后更新自己的配置。&#xA;故障检测和副本提升&#xD;#&#xD;Redis集群使用心跳包和gossip协议来检测节点是否可达，并使用PFAIL和FAIL两种标志来表示故障状态。当一个主节点被大多数主节点标记为FAIL时，它的一个副本会发起选举并请求投票。如果获得了大多数主节点的授权，该副本会提升为主节点，并生成一个新的配置版本号（configEpoch）。&#xA;副本选举和配置传播的机制[bing]&#xD;#&#xD;副本选举&#xD;#&#xD;当一个主节点失效时，它的一个副本会尝试发起选举，向其他主节点发送授权请求。如果获得了大多数主节点的回复，它就赢得了选举，并获得了一个新的唯一的配置版本号（configEpoch）。它会开始以主节点的身份广播心跳包，并通知其他节点更新配置。&#xA;配置传播&#xD;#&#xD;当一个节点收到一个心跳包或UPDATE消息时，它会根据一些规则来更新自己的哈希槽映射表。如果一个哈希槽是未分配的，或者有一个新的节点使用更高的configEpoch来声明它，那么接收者会将该哈希槽绑定到新的节点。这样可以保证最后一次故障转移胜出，并且所有节点最终会达成一致。&#xA;节点重置和遗忘&#xD;#&#xD;当一个节点需要从一个集群中移除或加入到另一个集群时，可以使用CLUSTER RESET命令来重置它的状态。这个命令有两种模式：软重置和硬重置。软重置会保留当前的configEpoch，而硬重置会将其设置为0。当一个节点被移除后，其他节点需要使用CLUSTER FORGET命令来删除它在节点表中的条目，并设置一个60秒的禁止期，防止因为gossip协议而重新添加它。&#xA;发布订阅&#xD;#&#xD;Redis集群支持发布订阅功能，客户端可以向任何节点发送SUBSCRIBE或PUBLISH命令。集群会将发布的消息转发到所有其他节点。Redis 7.0及以后版本还支持分片发布订阅功能，其中分片频道根据与键相同的算法分配到哈希槽。分片消息必须发送到拥有该哈希槽的节点，集群会将发布的分片消息转发到该哈希槽所在的分片中的所有节点。&#xA;CRC16算法&#xD;#&#xD;这篇文章最后给出了计算键对应哈希槽的CRC16算法的C语言实现代码。这个算法使用了1021作为多项式，并且不反转输入输出字节。&#xA;参考&#xD;#&#xD;Redis cluster specification ***</description>
    </item>
    <item>
      <title>Redis和数据库之间的一致性</title>
      <link>https://www6v.github.io/www6vMiddleware/docs/Redis&#43;%E7%BC%93%E5%AD%98/Redis-%E6%95%85%E9%9A%9C%E4%BC%98%E5%8C%96/%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98/redisDbConsistent/</link>
      <pubDate>Mon, 21 Feb 2022 21:23:23 +0000</pubDate>
      <guid>https://www6v.github.io/www6vMiddleware/docs/Redis&#43;%E7%BC%93%E5%AD%98/Redis-%E6%95%85%E9%9A%9C%E4%BC%98%E5%8C%96/%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98/redisDbConsistent/</guid>
      <description>“数据的一致性”含义&#xD;#&#xD;缓存中有数据，那么，缓存的数据值需要和数据库中的值相同； 缓存中本身没有数据，那么，数据库中的值必须是最新值。&#xA;对于“读写缓存”的情况&#xD;#&#xD;如果我们采用同步写回策略，那么可以保证缓存和数据库中的数据一致。 所以，我们要在业务应用中使用事务机制，来保证缓存和数据库的更新具有原子性， 也就是说，两者要不一起更新，要不都不更新，返回错误信息，进行重试。否则，我们就无法实现同步直写。&#xA;对于”只读缓存”的情况&#xD;#&#xD;参考：&#xD;#&#xD;25丨缓存异常（上）：如何解决缓存和数据库的数据不一致问题？</description>
    </item>
    <item>
      <title>Redis 集群  容灾（同城多活）</title>
      <link>https://www6v.github.io/www6vMiddleware/docs/Redis&#43;%E7%BC%93%E5%AD%98/Redis-%E5%9F%BA%E7%A1%80/Arch-Redis-Cluster/redisHA/</link>
      <pubDate>Sun, 31 Jul 2022 11:37:41 +0000</pubDate>
      <guid>https://www6v.github.io/www6vMiddleware/docs/Redis&#43;%E7%BC%93%E5%AD%98/Redis-%E5%9F%BA%E7%A1%80/Arch-Redis-Cluster/redisHA/</guid>
      <description>目录&#xD;#&#xD;1. 背景&#xD;#&#xD;Redis 集群自身已经具备了高可用的特性，即使几个Redis节点异常或者挂掉，Redis 集群也会实现故障自动转移，对应用方来说也可以在很短时间内恢复故障。 但是，如果发生了机房故障(断电、断网等极端情况)，Redis集群节点全部挂掉（过半主节点挂掉），会造成集群服务不可用，对于核心业务来说是不可接受的。 为了应对机房故障情况，保障在这种极端情况下，核心业务仍然可以正常访问 Redis 服务，本文将给出适合我司的 Redis 跨机房高可用解决方案。 2. 目标&#xD;#&#xD;保障单机房整体故障时 Redis 缓存服务正常运行。 单机房故障 RTO：30s，RPO：1s 3. 解决方案&#xD;#&#xD;3.1 核心能力&#xD;#&#xD;客户端流量路由：支持按一定的策略，把流量分流到不同机房；机房故障后，流量自动流向其他机房。 服务端故障转移：支持机房故障后，当前机房原来主节点的从节点，通过选举自动倒换成新的主节点。 管理平台正常服务：任一机房故障，Renault 管理平台使用不受影响。 3.2 工作模式&#xD;#&#xD;组件在机房高可用场景下一般有多种工作模式，典型的有单集群模式及多集群模式。本节描述组件在各种工作模式下的部署方式及工作机制。&#xA;部署方案 方案说明 跨机房混合部署 将Redis集群主节点平均分配到各个机房，主从节点在不同机房 各机房独立部署集群 + 数据单向同步 各机房均独立部署集群，集群为热备模式，写请求均写入同一个集群，然后同步到其他集群 各机房独立部署集群 + 数据双向同步 每个机房部署一套Redis集群，同步核心业务写请求 数据同步方法：&#xA;数据同步方案 方案说明 客户端双写 客户端同时写入到各个集群 客户端代理 Netflix开源实现的Dynomite，通过代理层接受数据后写入各个需要同步的节点&#xA;改造难度大&#xA;客户端需要优化添加Dyno Client服务端每个节点需要部署Dyno Node&#xA;read/write性能较原生差异较大，主要体现在write上，之间的差异随着node节点数越多越严重 伪从节点 基于Redis的Master-Slave复制协议，实现低延时、高可用的Redis多数据中心、跨公网数据复制携程开源系统：https://github.com/ctripcorp/x-pipe阿里RedisShake同步工具 写事件监听+MQ跨集群消息同步 读写在本机房，监听写事件 + MQ消息同步到其他机房需要开启事件通知（PUB），修改Redis配置文件中的 notify-keyspace-events 配置（默认的redis并没有开启这个功能）需要独立服务订阅写事件（SUB），并同步到其他集群依赖MQ组件 不考虑客户端代理、发布订阅写事件</description>
    </item>
    <item>
      <title>Redis 慢查询排查</title>
      <link>https://www6v.github.io/www6vMiddleware/docs/Redis&#43;%E7%BC%93%E5%AD%98/Redis-%E6%95%85%E9%9A%9C%E4%BC%98%E5%8C%96/%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98/redisSlowResponse/</link>
      <pubDate>Fri, 25 Mar 2022 11:59:43 +0000</pubDate>
      <guid>https://www6v.github.io/www6vMiddleware/docs/Redis&#43;%E7%BC%93%E5%AD%98/Redis-%E6%95%85%E9%9A%9C%E4%BC%98%E5%8C%96/%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98/redisSlowResponse/</guid>
      <description>慢查询 排查&#xD;#&#xD;获取 Redis 实例在当前环境下的基线性能。&#xA;是否用了慢查询命令？ 如果是的话，就使用其他命令替代慢查询命令，或者把聚合计算命令放在客户端做。&#xA;是否对过期 key 设置了相同的过期时间？ 对于批量删除的 key，可以在每个 key 的过期时间上加一个随机数，避免同时删除。&#xA;是否存在 bigkey？ 对于 bigkey 的删除操作，如果你的 Redis 是 4.0 及以上的版本，可以直接利用异步线程机制减少主线程阻塞；如果是 Redis 4.0 以前的版本，可以使用SCAN 命令迭代删除；对于 bigkey 的集合查询和聚合操作，可以使用 SCAN 命令在客户端完成。&#xA;Redis AOF 配置级别是什么？业务层面是否的确需要这一可靠性级别？ 如果我们需要高性能，同时也允许数据丢失，可以将配置项 no-appendfsync-on-rewrite 设置为 yes，避免 AOF 重写和 fsync 竞争磁盘 IO 资源，导致 Redis 延迟增加。 如果既需要高性能又需要高可靠性，最好使用高速固态盘作为 AOF 日志的写入盘。&#xA;Redis 实例的内存使用是否过大？发生 swap 了吗？ 如果是的话，就增加机器内存，或者是使用 Redis 集群，分摊单机 Redis 的键值对数量和内存压力。同时，要避免出现Redis 和其他内存需求大的应用共享机器的情况。&#xA;在 Redis 实例的运行环境中，是否启用了透明大页机制？ 如果是的话，直接关闭内存大页机制就行了。&#xA;是否运行了 Redis 主从集群？ 如果是的话，把主库实例的数据量大小控制在 2~4GB，以免主从复制时，从库因加载大的 RDB 文件而阻塞。</description>
    </item>
    <item>
      <title>Redis 热点Hotkey</title>
      <link>https://www6v.github.io/www6vMiddleware/docs/Redis&#43;%E7%BC%93%E5%AD%98/Redis-%E6%95%85%E9%9A%9C%E4%BC%98%E5%8C%96/%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98/redisHotkey/</link>
      <pubDate>Fri, 03 Jun 2022 21:48:24 +0000</pubDate>
      <guid>https://www6v.github.io/www6vMiddleware/docs/Redis&#43;%E7%BC%93%E5%AD%98/Redis-%E6%95%85%E9%9A%9C%E4%BC%98%E5%8C%96/%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98/redisHotkey/</guid>
      <description>HotKey&#xD;#&#xD;寻找热点Key [2]&#xA;客户端 [1] 缺点: 只能统计单个客户端 代理 缺点: 代理端的开发部署成本 服务端 缺点: monitor命令, 短时间用 机器 packetbeat 抓包 缺点: 运维部署和机器成本 解决热点key [2]&#xA;拆分复杂数据结构 迁移热点key 本地缓存加通知机制 [3] 使用二级缓存 [1] 参考&#xD;#&#xD;有赞透明多级缓存解决方案（TMC） 《Redis 开发与运维》 12.5 京东 Redis 热点数据探测工具镜像 京东毫秒级热key探测框架设计与实践，已实战于618大促 热点 Key 问题的发现与解决 阿里 文档 已失效 通常的解决方案主要集中在对客户端和Server端进行相应的改造。 I. 服务端本地缓存. II. 服务端分布式缓存。&#xA;阿里云方案 (整体看是用中间件 负载均衡 水平扩展)&#xA;I. 读写分离方案解决热读 写 热备; 读 存储水平扩展 II. 热点数据解决方案 该方案通过主动发现热点并对其进行存储来解决热点Key的问题。</description>
    </item>
    <item>
      <title>Redis  命中率</title>
      <link>https://www6v.github.io/www6vMiddleware/docs/Redis&#43;%E7%BC%93%E5%AD%98/Redis-%E6%95%85%E9%9A%9C%E4%BC%98%E5%8C%96/%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98/redisHitRate/</link>
      <pubDate>Sun, 31 Jul 2022 17:13:43 +0000</pubDate>
      <guid>https://www6v.github.io/www6vMiddleware/docs/Redis&#43;%E7%BC%93%E5%AD%98/Redis-%E6%95%85%E9%9A%9C%E4%BC%98%E5%8C%96/%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98/redisHitRate/</guid>
      <description>&#xA;命中率不高&#xD;#&#xD;会增加接口响应时间&#xA;提高redis命中率 [3][4]&#xD;#&#xD;缓存粒度 缓存粒度越小，命中率越高 合理调整缓存有效期的时间 避免缓存同时失效 预加载 防止缓存击穿和穿透[5] 增加存储容量 容量不足时会触发Redis内存淘汰机制 清空策略 [6] FIFO(first in first out) LFU(less frequently used) LRU(least recently used) 参考&#xD;#&#xD;如何提高redis缓存命中率 关于如何提高缓存命中率（redis） {% post_link &amp;lsquo;redisReliability-1&amp;rsquo; %} self 缓存那些事 </description>
    </item>
    <item>
      <title>Redis 混合持久化</title>
      <link>https://www6v.github.io/www6vMiddleware/docs/Redis&#43;%E7%BC%93%E5%AD%98/Redis-%E5%9F%BA%E7%A1%80/%E6%8C%81%E4%B9%85%E5%8C%96/redisBothAofAndRDB/</link>
      <pubDate>Mon, 10 Jul 2023 15:48:29 +0000</pubDate>
      <guid>https://www6v.github.io/www6vMiddleware/docs/Redis&#43;%E7%BC%93%E5%AD%98/Redis-%E5%9F%BA%E7%A1%80/%E6%8C%81%E4%B9%85%E5%8C%96/redisBothAofAndRDB/</guid>
      <description>&#xA;Redis 混合持久化&#xD;#&#xD;数据恢复顺序和加载流程 [2][3]&#xD;#&#xD;在这种情况下， 当redis重启的时候会优先载入AOF文件来恢复原始的数据 ，因为在通常情况下AOF文件保存的数据集要比RDB文件保存的数据集要完整。&#xA;RDB和AOF共存时会优先加载AOF文件&#xA;【主从切换 优先加载 RDB -&amp;gt; 速度】 【redis重启 优先加载 AOF -&amp;gt; 数据完整性】&#xA;开启&#xD;#&#xD;aof-use-rdb-preamble no -&amp;gt; yes 原理 [3]&#xD;#&#xD;RDB镜像做全量持久化，AOF做增量持久化 先使用RDB进行快照存储，然后使用AOF持久化记录所有的写操作，当重写策略满足或手动触发重写的时候，将最新的数据存储为新的RDB记录。 这样的话，重启服务的时候会从RDB和AOF两部分恢复数据，既保证了数据完整性，又提高了恢复数据的性能。简单来说:混合持久化方式产生的文件一部分是RDB格式，一部分是AOF格式。&#xA;AOF+RDB混合[1]&#xD;#&#xD;而混合使用 RDB 和 AOF，正好可以取两者之长，避两者之短，以较小的性能开销保证数据可靠性和性能。&#xA;参考&#xD;#&#xD;《05丨内存快照：宕机后，Redis如何实现快速恢复？》 redis++：Redis持久化 rdb &amp;amp; aof 工作原理及流程图 （三） RDB-AOF混合持久化 尚硅谷Redis零基础到进阶，最强redis7教程，阳哥亲自带练（附redis面试题） </description>
    </item>
    <item>
      <title>Redis 主从复制 *</title>
      <link>https://www6v.github.io/www6vMiddleware/docs/Redis&#43;%E7%BC%93%E5%AD%98/Redis-%E5%9F%BA%E7%A1%80/%E6%8C%81%E4%B9%85%E5%8C%96/redisReplica/</link>
      <pubDate>Sun, 10 Jul 2022 19:04:46 +0000</pubDate>
      <guid>https://www6v.github.io/www6vMiddleware/docs/Redis&#43;%E7%BC%93%E5%AD%98/Redis-%E5%9F%BA%E7%A1%80/%E6%8C%81%E4%B9%85%E5%8C%96/redisReplica/</guid>
      <description>&#xA;主从复制流程&#xD;#&#xD;主从库第一次同步的流程&#xD;#&#xD;主从库增量复制流程&#xD;#&#xD;repl_backlog_buffer 是一个环形缓冲区，主库会记录自己写到的位置，从库则会记录自己 已经读到的位置。&#xA;缺点 [3]&#xD;#&#xD;主从延迟 复制偏移量：master_repl_offset | slave_repl_offset master挂了怎么办？ 默认情况下，不会在slave节点中自动选一个master 每次都要人工干预 需要Redis哨兵(sentinel) 参考&#xD;#&#xD;《06 | 数据同步：主从库如何实现数据一致？》 redis主从复制、主从延迟知几何 复制原理和工作流程 61_redis主从复制之工作流程总结 V 62_redis主从复制之痛点和改进需求 V </description>
    </item>
    <item>
      <title>Redis 集群扩容时NodeId问题</title>
      <link>https://www6v.github.io/www6vMiddleware/docs/Redis&#43;%E7%BC%93%E5%AD%98/Redis-%E6%95%85%E9%9A%9C%E4%BC%98%E5%8C%96/redisNodeId/</link>
      <pubDate>Mon, 23 May 2022 09:56:54 +0000</pubDate>
      <guid>https://www6v.github.io/www6vMiddleware/docs/Redis&#43;%E7%BC%93%E5%AD%98/Redis-%E6%95%85%E9%9A%9C%E4%BC%98%E5%8C%96/redisNodeId/</guid>
      <description>1. 背景&#xD;#&#xD;有一次扩容 Redis 集群，往集群加入节点，这个操作了很多次的功能居然失败了。查看到异常日志：addAppClusterSharding:10.3.28.7:10240:10.3.28.70, result is false&#xA;观察发现，Redis实例已启动，并且加入到集群，但是主从角色不正确&#xA;本地调试发现，在从节点执行cluster replicate &amp;lt;master_node_id&amp;gt;报错，提示***，发现命令的&amp;lt;master_node_id&amp;gt;和Redis实例的&amp;lt;node_id&amp;gt;不一致&#xA;Redis node_id是如何生成的，怎么会变化呢？ 临时查看最近修改代码， com.tuhu.renault.portal.redis.impl.RedisCenterImpl getNodeId方法 原来：&#xA;从目标Redis实例获取自己的node_id&#xA;改成了：&#xA;可以从其他Redis实例获取（因为cluster nodes命令可以拿到集群所有节点信息）&#xA;原因是：&#xA;当目标节点挂了，会获取不到node_id，页面操作故障节点下线会失败（用于下线故障节点）&#xA;修复方法：&#xA;临时恢复从目标实例获取自己的node_id;下线故障节点时候从其他节点获取node_id&#xA;下文简单梳理 Redis 集群扩容过程，主要关注 Redis node_id 变化及相关源码。&#xA;2. Redis集群扩容过程梳理&#xD;#&#xD;Renault管理平台入口：&#xA;com.tuhu.renault.portal.controller.ClusterController doAddHorizontalNodes 方法&#xA;主要包括三个步骤：（1）启动 Redis 实例；（2）meet Redis 实例；（3）确定主从角色。 2.1 启动Redis实例&#xD;#&#xD;根据模板生成Redis配置文件，并拷贝到目标机器 执行：redis-server /usr/local/renault/conf/redis-cluster-6379.conf 没有返回值，检测端口被占用则认为成功 2.2 Redis集群所有主节点meet待加入节点&#xD;#&#xD;确定Redis实例为&amp;quot;单身&amp;quot; 执行：cluster meet ，https://redis.io/commands/cluster-meet 返回“OK”即成功 2.3 确定主从角色&#xD;#&#xD;获取主节点NodeId 从节点实例执行：cluster replicate &amp;lt;node_id&amp;gt;，https://redis.io/commands/cluster-replicate 返回“OK”即成功 3. Redis集群扩容期间节点状态&#xD;#&#xD;3.</description>
    </item>
    <item>
      <title>Redis NVM</title>
      <link>https://www6v.github.io/www6vMiddleware/docs/Redis&#43;%E7%BC%93%E5%AD%98/Redis-%E5%9F%BA%E7%A1%80/%E5%85%B6%E4%BB%96/redisNVM/</link>
      <pubDate>Sat, 14 May 2022 20:49:50 +0000</pubDate>
      <guid>https://www6v.github.io/www6vMiddleware/docs/Redis&#43;%E7%BC%93%E5%AD%98/Redis-%E5%9F%BA%E7%A1%80/%E5%85%B6%E4%BB%96/redisNVM/</guid>
      <description>特点&#xD;#&#xD;能持久化保存数据 读写速度和 DRAM 接近 容量大 Intel Optane AEP 内存条(简称 AEP 内存)&#xD;#&#xD;Memory 模式 软件系统能使用到 的内存空间，就是 AEP 内存条的空间容量。 在 Memory 模式时，Redis 可以利用 NVM 容量大的特点，实现大容量实例，保存更 多数据。&#xA;App Direct 模式 使用了 App Direct 模式的 AEP 内存，也叫 做持久化内存(Persistent Memory，PM)。&#xA;Redis 可以直接在持久化内存上进行数据读写，在这 种情况下，Redis 不用再使用 RDB 或 AOF 文件了，数据在机器掉电后也不会丢失。 而且，实例可以直接使用持久化内存上的数据进行恢复，恢复速度特别快。&#xA;参考：&#xD;#&#xD;40 | Redis的下一步:基于NVM内存的实践</description>
    </item>
    <item>
      <title>Redis AOF</title>
      <link>https://www6v.github.io/www6vMiddleware/docs/Redis&#43;%E7%BC%93%E5%AD%98/Redis-%E5%9F%BA%E7%A1%80/%E6%8C%81%E4%B9%85%E5%8C%96/redisAOF/</link>
      <pubDate>Tue, 18 Jan 2022 22:21:15 +0000</pubDate>
      <guid>https://www6v.github.io/www6vMiddleware/docs/Redis&#43;%E7%BC%93%E5%AD%98/Redis-%E5%9F%BA%E7%A1%80/%E6%8C%81%E4%B9%85%E5%8C%96/redisAOF/</guid>
      <description>AOF&#xD;#&#xD;定义[1]&#xD;#&#xD;[AOF不是WAL，是先操作，后记录日志。]&#xA;传统数据库的日志，例如 redo log(重做日志)，记录的是修改后的数据，而AOF里记录的是Redis收到的每一条命令，这些命令是以文本形式保存的。&#xA;AOF 日志正好相反，它是写后日志，“写后”的意思是 Redis 是先执行命令，把数据写入内存，然后才记录日志。&#xA;而写后日志这种方式，就是先让系统执行命令，只有命令能执行成功，才会被记录到日志中，否则，系统就会直接向客户端报错。 所以，Redis 使用写后日志这一方式的一大好处是，可以避免出现记录错误命令的情况。&#xA;AOF 还有一个好处：它是在命令执行后才记录日志，所以不会阻塞当前的写操作。&#xA;AOF 是 写前日志&#xA;两个潜在的风险 [1]&#xD;#&#xD;如果刚执行完一个命令，还没有来得及记日志就宕机了，那么这个命令和相应的数 据就有丢失的风险. AOF 日志也是在主线程中执行的，如果在把日志文件写入磁盘时，磁盘写压力大，就 会导致写盘很慢，进而导致后续的操作也无法执行了. 三种写回策略 [1]&#xD;#&#xD;AOF 配置项 - appendfsync 的三个可选值 Always，同步写回：每个写命令执行完，立马同步地将日志写回磁盘； Everysec，每秒写回：每个写命令执行完，只是先把日志写到 AOF 文件的内存缓冲区，每隔一秒把缓冲区中的内容写入磁盘； No，操作系统控制的写回：每个写命令执行完，只是先把日志写到 AOF 文件的内存缓冲区，由操作系统决定何时将缓冲区内容写回磁盘。 关闭AOF落盘 [2]&#xD;#&#xD;AOF落盘会带来一定写性能损耗，如果将Redis实例应用于纯缓存场景中，对数据持久化没有需求，您可以按照本章节的说明，修改appendonly参数的值，关闭AOF落盘。&#xA;AOF Rewrite过程&#xD;#&#xD;功能 压缩AOF文件的大小&#xA;AOF Rewrite过程 [1] 非阻塞的重写&#xA;一个拷贝，两处日志 [1] 触发机制 [4]&#xA;手动触发 bgrewriteaof 命令 自动触发 AOF文件大小 参考&#xD;#&#xD;《04 | AOF日志:宕机了，Redis如何避免数据丢失?</description>
    </item>
    <item>
      <title>Redis 事务</title>
      <link>https://www6v.github.io/www6vMiddleware/docs/Redis&#43;%E7%BC%93%E5%AD%98/Redis-%E5%9F%BA%E7%A1%80/%E4%BA%8B%E5%8A%A1/redisTransaction/</link>
      <pubDate>Tue, 18 Jan 2022 21:54:01 +0000</pubDate>
      <guid>https://www6v.github.io/www6vMiddleware/docs/Redis&#43;%E7%BC%93%E5%AD%98/Redis-%E5%9F%BA%E7%A1%80/%E4%BA%8B%E5%8A%A1/redisTransaction/</guid>
      <description>事务的 ACID 属性是我们使用事务进行正确操作的基本要求。&#xA;Redis 的事务机制可以保证一致性和隔离性，但是无法保证持久性。&#xA;不过，因为 Redis 本身是内存数据库，持久性并不是一个必须的属性，我们更加关注的还是原子性、 一致性和隔离性这三个属性。&#xA;原子性的情况比较复杂，只有当事务中使用的命令语法有误时，原子性得不到保证，在其它情况下，事务都可以原子性执行。&#xA;事务 是否能保证 一致性 C 能保证 隔离性 I 能保证 原子性 A 能保证(命令语法无误时) 持久性 D 不能保证 【redis cluster 没有事务】&#xA;参考&#xD;#&#xD;31 | 事务机制:Redis能实现ACID属性吗?&#xA;[redis]redis集群不支持事务multi、exec 失效</description>
    </item>
    <item>
      <title>Redis RDB源码</title>
      <link>https://www6v.github.io/www6vMiddleware/docs/Redis&#43;%E7%BC%93%E5%AD%98/Redis-%E5%9F%BA%E7%A1%80/%E6%8C%81%E4%B9%85%E5%8C%96/rdb/</link>
      <pubDate>Wed, 08 Dec 2021 20:28:02 +0000</pubDate>
      <guid>https://www6v.github.io/www6vMiddleware/docs/Redis&#43;%E7%BC%93%E5%AD%98/Redis-%E5%9F%BA%E7%A1%80/%E6%8C%81%E4%B9%85%E5%8C%96/rdb/</guid>
      <description>/// 对应了 Redis 的 save 命 令，会在 save 命令的实现函数 saveCommand(在 rdb.c 文件中)中被调用 /* Save the DB on disk. Return C_ERR on error, C_OK on success. */ int rdbSave(char *filename, rdbSaveInfo *rsi) { char tmpfile[256]; char cwd[MAXPATHLEN]; /* Current working dir path for error messages. */ FILE *fp; rio rdb; int error = 0; snprintf(tmpfile,256,&amp;#34;temp-%d.rdb&amp;#34;, (int) getpid()); fp = fopen(tmpfile,&amp;#34;w&amp;#34;); if (!fp) { char *cwdp = getcwd(cwd,MAXPATHLEN); serverLog(LL_WARNING, &amp;#34;Failed opening the RDB file %s (in server root dir %s) &amp;#34; &amp;#34;for saving: %s&amp;#34;, filename, cwdp ?</description>
    </item>
    <item>
      <title>Redis AOF Rewrite</title>
      <link>https://www6v.github.io/www6vMiddleware/docs/Redis&#43;%E7%BC%93%E5%AD%98/Redis-%E5%9F%BA%E7%A1%80/%E6%8C%81%E4%B9%85%E5%8C%96/aofRewrite/</link>
      <pubDate>Sun, 21 Nov 2021 19:35:54 +0000</pubDate>
      <guid>https://www6v.github.io/www6vMiddleware/docs/Redis&#43;%E7%BC%93%E5%AD%98/Redis-%E5%9F%BA%E7%A1%80/%E6%8C%81%E4%B9%85%E5%8C%96/aofRewrite/</guid>
      <description>一. AOF 重写函数与触发时机&#xD;#&#xD;我们就了解了 AOF 重写的四个触发时机，这里我也给你总结下，方便你回 顾复习。&#xA;时机一:bgrewriteaof 命令被执行。&#xD;#&#xD;时机二:主从复制完成 RDB 文件解析和加载(无论是否成功)。&#xD;#&#xD;而对于 restartAOFAfterSYNC 函数来说，它会在主从节点的复制过程中被调用。简单来 说，就是当主从节点在进行复制时，如果从节点的 AOF 选项被打开，那么在加载解析 RDB 文件时，AOF 选项就会被关闭。然后，无论从节点是否成功加载了 RDB 文件， restartAOFAfterSYNC 函数都会被调用，用来恢复被关闭的 AOF 功能。&#xD;那么在这个过程中，restartAOFAfterSYNC 函数就会调用 startAppendOnly 函数，并进 一步调用 rewriteAppendOnlyFileBackground 函数，来执行一次 AOF 重写。&#xD;时机三:AOF 重写被设置为待调度执行。&#xD;#&#xD;时机四:AOF 被启用，同时 AOF 文件的大小比例超出阈值，以及 AOF 文件的大小绝对 值超出阈值。&#xD;#&#xD;auto-aof-rewrite-percentage:AOF 文件大小超出基础大小的比例，默认值为 100%，即超出 1 倍大小。 auto-aof-rewrite-min-size:AOF 文件大小绝对值的最小值，默认为 64MB。&#xA;另外，这里你还需要注意，在这四个时机下，其实都不能有正在执行的 RDB 子进程和 AOF 重写子进程，否则的话，AOF 重写就无法执行了。&#xA;二. AOF 重写的基本过程&#xD;#&#xD;int rewriteAppendOnlyFileBackground(void) { .</description>
    </item>
    <item>
      <title>Redis RDB</title>
      <link>https://www6v.github.io/www6vMiddleware/docs/Redis&#43;%E7%BC%93%E5%AD%98/Redis-%E5%9F%BA%E7%A1%80/%E6%8C%81%E4%B9%85%E5%8C%96/redisRDB/</link>
      <pubDate>Sat, 02 Jan 2021 21:41:43 +0000</pubDate>
      <guid>https://www6v.github.io/www6vMiddleware/docs/Redis&#43;%E7%BC%93%E5%AD%98/Redis-%E5%9F%BA%E7%A1%80/%E6%8C%81%E4%B9%85%E5%8C%96/redisRDB/</guid>
      <description>&#xA;RDB&#xD;#&#xD;功能 [1]&#xD;#&#xD;只需要把 RDB 文件直接读入内存，可以快速恢复数据库。这就避免了 AOF 需要顺序、逐一重新执行操作命令带来的低效性能问题。&#xA;Redis 设计了 bgsave 和写时复制方式，尽可能减少了内存快照对正常读写的影响，但是，频繁快照仍然是不太能接受的。&#xA;【 总结: bgsave 异步 + 写时复制（copy-on-write）】&#xA;触发机制 [2]&#xD;#&#xD;手动触发 bgsave [3] save 废弃 [3] 自动触发 save的相关配置 从节点全量复制，主节点执行bgsave生成RDB并发送给从节点 其他 优点/缺点[2]&#xD;#&#xD;优点 加载RDB恢复数据远远快于AOF的方式 缺点 没办法做到实时持久化 建议 [1]&#xD;#&#xD;数据不能丢失时，内存快照和 AOF 的混合使用是一个很好的选择； 如果允许分钟级别的数据丢失，可以只使用 RDB； 如果只用 AOF，优先使用 everysec 的配置选项，因为它在可靠性和性能之间取了一个平衡。 参考&#xD;#&#xD;《05丨内存快照：宕机后，Redis如何实现快速恢复？》 《redis开发与运维》 第5章 {% post_link &amp;lsquo;rdb&amp;rsquo; %} self </description>
    </item>
  </channel>
</rss>
