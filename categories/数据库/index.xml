<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>数据库 on 中间件</title>
    <link>https://www6v.github.io/www6vMiddleware/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/</link>
    <description>Recent content in 数据库 on 中间件</description>
    <generator>Hugo</generator>
    <language>en</language>
    <lastBuildDate>Tue, 15 Aug 2023 12:42:56 +0000</lastBuildDate>
    <atom:link href="https://www6v.github.io/www6vMiddleware/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>分布式 数据库 总结</title>
      <link>https://www6v.github.io/www6vMiddleware/docs/RMDB/%E5%88%86%E5%B8%83%E5%BC%8F/distributedDatabase/</link>
      <pubDate>Wed, 09 Feb 2022 12:31:58 +0000</pubDate>
      <guid>https://www6v.github.io/www6vMiddleware/docs/RMDB/%E5%88%86%E5%B8%83%E5%BC%8F/distributedDatabase/</guid>
      <description>参考&#xD;#&#xD;&amp;laquo;分布式数据库30讲&amp;raquo;&#xA;{% post_link &amp;lsquo;distributedDatabaseGlobalTime&amp;rsquo; %} self</description>
    </item>
    <item>
      <title>Redis Rehash机制</title>
      <link>https://www6v.github.io/www6vMiddleware/docs/Redis&#43;%E7%BC%93%E5%AD%98/Redis-%E5%9F%BA%E7%A1%80/%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B/redisRehash/</link>
      <pubDate>Sun, 20 Jun 2021 22:50:50 +0000</pubDate>
      <guid>https://www6v.github.io/www6vMiddleware/docs/Redis&#43;%E7%BC%93%E5%AD%98/Redis-%E5%9F%BA%E7%A1%80/%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B/redisRehash/</guid>
      <description>&#xA;什么时候触发 rehash？&#xD;#&#xD;，_dictExpandIfNeeded 函数中定义了三个扩容条件。 下面的代码就展示了 _dictExpandIfNeeded 函数对这三个条件的定义，你可以看下。 条件一：ht[0]的大小为 0。 条件二：ht[0]承载的元素个数已经超过了 ht[0]的大小，同时 Hash 表可以进行扩容。 条件三：ht[0]承载的元素个数，是 ht[0]的大小的 dict_force_resize_ratio 倍，其中， dict_force_resize_ratio 的默认值是 5。&#xA;rehash 扩容扩多大？&#xD;#&#xD;对 Hash表扩容的思路也很简单，就是如果当前表的已用空间大小为 size，那么就将表扩容到 size*2 的大小。&#xA;rehash 如何执行？&#xD;#&#xD;其实这是因为，Hash 表在执行 rehash 时，由于 Hash 表空间扩大，原本映射到某一位置 的键可能会被映射到一个新的位置上，因此，很多键就需要从原来的位置拷贝到新的位 置。而在键拷贝时，由于 Redis 主线程无法执行其他请求，所以键拷贝会阻塞主线程，这 样就会产生 rehash 开销。&#xA;而为了降低 rehash 开销，Redis 就提出了渐进式 rehash 的方法。&#xA;dictRehash 的主要执行流程&#xD;#&#xD;</description>
    </item>
    <item>
      <title>Redis 架构</title>
      <link>https://www6v.github.io/www6vMiddleware/docs/Redis&#43;%E7%BC%93%E5%AD%98/Redis-%E5%9F%BA%E7%A1%80/Arch-Redis-Cluster/redisArch/</link>
      <pubDate>Tue, 25 May 2021 18:35:49 +0000</pubDate>
      <guid>https://www6v.github.io/www6vMiddleware/docs/Redis&#43;%E7%BC%93%E5%AD%98/Redis-%E5%9F%BA%E7%A1%80/Arch-Redis-Cluster/redisArch/</guid>
      <description>目录&#xD;#&#xD;Redis架构演进[1]&#xD;#&#xD;数据怕丢失 -&amp;gt; 持久化（RDB/AOF） 恢复时间久 -&amp;gt; 主从副本（副本随时可切） 故障手动切换慢 -&amp;gt; 哨兵集群（自动切换） 读存在压力 -&amp;gt; 扩容副本（读写分离） 写存在压力/容量瓶颈 -&amp;gt; 分片集群 分片集群社区方案 -&amp;gt; Twemproxy、Codis（Redis 节点之间无通信，需要部署哨兵，可横向扩容） 分片集群官方方案 -&amp;gt; Redis Cluster （Redis 节点之间 Gossip 协议，无需部署哨兵，可横向扩容） 业务侧升级困难 -&amp;gt; Proxy + Redis Cluster（不侵入业务侧） 主从架构&#xD;#&#xD;主从同步 异步方式来同步数据 最终一致性 分类 增量同步 （同步的是指令） 1.指令记录在master本地的内存 buffer 2.异步将 buffer 中的指令同步到从节点 类似 AOF 快照同步（同步的是内容，全量同步） bgsave存磁盘rdb，然后rdb发到slave，slave装载 优化: 2.8.18 版开始支持无盘复制 哨兵集群 sentinel&#xD;#&#xD;master-slave异步复制, 所以会丢消息&#xA;参数: # 至少有一个slave复制 min-slaves-to-write 1 # slave节点最大10s的延迟 min-slaves-max-lag 10 Redis cluster&#xD;#&#xD;整体架构</description>
    </item>
    <item>
      <title>MySQL 事务-隔离性</title>
      <link>https://www6v.github.io/www6vMiddleware/docs/RMDB/%E5%8D%95%E6%9C%BA/mysqlTransactionAndLock/</link>
      <pubDate>Fri, 14 Aug 2020 17:22:20 +0000</pubDate>
      <guid>https://www6v.github.io/www6vMiddleware/docs/RMDB/%E5%8D%95%E6%9C%BA/mysqlTransactionAndLock/</guid>
      <description>MyISAM vs. InnoDB&#xD;#&#xD;描述 MyISAM InnoDB 行锁(并发高，会死锁) × √ (默认支持)&#xA;Record lock: 锁记录&#xA;Gap lock: 锁范围，不锁记录&#xA;Next-key lock： 锁范围+锁记录 表锁(并发低，不会死锁) √ √ 事务和崩溃恢复 × √ 外键 × √ MVCC × √ 在READ COMMITTED 和 REPEATABLE READ时有效 事务隔离级别 [4]&#xD;#&#xD;隔离级别(从高到低) 脏读 不可重复读&#xA;（重点是修改） 幻影读&#xA;（重点是新增或者删除） SERIALIZABLE × × × REPEATABLE-READ&#xA;（InnoDB默认隔离级别） × × √ READ-COMMITTED × √ √ READ-UNCOMMITTED √ √ √ innodb对于行的查询使用next-key lock Next-locking keying、Gap锁为了解决Phantom Problem幻读问题 当查询的索引含有唯一属性时(单条记录)，将next-key lock降级为record key</description>
    </item>
    <item>
      <title>Redis 总结</title>
      <link>https://www6v.github.io/www6vMiddleware/docs/Redis&#43;%E7%BC%93%E5%AD%98/Redis-%E5%9F%BA%E7%A1%80/overview/redis/</link>
      <pubDate>Sat, 12 Nov 2016 23:29:16 +0000</pubDate>
      <guid>https://www6v.github.io/www6vMiddleware/docs/Redis&#43;%E7%BC%93%E5%AD%98/Redis-%E5%9F%BA%E7%A1%80/overview/redis/</guid>
      <description>事务&#xD;#&#xD;- 原子性 一致性 隔离性 持久性 redis 一定的原子性，但不支持回滚 × √ 通过一定策略可以保证持久性 redis 没有进行回滚，不具备原子性.操作之后写AOF日志 aof可以保证，但从应用层看没有回滚和原子性，所以并不能保证一致性 单线程天然隔离 纯内存(×)RDB Bgsave(√) RDB 异步执行(×) mysql √ √ √ √ mysql undo log 锁 锁 redo log hash命令&#xD;#&#xD;redis hash的结构：一维数组+二维链表（和java的hashmap结构一样）&#xA;redis rehash: 渐进式rehash Java rehash： 一次性将旧数组下挂接的元素全部转移到新数组下面&#xA;IO模型和性能&#xD;#&#xD;非阻塞IO： read， write时不阻塞&#xA;事件轮询和多路复用[8]&#xA;redis性能 最低配置: 4GB， 2核， 链接数2w， QPS 16w&#xA;redis性能高的原因&#xA;高效的数据结构 多路复用IO模型 事件机制 总结:Reactor + 队列 [10] 大体上可以说 Redis 的工作模式是，reactor 模式配合一个队列，用一个 serverAccept 线程来处理建立请求的链接， 并且通过 IO 多路复用模型，让内核来监听这些 socket，一旦某些 socket 的读写事件准备就绪后就对应的事件压入队列中， 然后 worker 工作，由文件事件分派器从中获取事件交于对应的处理器去执行，当某个事件执行完成后文件事件分派器才会从队列中获取下一个事件进行处理。 可以类比在 netty 中，我们一般会设置 bossGroup 和 workerGroup 默认情况下 bossGroup 为 1，workerGroup = 2 * cpu 数量， 这样可以由多个线程来处理读写就绪的事件，但是其中不能有比较耗时的操作如果有的话需要将其放入线程池中，不然会降低其吐吞量。 在 Redis 中我们可以看做这二者的值都是 1。</description>
    </item>
    <item>
      <title>Redis Error-MOVED和ASK指令</title>
      <link>https://www6v.github.io/www6vMiddleware/docs/Redis&#43;%E7%BC%93%E5%AD%98/Redis-%E5%9F%BA%E7%A1%80/Arch-Redis-Cluster/redisError/</link>
      <pubDate>Mon, 28 Mar 2022 10:47:56 +0000</pubDate>
      <guid>https://www6v.github.io/www6vMiddleware/docs/Redis&#43;%E7%BC%93%E5%AD%98/Redis-%E5%9F%BA%E7%A1%80/Arch-Redis-Cluster/redisError/</guid>
      <description>{% details 相关代码 %} cluster.c&#xA;/* Return the pointer to the cluster node that is able to serve the command. * For the function to succeed the command should only target either: * * 1) A single key (even multiple times like LPOPRPUSH mylist mylist). * 2) Multiple keys in the same hash slot, while the slot is stable (no * resharding in progress). * * On success the function returns the node that is able to serve the request.</description>
    </item>
    <item>
      <title>分布式 数据库 比较</title>
      <link>https://www6v.github.io/www6vMiddleware/docs/RMDB/%E5%88%86%E5%B8%83%E5%BC%8F/distributedDatabaseCompare/</link>
      <pubDate>Fri, 11 Mar 2022 20:13:01 +0000</pubDate>
      <guid>https://www6v.github.io/www6vMiddleware/docs/RMDB/%E5%88%86%E5%B8%83%E5%BC%8F/distributedDatabaseCompare/</guid>
      <description>分布式 数据库 比较 [1]&#xD;#&#xD;PolarDB-X TiDB CockroachDB Spanner 分布式事务 MVCC+TSO MVCC+TSO [Percolator][5][6] MVCC+HLC[2][3][4] MVCC+TrueTime API 存储引擎 InnoDB/x-engine&#xA;HEX2(列存) RocksDBTiFlash(列存) RocksDB Colossus 高可用 计算无状态集群&#xA;存储Multi-Paxos 计算无状态集群&#xA;存储Raft 计算存储一体化 集群化 存储Raft 计算存储一体化 集群化 存储Multi-Paxos 数据分区 Hash/List/Range Range/Hash Range/Hash Range/Hash 全局索引 √ √ √ √ HTAP 强隔离 强一致&#xA;MPP并行 强隔离 强一致&#xA;Spark 混合负载&#xA;MPP并行 混合负载&#xA;MPP并行 生态兼容性 基本兼容MySQL 基本兼容MySQL 基本兼容PGSQL 非标准SQL 元数据DDL 全局一致 + Online 全局一致 + Online 全局一致 + Online 全局一致 + Online 全局日志 √ √ √（企业版） × 备份恢复 √ √ √ √ 参考&#xD;#&#xD;《云数据库架构》 2.</description>
    </item>
    <item>
      <title>Redis 的IO模型</title>
      <link>https://www6v.github.io/www6vMiddleware/docs/Redis&#43;%E7%BC%93%E5%AD%98/Redis-%E5%9F%BA%E7%A1%80/overview/redisIO/</link>
      <pubDate>Tue, 18 Jan 2022 21:28:08 +0000</pubDate>
      <guid>https://www6v.github.io/www6vMiddleware/docs/Redis&#43;%E7%BC%93%E5%AD%98/Redis-%E5%9F%BA%E7%A1%80/overview/redisIO/</guid>
      <description>关键词： 单线程，事件， socket， 多路复用&#xD;#&#xD;Redis 的IO模型&#xD;#&#xD;Redis 是单线程，主要是指 Redis 的网络 IO 和键值对读写是由一个线程来完成的，这也是 Redis 对外提供键值存储服务的主要流程。 但 Redis 的其他功能，比如持久化、异步删除、集群数据同步等，其实是由额外的线程执 行的。&#xA;多路复用&#xD;#&#xD;Linux 中的 IO 多路复用机制是指一个线程处理多个 IO 流，就是我们经常听到的 select/epoll 机制。简单来说，在 Redis 只运行单线程的情况下，该机制允许内核中，同 时存在多个监听套接字和已连接套接字。内核会一直监听这些套接字上的连接请求或数据 请求。一旦有请求到达，就会交给 Redis 线程处理，这就实现了一个 Redis 线程处理多个 IO 流的效果。&#xA;为了在请求到达时能通知到 Redis 线程，select/epoll 提供了基于事件的回调机制，即针 对不同事件的发生，调用相应的处理函数。&#xA;epoll的API&#xD;#&#xD;int epoll_create(int size); int epoll_ctl(int epfd, int op, int fd, struct epoll_event *event); // 事件注册 int epoll_wait(int epfd, struct epoll_event * events, int maxevents, int timeout); // 事件分配、事件处理</description>
    </item>
    <item>
      <title>Redis数据结构</title>
      <link>https://www6v.github.io/www6vMiddleware/docs/Redis&#43;%E7%BC%93%E5%AD%98/Redis-%E5%9F%BA%E7%A1%80/%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B/redisDataStructure/</link>
      <pubDate>Wed, 05 May 2021 22:25:55 +0000</pubDate>
      <guid>https://www6v.github.io/www6vMiddleware/docs/Redis&#43;%E7%BC%93%E5%AD%98/Redis-%E5%9F%BA%E7%A1%80/%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B/redisDataStructure/</guid>
      <description>数据结构和实现&#xD;#&#xD;数据结构 基础 优化 特点 String SDS List 双向列表 压缩列表 Hash hash表 压缩列表 渐进式rehash SortedSet 跳表 压缩列表 Set 整数数组 全局hash表 &amp;amp;&amp;amp; 渐进式 rehash&#xD;#&#xD;参考：&#xD;#&#xD;02 | 数据结构:快速的Redis有哪些慢操作?</description>
    </item>
    <item>
      <title>MySQL中的SQL更新语句</title>
      <link>https://www6v.github.io/www6vMiddleware/docs/RMDB/%E5%8D%95%E6%9C%BA/mysqlUpdate/</link>
      <pubDate>Fri, 26 Jun 2020 13:41:44 +0000</pubDate>
      <guid>https://www6v.github.io/www6vMiddleware/docs/RMDB/%E5%8D%95%E6%9C%BA/mysqlUpdate/</guid>
      <description>&#xA;redo log &amp;amp;&amp;amp; bin log&#xD;#&#xD;有了redo log，InnoDB就可以保证即使数据库发生异常重启，之前提交的记录都不会丢失，这个 能力称为crash-safe。&#xA;\ redo log bin log where InnoDB引擎特有的 MySQL的Server层实现的 what 物理日志，记录的是“在某个数据页上做了什么修改” 逻辑日志，记录的是这个语句的原始逻辑 how 循环写的 追加写入的 update in Mysql&#xD;#&#xD;MySQL里的WAL(Write-Ahead Logging)技术，它的关键点就是先写日志，再写磁盘.&#xA;更新流程还涉及两个重要的日志模块，redo log（重做日志）和 binlog（归档日志）。&#xA;图中浅色框表示是在InnoDB内部执行的，深色框表示是在执行器中执行的。&#xA;redo log的写入拆成了两个步骤：prepare和commit，这就是&amp;quot;两阶段提交&amp;quot;, 让redo log和bin log之间的逻辑一致。&#xA;参考&#xD;#&#xD;《MySQL实战45讲 - 日志系统：一条SQL更新语句是如何执行的？》 丁奇 </description>
    </item>
    <item>
      <title>TiKV Transaction-MVCC&#43;TSO</title>
      <link>https://www6v.github.io/www6vMiddleware/docs/RMDB/%E5%88%86%E5%B8%83%E5%BC%8F/tikvMVCCTransaction/</link>
      <pubDate>Mon, 10 Apr 2023 15:43:51 +0000</pubDate>
      <guid>https://www6v.github.io/www6vMiddleware/docs/RMDB/%E5%88%86%E5%B8%83%E5%BC%8F/tikvMVCCTransaction/</guid>
      <description>原理&#xD;#&#xD;Percolator [1]&#xD;#&#xD;总体来说就是一个经过优化的 2PC 的实现，依赖一个单点的授时服务 TSO 来实现单调递增的事务编号生成，提供SI 的隔离级别。&#xA;TiKV 的写事务分为两个阶段 [1]&#xD;#&#xD;1、Prewrite 阶段 MVCC 在对应传统 2PC 的第一阶段的 prewrite 流程。 首先选出一个 primary row 和其他的 secondary rows，然后对 primary row 进行上锁，再对 secondary rows 进行类似的上锁流程。如果任何一步出错，都会进行回滚。完成 prewrite 阶段后，进入 commit 阶段，当前时间戳为 commitTs，TSO 会保证 commitTs &amp;gt; startTs。&#xA;2、Commit 阶段 MVCC 中的 Commit 流程，包括在 primary 上写入 meta，删除 Lock 标记，以及异步提交 secondaries。如果 primary row 提交失败，则整个事务回滚。如果成功，则标志着整个事务提交成功。&#xA;Tidb乐观锁 [2] Tidb悲观锁 [2] TiKV 的读事务 [1]&#xD;#&#xD;在事务中进行读操作的过程。 首先，需要检查行是否被锁定，如果被锁定，则需要等待或者清除锁。然后，需要读取最新的数据版本，方法是读取元数据并找到最大的时间戳。 锁分为两级，Primary和Secondary row，只有Primary row的锁被释放，事务才算提交成功。Secondary row的提交可以异步进行，但在此过程中可能需要清理锁。即使Secondary row提交失败，也可以通过锁找到Primary row，并根据元数据确定事务是回滚还是提交成功。</description>
    </item>
    <item>
      <title>Redis Cluster</title>
      <link>https://www6v.github.io/www6vMiddleware/docs/Redis&#43;%E7%BC%93%E5%AD%98/Redis-%E5%9F%BA%E7%A1%80/Arch-Redis-Cluster/redisCluster/</link>
      <pubDate>Mon, 11 Jul 2022 06:45:41 +0000</pubDate>
      <guid>https://www6v.github.io/www6vMiddleware/docs/Redis&#43;%E7%BC%93%E5%AD%98/Redis-%E5%9F%BA%E7%A1%80/Arch-Redis-Cluster/redisCluster/</guid>
      <description>目录&#xD;#&#xD;Cluster 功能 [1.1]&#xD;#&#xD;Redis Cluster支持多个master，每个master又可以挂载多个slave&#xA;读写分离 支持数据的高可用 故障转移， 高可用 由于Cluster自带Sentinel的故障转移机制，内置了高可用的支持， 无需再去使用哨兵功能&#xA;由对应的集群来负责维护节点、插槽和数据之间的关系&#xA;Slot&#xD;#&#xD;Redis集群有16384个哈希槽每个key通过CRC16校验后对16384取模来决定放置哪个槽，集群的每个节点负责一部分hash槽.&#xA;分片方式&#xD;#&#xD;crc（key）% 16384 映射关系&#xD;#&#xD;key （→ CRC） 分片 分片 (→ 映射关系) 实例&#xA;slot分配&#xD;#&#xD;自动分配slot create() 手动分配slot meet() addSlot() 指令&#xD;#&#xD;MOVED指令， ASK 指令 最大槽数是16384的原因 [1.3]&#xD;#&#xD;[ redis 作者解答] why redis-cluster use 16384 slots? #2576 antirez&#xA;[中文翻译] 正常的心跳数据包带有节点的完整配置，可以用幂等方式用旧的节点替换旧节点，以便更新旧的配置。 这意味着它们包含原始节点的插槽配置，该节点使用2k的空间和16k的插槽，但是会使用8k的空间（使用65k的插槽）。同时，由于其他设计折衷，Redis集群不太可能扩展到1000个以上的主节点。 因此16k处于正确的范围内，以确保每个主机具有足够的插槽，最多可容纳1000个矩阵，但数量足够少，可以轻松地将插槽配置作为原始位图传播。请注意，在小型群集中，位图将难以压缩，因为当N较小时，位图将设置的slot / N位占设置位的很大百分比。&#xA;[解读]&#xA;消息头太大， 发送的心跳包过于庞大 如果槽位为65536，发送心跳信息的消息头达8k，发送的心跳包过于庞大。 在消息头中最占空间的是myslots[CLUSTER_SLOTS/8]。当槽位为65536时，这块的大小是:65536÷8÷1024=8kb&#xA;在消息头中最占空间的是myslots[CLUSTER_SLOTS/8]。当槽位为16384时，这块的大小是:16384∶8∶1024=2kb</description>
    </item>
    <item>
      <title>MySQL的主从 高可用 容灾</title>
      <link>https://www6v.github.io/www6vMiddleware/docs/RMDB/%E5%8D%95%E6%9C%BA/mysqlReliability/</link>
      <pubDate>Sun, 21 Jun 2020 18:14:49 +0000</pubDate>
      <guid>https://www6v.github.io/www6vMiddleware/docs/RMDB/%E5%8D%95%E6%9C%BA/mysqlReliability/</guid>
      <description>MySQL主从复制原理&#xD;#&#xD;主从复制-流程&#xD;#&#xD;MySQL主从复制&#xA;MySQL master 将数据变更写入二进制日志( binary log, 其中记录叫做二进制日志事件binary log events，可以通过 show binlog events 进行查看) MySQL slave 将 master 的 binary log events 拷贝到它的中继日志(relay log) MySQL slave 重放 relay log 中事件，将数据变更反映它自己的数据 主从复制-类型 [6]&#xD;#&#xD;异步复制 半同步复制 MHA + 半同步复制 全同步复制 MGR + 全同步 主备切换 [1]&#xD;#&#xD;因为readonly设置对超级(super)权限用户是无效的，而用于同步更新的线程，就拥有超级权限。&#xA;一个事务日志同步的完整过程是这样的： 在备库B上通过change master命令，设置主库A的IP、端口、用户名、密码，以及要从哪个 位置开始请求binlog，这个位置包含文件名和日志偏移量。 在备库B上执行start slave命令，这时候备库会启动两个线程，就是图中的io_thread和 sql_thread。其中io_thread负责与主库建立连接。 主库A校验完用户名、密码后，开始按照备库B传过来的位置，从本地读取binlog，发给B。 备库B拿到binlog后，写到本地文件，称为中转日志（relay log）。 sql_thread读取中转日志，解析出日志里的命令，并执行。 Master-Master(双M)循环复制问题 [1]&#xD;#&#xD;如果设置了双M结构，日志的执行流就会变成这样： 从节点A更新的事务，binlog里面记的都是A的server id； 传到节点B执行一次以后，节点B生成的binlog 的server id也是A的server id； 再传回给节点A，A判断到这个server id与自己的相同，就不会再处理这个日志。所以，死循 环在这里就断掉了。 主备延迟 [2]&#xD;#&#xD;主备延迟原因 备库所在机器的性能要比主库所在的机器性能差 备库的压力大 解决方案: I.</description>
    </item>
    <item>
      <title>Redis Cluster Spec</title>
      <link>https://www6v.github.io/www6vMiddleware/docs/Redis&#43;%E7%BC%93%E5%AD%98/Redis-%E5%9F%BA%E7%A1%80/Arch-Redis-Cluster/redisClusterSpec/</link>
      <pubDate>Mon, 11 Jul 2022 13:15:05 +0000</pubDate>
      <guid>https://www6v.github.io/www6vMiddleware/docs/Redis&#43;%E7%BC%93%E5%AD%98/Redis-%E5%9F%BA%E7%A1%80/Arch-Redis-Cluster/redisClusterSpec/</guid>
      <description>目录&#xD;#&#xD;设计目标和基本原理[bing]&#xD;#&#xD;高性能和线性扩展&#xD;#&#xD;Redis集群可以支持到1000个节点，使用异步复制和无代理的架构，避免了值合并的开销。&#xA;可接受的写安全性&#xD;#&#xD;Redis集群尽力保留与大多数主节点连接的客户端的写操作，但在分区窗口期内可能会丢失已确认的写操作。&#xA;可用性&#xD;#&#xD;Redis集群可以在大多数主节点可达且每个不可达主节点至少有一个可达副本的情况下存活，并且可以通过副本迁移来提高抗故障能力。&#xA;哈希槽分配&#xD;#&#xD;Redis集群将16384个哈希槽分配给不同的主节点，每个主节点负责存储和服务一部分哈希槽。客户端可以通过计算键的CRC16值对16384取模来得到对应的哈希槽。也可以使用哈希标签来强制将多个键分配到同一个哈希槽，以支持多键操作。&#xA;节点间通信&#xD;#&#xD;Redis集群节点之间使用一个TCP端口和一个二进制协议进行通信，称为集群总线。每个节点都与其他所有节点连接，使用gossip协议来传播集群的信息，如新节点、故障节点、配置变化等。&#xA;客户端重定向&#xD;#&#xD;Redis集群节点不会代理请求，而是根据自己的哈希槽映射表，将客户端重定向到正确的节点。客户端可能收到MOVED或ASK错误，表示需要重新发送请求到另一个节点。MOVED表示哈希槽被永久地分配给了另一个节点，ASK表示哈希槽正在被迁移，需要发送ASKING命令后再发送请求。&#xA;哈希槽迁移&#xD;#&#xD;Redis集群支持在运行时添加和删除节点，这是通过将哈希槽从一个节点移动到另一个节点来实现的。迁移过程中，源节点会将接收到的关于该哈希槽的请求重定向到目标节点，或者直接处理已存在键的请求。目标节点会接收到源节点通过MIGRATE命令发送过来的键，并在迁移完成后更新自己的配置。&#xA;故障检测和副本提升&#xD;#&#xD;Redis集群使用心跳包和gossip协议来检测节点是否可达，并使用PFAIL和FAIL两种标志来表示故障状态。当一个主节点被大多数主节点标记为FAIL时，它的一个副本会发起选举并请求投票。如果获得了大多数主节点的授权，该副本会提升为主节点，并生成一个新的配置版本号（configEpoch）。&#xA;副本选举和配置传播的机制[bing]&#xD;#&#xD;副本选举&#xD;#&#xD;当一个主节点失效时，它的一个副本会尝试发起选举，向其他主节点发送授权请求。如果获得了大多数主节点的回复，它就赢得了选举，并获得了一个新的唯一的配置版本号（configEpoch）。它会开始以主节点的身份广播心跳包，并通知其他节点更新配置。&#xA;配置传播&#xD;#&#xD;当一个节点收到一个心跳包或UPDATE消息时，它会根据一些规则来更新自己的哈希槽映射表。如果一个哈希槽是未分配的，或者有一个新的节点使用更高的configEpoch来声明它，那么接收者会将该哈希槽绑定到新的节点。这样可以保证最后一次故障转移胜出，并且所有节点最终会达成一致。&#xA;节点重置和遗忘&#xD;#&#xD;当一个节点需要从一个集群中移除或加入到另一个集群时，可以使用CLUSTER RESET命令来重置它的状态。这个命令有两种模式：软重置和硬重置。软重置会保留当前的configEpoch，而硬重置会将其设置为0。当一个节点被移除后，其他节点需要使用CLUSTER FORGET命令来删除它在节点表中的条目，并设置一个60秒的禁止期，防止因为gossip协议而重新添加它。&#xA;发布订阅&#xD;#&#xD;Redis集群支持发布订阅功能，客户端可以向任何节点发送SUBSCRIBE或PUBLISH命令。集群会将发布的消息转发到所有其他节点。Redis 7.0及以后版本还支持分片发布订阅功能，其中分片频道根据与键相同的算法分配到哈希槽。分片消息必须发送到拥有该哈希槽的节点，集群会将发布的分片消息转发到该哈希槽所在的分片中的所有节点。&#xA;CRC16算法&#xD;#&#xD;这篇文章最后给出了计算键对应哈希槽的CRC16算法的C语言实现代码。这个算法使用了1021作为多项式，并且不反转输入输出字节。&#xA;参考&#xD;#&#xD;Redis cluster specification ***</description>
    </item>
    <item>
      <title>分布式数据库-全局时钟</title>
      <link>https://www6v.github.io/www6vMiddleware/docs/RMDB/%E5%88%86%E5%B8%83%E5%BC%8F/distributedDatabaseGlobalTime/</link>
      <pubDate>Mon, 11 Apr 2022 11:11:25 +0000</pubDate>
      <guid>https://www6v.github.io/www6vMiddleware/docs/RMDB/%E5%88%86%E5%B8%83%E5%BC%8F/distributedDatabaseGlobalTime/</guid>
      <description>Overview [2]&#xD;#&#xD;TSO 和 HLC 的区别[N AI]&#xD;#&#xD;TSO (Timestamp Ordering) 和 HLC (Hybrid Logical Clock) 都是两种分布式系统中用于解决事件顺序问题的算法。 虽然两种算法都是基于时间戳的，但它们也有着一些区别。&#xA;时间同步&#xD;#&#xD;TSO 需要依赖全局的时间同步服务，如 NTP (Network Time Protocol)，保证所有机器的时钟是一致的。而 HLC 可以在没有全局时钟同步服务的情况下，通过增加逻辑时钟来维护全局时钟的顺序。 这就使得 HLC 比 TSO 更加灵活和适用于更多的场景。&#xA;时钟漂移&#xD;#&#xD;TSO 可能会受到时钟漂移的影响，当时钟出现漂移时，事件的顺序可能会受到影响。而 HLC 可以通过逻辑时钟来解决时钟漂移的问题。这使得 HLC 更加鲁棒，并且可以在更长的时间内保持正确的事件顺序。&#xA;时间精度&#xD;#&#xD;TSO 采用 64 位的时间戳，精度为纳秒级别。而 HLC 采用 64 位的时间戳和 16 位的逻辑时钟，精度为微秒级别，比 TSO 更高。这意味着 HLC 可以更准确地记录事件发生的顺序。&#xA;HLC&#xD;#&#xD;HLC的特点和缺点 [1]&#xD;#&#xD;HLC（Hybrid Logical Clock 混合逻辑时钟）结合了物理时间和逻辑时钟的优点，提供了下面3个特性：&#xA;如果a happened-before b, 则hlc(a) &amp;lt; hlc(b)。不过反之不成立 HLC的时间戳占用的bit数不变 误差有上届。（其实就是NTP的最大误差，也就是所有机器的物理时间的最大误差） HLC本质上来说还是一个逻辑时钟，所以它只能提供partial ordering，而不能提供total ordering。所以2个节点中发生的独立事件a和b，如果他们的timestamp在误差的上届范围内，是无法排序的。</description>
    </item>
    <item>
      <title>MySQL的索引和优化</title>
      <link>https://www6v.github.io/www6vMiddleware/docs/RMDB/%E5%8D%95%E6%9C%BA/mysqlIndex/</link>
      <pubDate>Tue, 10 Sep 2019 16:02:39 +0000</pubDate>
      <guid>https://www6v.github.io/www6vMiddleware/docs/RMDB/%E5%8D%95%E6%9C%BA/mysqlIndex/</guid>
      <description>索引-结构&#xD;#&#xD;索引分类[7]&#xD;#&#xD;分类 含义 特点 关键字 主键索引 针对于表中主键创建的索引 默认自动创建，只能有一个 PRIMARY 唯一索引 避免同一个表中某数据列中的值重复 可以有多个 UNIQUE 常规索引 快速定位特定数据 可以有多个 全文索引 全文索引查找的是文本中的关键词，而不是比较索引中的值 可以有多个 FULLTEXT 分类 含义 特点 聚集索引(Clustered Index) 将数据存储与索引放一块，索引结构的叶子节点保存了行数据 必须有，而且只有一个 二级索引(Secondary Index) 将数据与索引分开存储，索引结构的叶子节点关联的是对应的主键 可以存在多个 聚集索引选取规则: 如果存在主键，主键索引就是聚集索引 如果不存在主键，将使用第一个唯一（UNIQUE）索引作为聚集索引。 如果表没有主键，或没有合适的唯一索引，则InnoDB会自动生成一个rowid作为隐藏的聚集索 引。 索引结构和存储引擎 [3]&#xD;#&#xD;索引的数据结构： B+树能够很好地配合磁盘的读写特性，减少单次查询的磁盘访问次数&#xA;index MyISAM InnoDB Memory B-Tree&#xA;（balanced 平衡的） 支持 支持 支持 Hash 不支持 不支持 支持 R-Tree 空间索引 支持 不支持 不支持 Full-text 支持 支持 不支持 复合索引的数据结构&#xD;#&#xD;create table people {&#xD;last_name,&#xD;first_name,&#xD;dob,&#xD;gender,&#xD;key(last_name, first_name, dob)&#xD;} 索引- 使用&#xD;#&#xD;索引的使用场景&#xD;#&#xD;索引的使用场景 例子 匹配全值 index (a,b,c) a=1 and b=2 and c=3 范围查找 index a&amp;gt;1 and b&amp;lt;3 匹配最左前缀 index(a，b，c) a OR a，b OR a、b、c OR a，c 会使用 b、c 不使用 仅对索引列进行查询（覆盖索引） index a a=1 匹配列前缀 index （a， b） a like &amp;lsquo;WEER%&amp;rsquo; Index Condition Pushdown（ICP） 减少回表IO 索引的失效 [12][7]&#xD;#&#xD;非复合索引</description>
    </item>
    <item>
      <title>Redis 集群  容灾（同城多活）</title>
      <link>https://www6v.github.io/www6vMiddleware/docs/Redis&#43;%E7%BC%93%E5%AD%98/Redis-%E5%9F%BA%E7%A1%80/Arch-Redis-Cluster/redisHA/</link>
      <pubDate>Sun, 31 Jul 2022 11:37:41 +0000</pubDate>
      <guid>https://www6v.github.io/www6vMiddleware/docs/Redis&#43;%E7%BC%93%E5%AD%98/Redis-%E5%9F%BA%E7%A1%80/Arch-Redis-Cluster/redisHA/</guid>
      <description>目录&#xD;#&#xD;1. 背景&#xD;#&#xD;Redis 集群自身已经具备了高可用的特性，即使几个Redis节点异常或者挂掉，Redis 集群也会实现故障自动转移，对应用方来说也可以在很短时间内恢复故障。 但是，如果发生了机房故障(断电、断网等极端情况)，Redis集群节点全部挂掉（过半主节点挂掉），会造成集群服务不可用，对于核心业务来说是不可接受的。 为了应对机房故障情况，保障在这种极端情况下，核心业务仍然可以正常访问 Redis 服务，本文将给出适合我司的 Redis 跨机房高可用解决方案。 2. 目标&#xD;#&#xD;保障单机房整体故障时 Redis 缓存服务正常运行。 单机房故障 RTO：30s，RPO：1s 3. 解决方案&#xD;#&#xD;3.1 核心能力&#xD;#&#xD;客户端流量路由：支持按一定的策略，把流量分流到不同机房；机房故障后，流量自动流向其他机房。 服务端故障转移：支持机房故障后，当前机房原来主节点的从节点，通过选举自动倒换成新的主节点。 管理平台正常服务：任一机房故障，Renault 管理平台使用不受影响。 3.2 工作模式&#xD;#&#xD;组件在机房高可用场景下一般有多种工作模式，典型的有单集群模式及多集群模式。本节描述组件在各种工作模式下的部署方式及工作机制。&#xA;部署方案 方案说明 跨机房混合部署 将Redis集群主节点平均分配到各个机房，主从节点在不同机房 各机房独立部署集群 + 数据单向同步 各机房均独立部署集群，集群为热备模式，写请求均写入同一个集群，然后同步到其他集群 各机房独立部署集群 + 数据双向同步 每个机房部署一套Redis集群，同步核心业务写请求 数据同步方法：&#xA;数据同步方案 方案说明 客户端双写 客户端同时写入到各个集群 客户端代理 Netflix开源实现的Dynomite，通过代理层接受数据后写入各个需要同步的节点&#xA;改造难度大&#xA;客户端需要优化添加Dyno Client服务端每个节点需要部署Dyno Node&#xA;read/write性能较原生差异较大，主要体现在write上，之间的差异随着node节点数越多越严重 伪从节点 基于Redis的Master-Slave复制协议，实现低延时、高可用的Redis多数据中心、跨公网数据复制携程开源系统：https://github.com/ctripcorp/x-pipe阿里RedisShake同步工具 写事件监听+MQ跨集群消息同步 读写在本机房，监听写事件 + MQ消息同步到其他机房需要开启事件通知（PUB），修改Redis配置文件中的 notify-keyspace-events 配置（默认的redis并没有开启这个功能）需要独立服务订阅写事件（SUB），并同步到其他集群依赖MQ组件 不考虑客户端代理、发布订阅写事件</description>
    </item>
    <item>
      <title>数据库  关联查询</title>
      <link>https://www6v.github.io/www6vMiddleware/docs/RMDB/%E5%88%86%E5%B8%83%E5%BC%8F/distributedDatabaseJoinQuery/</link>
      <pubDate>Sun, 30 May 2021 12:05:34 +0000</pubDate>
      <guid>https://www6v.github.io/www6vMiddleware/docs/RMDB/%E5%88%86%E5%B8%83%E5%BC%8F/distributedDatabaseJoinQuery/</guid>
      <description>&#xA;TiDB 的 Join 算法[2][5]&#xD;#&#xD;TiDB 的 Join 算法包括如下几类：&#xA;Hash Join Merge Join Index Hash Join Index Merge Join TiDB 目前表 Join 的方式 [3][4]&#xA;Sort Merge Join Index Nested Loop Join Hash Join 参考&#xD;#&#xD;《20 | 关联查询：如何提升多表Join能力？ 》 TiDB 查询优化及调优系列（二）TiDB 查询计划简介 查看 Join 的执行计划 TiDB 源码阅读系列 TiDB 查询优化及调优系列（四）查询执行计划的调整及优化原理 JOIN 查询的执行计划 比较 </description>
    </item>
    <item>
      <title>MySQL事务-总结</title>
      <link>https://www6v.github.io/www6vMiddleware/docs/RMDB/%E5%8D%95%E6%9C%BA/mysqlTransaction/</link>
      <pubDate>Sat, 21 Feb 2015 14:44:33 +0000</pubDate>
      <guid>https://www6v.github.io/www6vMiddleware/docs/RMDB/%E5%8D%95%E6%9C%BA/mysqlTransaction/</guid>
      <description>&#xA;MySQL Log和事务&#xD;#&#xD;{% post_link &amp;lsquo;mysqlLog&amp;rsquo; %}&#xA;参考&#xD;#&#xD;拨开云雾见天日：剖析单机事务原理 CHEN川 *** 多版本并发控制(MVCC)在分布式系统中的应用 Todd 阿里云分布式缓存OCS与DB之间的数据一致性 杨成虎 乐观锁和 MVCC 的区别？ mysql可重复读和幻读实例 CWeeYii MySQL脏读、虚读、幻读 Eternity味道 MySQL 中事务的实现原理 失效 </description>
    </item>
    <item>
      <title>全局二级索引-GSI</title>
      <link>https://www6v.github.io/www6vMiddleware/docs/RMDB/%E5%88%86%E5%B8%83%E5%BC%8F/globalSecondaryIndex/</link>
      <pubDate>Mon, 05 Jun 2023 14:50:16 +0000</pubDate>
      <guid>https://www6v.github.io/www6vMiddleware/docs/RMDB/%E5%88%86%E5%B8%83%E5%BC%8F/globalSecondaryIndex/</guid>
      <description>&#xA;场景&#xD;#&#xD;[Claude] 分布式数据库的全局二级索引主要有以下几个使用场景: 加速多表关联查询:用全局二级索引构建外键索引,可以有效地加速涉及多表关联的查询。 全表扫描查询:当需要做全表扫描时,使用全局二级索引可以跳过不需要的行,大幅降低扫描成本。 频繁查询的列上:对于数据库中经常需要根据某列进行查询的情况,建立该列的全局二级索引,可以大幅提高查询效率。 需要排序的查询:当需要查询结果按某个列排序时,全局二级索引可以加速排序。 模糊查询优化:通过部分键值匹配,全局二级索引可以优化like查询等模式查询。 分页查询优化:结合 Cursor 标记,全局二级索引可以有效的支持分页查询。&#xA;总的来说,对于需要高效查询、排序、混合查询等复杂查询的分布式数据库而言,引入全局二级索引可以大大提高性能。尤其是处理大规模数据时,二级索引发挥的作用更加明显。&#xA;全局二级索引能够解决什么问题 [1] 如果查询的维度与逻辑表的拆分维度不同，会产生跨分片查询。跨分片查询的增加会导致查询卡慢、连接池耗尽等性能问题。GSI能够通过增加拆分维度来减少跨分片查询，消除性能瓶颈。&#xA;增加拆分维度 [4] 例如，对于在线商城的订单表，假设按照买家用户维度拆分，那么对于卖家查询（例如，查询某个卖家的本月所有订单）就需要扫描所有分区。但是借助全局二级索引，可以仅仅扫描相应卖家所在的索引表分区，快速找到所需的订单信息。&#xA;全局唯一约束 [4] 例如，假设用户表是一张分布式表，按照用户ID分区。若要求用户手机号需要全局唯一，那么本地索引无法满足，必须构建一个按手机号作为索引键（同时也是分区键）的唯一索引。&#xA;全局索引 vs 局部索引 [1][2]&#xD;#&#xD;全局二级索引 [DDIA 基于关键词的二级索引分区] 数据行和对应的索引行保存在不同分片上&#xA;分类 [3] 全局非分区索引（Global Non-Partitioned Index） 全局分区索引（Global Partitioned Index） 局部索引 [DDIA 基于文档的二级索引分区] 如果数据行和对应的索引行保存在相同分片上&#xA;PolarDB 全局索引&#xD;#&#xD;PolarDB-X [1]&#xA;XA多写，保证主表与索引表数据强一致。[性能会不会慢] Online Schema Change，添加GSI不锁主表。 PolarDB-X GSI [4] 每个GSI对应一张分布式索引表，和其他分布式表一样，按照指定的分区规则水平拆分为多张物理表。PolarDB-X使用分布式事务维护主表和索引表之间数据强一致。&#xA;参考&#xD;#&#xD;全局二级索引 PolarDB 设计数据密集型应用-C6-分区和二级索引 DDIA 二级索引 OB 全局二级索引 PolarDB PolarDB-X 全局二级索引 未 PolarDB-X 数据分布解读（三） ：TPCC与透明分布式 未 </description>
    </item>
    <item>
      <title>MySQL Logs</title>
      <link>https://www6v.github.io/www6vMiddleware/docs/RMDB/%E5%8D%95%E6%9C%BA/mysqlLog/</link>
      <pubDate>Sun, 27 Feb 2022 22:25:29 +0000</pubDate>
      <guid>https://www6v.github.io/www6vMiddleware/docs/RMDB/%E5%8D%95%E6%9C%BA/mysqlLog/</guid>
      <description>MySQL Log和事务[0]&#xD;#&#xD;redo log&#xD;#&#xD;有了redolog之后，当对缓冲区的数据进行增删改之后，会首先将操作的数据页的变化，记录在redo log buffer中。在事务提交时，会将redo log buffer中的数据刷新到redo log磁盘文件中。过一段时间之后，如果刷新缓冲区的脏页到磁盘时，发生错误，此时就可以借助于redo log进行数据恢复，这样就保证了事务的持久性。 因为在业务操作中，我们操作数据一般都是随机读写磁盘的，而不是顺序读写磁盘。 而redo log在往磁盘文件中写入数据，由于是日志文件，所以都是顺序写的。顺序写的效率，要远大于随机写。 这种先写日志的方式，称之为** WAL（Write-Ahead Logging）**。 undo log&#xD;#&#xD;回滚日志，用于记录数据被修改前的信息 , 作用包含两个 : **提供回滚(保证事务的原子性) 和MVCC(多版本并发控制) **。&#xA;undo log和redo log记录物理日志不一样，它是逻辑日志。可以认为当delete一条记录时，undolog中会记录一条对应的insert记录，反之亦然，当update一条记录时，它记录一条对应相反的update记录。&#xA;总结&#xD;#&#xD;Log 性质 记录内容 ACID redo log 物理日志[记录内容] wal 保证事务的持久性[D] undo log 物理日志[记录内容] 被修改前的信息，提供回滚 保证事务的原子性[A] ​ binlog 逻辑日志[记录操作]&#xA;MySQL Log和可靠性&#xD;#&#xD;binlog的三种格式[1]&#xD;#&#xD;statement&#xA;row格式&#xA;mixed格式: statement or row格式&#xA;因为有些statement格式的binlog可能会导致主备不一致，所以要使用row格式。 但row格式的缺点是，很占空间。比如你用一个delete语句删掉10万行数据，用statement的话就是一个SQL语句被记录到binlog中，占用几十个字节的空间。但如果用row格式的binlog，就要把这10万条记录都写到binlog中。这样做，不仅会占用更大的空间，同时写binlog也要耗费IO资源，影响执行速度。 所以，MySQL就取了个折中方案，也就是有了mixed格式的binlog。mixed格式的意思是，MySQL自己会判断这条SQL语句是否可能引起主备不一致，如果有可能，就用row格式，否则就用statement格式。 也就是说，mixed格式可以利用statment格式的优点，同时又避免了数据不一致的风险.因此，如果你的线上MySQL设置的binlog格式是statement的话，那基本上就可以认为这是一个不合理的设置。你至少应该把binlog的格式设置为mixed。&#xA;redo log 和 undo log [4]&#xD;#&#xD;redo Log</description>
    </item>
    <item>
      <title>MySQL  锁和死锁</title>
      <link>https://www6v.github.io/www6vMiddleware/docs/RMDB/%E5%8D%95%E6%9C%BA/mysqlDeadLock/</link>
      <pubDate>Tue, 15 Aug 2023 12:42:56 +0000</pubDate>
      <guid>https://www6v.github.io/www6vMiddleware/docs/RMDB/%E5%8D%95%E6%9C%BA/mysqlDeadLock/</guid>
      <description>锁&#xD;#&#xD;行锁， 锁优化 [3]&#xD;#&#xD;在InnoDB事务中，行锁是在需要的时候才加上的，但并不是不需要了就立刻释放，而是要等到事务结束时才释放。这个就是两阶段锁协议。 知道了这个设定，对我们使用事务有什么帮助呢？那就是，如果你的事务中需要锁多个行，要把最可能造成锁冲突、最可能影响并发度的锁尽量往后放.[todo 加个例子]&#xA;行锁是通过索引实现的，如果不通过索引条件检索数据，那么 InnoDB 将对表中所有的记录进行加锁。&#xA;行锁的具体实现算法有三种：record lock、gap lock 以及 next-key lock。&#xA;record lock是专门对索引项加锁； gap lock 是对索引项之间的间隙加锁； next-key lock 则是前面两种的组合，对索引项以其之间的间隙加锁。 只在可重复读或以上隔离级别下的特定操作才会取得 gap lock 或 next-key lock，在Select 、Update 和 Delete 时，除了基于唯一索引的查询之外，其他索引查询时都会获取gap lock 或 next-key lock，即锁住其扫描的范围。 隐式锁和显示锁&#xD;#&#xD;显示锁 SELECT &amp;hellip; LOCK IN SHARE MODE(加共享锁); SELECT &amp;hellip; FOR UPDATE(加排他锁);&#xA;死锁&#xD;#&#xD;死锁和死锁检测 [5]&#xD;#&#xD;当出现死锁以后，有两种策略：&#xA;一种策略是，直接进入等待，直到超时。这个超时时间可以通过参数 innodb_lock_wait_timeout来设置。 innodb_lock_wait_timeout的默认值是50s。 实际中不用这种策略。&#xA;另一种策略是，发起死锁检测，发现死锁后，主动回滚死锁链条中的某一个事务，让其他事 务得以继续执行。将参数 innodb_deadlock_detect 设置为on，表示开启这个逻辑。&#xA;带来的问题：每个新来的被堵住的线程，都要判断会不会由于自己的加入导致了死锁，这是一个时间复杂度是O(n)的操作。假设有1000个并发线程要同时更新同一行，那么死锁检测操作就是100万这个量级的。虽然最终检测的结果是没有死锁，但是这期间要消耗大量的CPU资源。&#xA;一种解决思路是控制并发度：并发控制要做在数据库服务端。如果有中间件，可以考虑在中间件实现；如果-团队有能修改MySQL源码的人，也可以做在MySQL里面。基本思路就是，对于相同行的更新，-在进入引擎之前排队。这样在InnoDB内部就不会有大量的死锁检测工作了。</description>
    </item>
    <item>
      <title>MySQL 主从延迟</title>
      <link>https://www6v.github.io/www6vMiddleware/docs/RMDB/%E5%8D%95%E6%9C%BA/mysqlMasterSlaveDelay/</link>
      <pubDate>Tue, 16 Aug 2022 16:01:58 +0000</pubDate>
      <guid>https://www6v.github.io/www6vMiddleware/docs/RMDB/%E5%8D%95%E6%9C%BA/mysqlMasterSlaveDelay/</guid>
      <description>&#xA;案例 [1]&#xD;#&#xD;案例一：主库DML请求频繁&#xD;#&#xD;解决思路 如果是MySQL 5.7以下的版本，可以做分片(sharding)，通过水平扩展(scale out)的方法打散写请求，提升写请求写入binlog的并行度。 MySQL 5.7以上的版本， 在MySQL 5.7，使用了基于逻辑时钟(Group Commit)的并行复制。 而在MySQL 8.0，使用了基于Write Set的并行复制。 案例二：主库执行大事务&#xD;#&#xD;解决思路 拆分大事务语句到若干小事务中，这样能够进行及时提交，减小主从复制延时。 案例三：主库对大表执行DDL语句&#xD;#&#xD;解决思路 避免业务高峰，尽量安排在业务低峰期执行 ； set sql_log_bin=0后，分别在主从库上手动执行DDL（此操作对于某些DDL操作会造成数据不一致，请务必严格测试） 参考&#xD;#&#xD;高可用数据库主从复制延时的解决方案 《26 | 备库为什么会延迟好几个小时？》 未 </description>
    </item>
    <item>
      <title>Redis 混合持久化</title>
      <link>https://www6v.github.io/www6vMiddleware/docs/Redis&#43;%E7%BC%93%E5%AD%98/Redis-%E5%9F%BA%E7%A1%80/%E6%8C%81%E4%B9%85%E5%8C%96/redisBothAofAndRDB/</link>
      <pubDate>Mon, 10 Jul 2023 15:48:29 +0000</pubDate>
      <guid>https://www6v.github.io/www6vMiddleware/docs/Redis&#43;%E7%BC%93%E5%AD%98/Redis-%E5%9F%BA%E7%A1%80/%E6%8C%81%E4%B9%85%E5%8C%96/redisBothAofAndRDB/</guid>
      <description>&#xA;Redis 混合持久化&#xD;#&#xD;数据恢复顺序和加载流程 [2][3]&#xD;#&#xD;在这种情况下， 当redis重启的时候会优先载入AOF文件来恢复原始的数据 ，因为在通常情况下AOF文件保存的数据集要比RDB文件保存的数据集要完整。&#xA;RDB和AOF共存时会优先加载AOF文件&#xA;【主从切换 优先加载 RDB -&amp;gt; 速度】 【redis重启 优先加载 AOF -&amp;gt; 数据完整性】&#xA;开启&#xD;#&#xD;aof-use-rdb-preamble no -&amp;gt; yes 原理 [3]&#xD;#&#xD;RDB镜像做全量持久化，AOF做增量持久化 先使用RDB进行快照存储，然后使用AOF持久化记录所有的写操作，当重写策略满足或手动触发重写的时候，将最新的数据存储为新的RDB记录。 这样的话，重启服务的时候会从RDB和AOF两部分恢复数据，既保证了数据完整性，又提高了恢复数据的性能。简单来说:混合持久化方式产生的文件一部分是RDB格式，一部分是AOF格式。&#xA;AOF+RDB混合[1]&#xD;#&#xD;而混合使用 RDB 和 AOF，正好可以取两者之长，避两者之短，以较小的性能开销保证数据可靠性和性能。&#xA;参考&#xD;#&#xD;《05丨内存快照：宕机后，Redis如何实现快速恢复？》 redis++：Redis持久化 rdb &amp;amp; aof 工作原理及流程图 （三） RDB-AOF混合持久化 尚硅谷Redis零基础到进阶，最强redis7教程，阳哥亲自带练（附redis面试题） </description>
    </item>
    <item>
      <title>Redis 主从复制</title>
      <link>https://www6v.github.io/www6vMiddleware/docs/Redis&#43;%E7%BC%93%E5%AD%98/Redis-%E5%9F%BA%E7%A1%80/%E6%8C%81%E4%B9%85%E5%8C%96/redisReplica/</link>
      <pubDate>Sun, 10 Jul 2022 19:04:46 +0000</pubDate>
      <guid>https://www6v.github.io/www6vMiddleware/docs/Redis&#43;%E7%BC%93%E5%AD%98/Redis-%E5%9F%BA%E7%A1%80/%E6%8C%81%E4%B9%85%E5%8C%96/redisReplica/</guid>
      <description>&#xA;主从复制流程&#xD;#&#xD;主从库第一次同步的流程&#xD;#&#xD;主从库增量复制流程&#xD;#&#xD;repl_backlog_buffer 是一个环形缓冲区，主库会记录自己写到的位置，从库则会记录自己 已经读到的位置。&#xA;缺点 [3]&#xD;#&#xD;主从延迟 复制偏移量：master_repl_offset | slave_repl_offset master挂了怎么办？ 默认情况下，不会在slave节点中自动选一个master 每次都要人工干预 需要Redis哨兵(sentinel) 参考&#xD;#&#xD;《06 | 数据同步：主从库如何实现数据一致？》 redis主从复制、主从延迟知几何 复制原理和工作流程 61_redis主从复制之工作流程总结 V 62_redis主从复制之痛点和改进需求 V </description>
    </item>
    <item>
      <title>Redis AOF</title>
      <link>https://www6v.github.io/www6vMiddleware/docs/Redis&#43;%E7%BC%93%E5%AD%98/Redis-%E5%9F%BA%E7%A1%80/%E6%8C%81%E4%B9%85%E5%8C%96/redisAOF/</link>
      <pubDate>Tue, 18 Jan 2022 22:21:15 +0000</pubDate>
      <guid>https://www6v.github.io/www6vMiddleware/docs/Redis&#43;%E7%BC%93%E5%AD%98/Redis-%E5%9F%BA%E7%A1%80/%E6%8C%81%E4%B9%85%E5%8C%96/redisAOF/</guid>
      <description>AOF&#xD;#&#xD;定义[1]&#xD;#&#xD;[AOF不是WAL，是先操作，后记录日志。]&#xA;传统数据库的日志，例如 redo log(重做日志)，记录的是修改后的数据，而AOF里记录的是Redis收到的每一条命令，这些命令是以文本形式保存的。&#xA;AOF 日志正好相反，它是写后日志，“写后”的意思是 Redis 是先执行命令，把数据写入内存，然后才记录日志。&#xA;而写后日志这种方式，就是先让系统执行命令，只有命令能执行成功，才会被记录到日志中，否则，系统就会直接向客户端报错。 所以，Redis 使用写后日志这一方式的一大好处是，可以避免出现记录错误命令的情况。&#xA;AOF 还有一个好处：它是在命令执行后才记录日志，所以不会阻塞当前的写操作。&#xA;AOF 是 写前日志&#xA;两个潜在的风险 [1]&#xD;#&#xD;如果刚执行完一个命令，还没有来得及记日志就宕机了，那么这个命令和相应的数 据就有丢失的风险. AOF 日志也是在主线程中执行的，如果在把日志文件写入磁盘时，磁盘写压力大，就 会导致写盘很慢，进而导致后续的操作也无法执行了. 三种写回策略 [1]&#xD;#&#xD;AOF 配置项 - appendfsync 的三个可选值 Always，同步写回：每个写命令执行完，立马同步地将日志写回磁盘； Everysec，每秒写回：每个写命令执行完，只是先把日志写到 AOF 文件的内存缓冲区，每隔一秒把缓冲区中的内容写入磁盘； No，操作系统控制的写回：每个写命令执行完，只是先把日志写到 AOF 文件的内存缓冲区，由操作系统决定何时将缓冲区内容写回磁盘。 关闭AOF落盘 [2]&#xD;#&#xD;AOF落盘会带来一定写性能损耗，如果将Redis实例应用于纯缓存场景中，对数据持久化没有需求，您可以按照本章节的说明，修改appendonly参数的值，关闭AOF落盘。&#xA;AOF Rewrite过程&#xD;#&#xD;功能 压缩AOF文件的大小&#xA;AOF Rewrite过程 [1] 非阻塞的重写&#xA;一个拷贝，两处日志 [1] 触发机制 [4]&#xA;手动触发 bgrewriteaof 命令 自动触发 AOF文件大小 参考&#xD;#&#xD;《04 | AOF日志:宕机了，Redis如何避免数据丢失?</description>
    </item>
    <item>
      <title>Redis 事务</title>
      <link>https://www6v.github.io/www6vMiddleware/docs/Redis&#43;%E7%BC%93%E5%AD%98/Redis-%E5%9F%BA%E7%A1%80/%E4%BA%8B%E5%8A%A1/redisTransaction/</link>
      <pubDate>Tue, 18 Jan 2022 21:54:01 +0000</pubDate>
      <guid>https://www6v.github.io/www6vMiddleware/docs/Redis&#43;%E7%BC%93%E5%AD%98/Redis-%E5%9F%BA%E7%A1%80/%E4%BA%8B%E5%8A%A1/redisTransaction/</guid>
      <description>事务的 ACID 属性是我们使用事务进行正确操作的基本要求。&#xA;Redis 的事务机制可以保证一致性和隔离性，但是无法保证持久性。&#xA;不过，因为 Redis 本身是内存数据库，持久性并不是一个必须的属性，我们更加关注的还是原子性、 一致性和隔离性这三个属性。&#xA;原子性的情况比较复杂，只有当事务中使用的命令语法有误时，原子性得不到保证，在其它情况下，事务都可以原子性执行。&#xA;事务 是否能保证 一致性 C 能保证 隔离性 I 能保证 原子性 A 能保证(命令语法无误时) 持久性 D 不能保证 【redis cluster 没有事务】&#xA;参考&#xD;#&#xD;31 | 事务机制:Redis能实现ACID属性吗?&#xA;[redis]redis集群不支持事务multi、exec 失效</description>
    </item>
    <item>
      <title>Redis RDB源码</title>
      <link>https://www6v.github.io/www6vMiddleware/docs/Redis&#43;%E7%BC%93%E5%AD%98/Redis-%E5%9F%BA%E7%A1%80/%E6%8C%81%E4%B9%85%E5%8C%96/rdb/</link>
      <pubDate>Wed, 08 Dec 2021 20:28:02 +0000</pubDate>
      <guid>https://www6v.github.io/www6vMiddleware/docs/Redis&#43;%E7%BC%93%E5%AD%98/Redis-%E5%9F%BA%E7%A1%80/%E6%8C%81%E4%B9%85%E5%8C%96/rdb/</guid>
      <description>/// 对应了 Redis 的 save 命 令，会在 save 命令的实现函数 saveCommand(在 rdb.c 文件中)中被调用 /* Save the DB on disk. Return C_ERR on error, C_OK on success. */ int rdbSave(char *filename, rdbSaveInfo *rsi) { char tmpfile[256]; char cwd[MAXPATHLEN]; /* Current working dir path for error messages. */ FILE *fp; rio rdb; int error = 0; snprintf(tmpfile,256,&amp;#34;temp-%d.rdb&amp;#34;, (int) getpid()); fp = fopen(tmpfile,&amp;#34;w&amp;#34;); if (!fp) { char *cwdp = getcwd(cwd,MAXPATHLEN); serverLog(LL_WARNING, &amp;#34;Failed opening the RDB file %s (in server root dir %s) &amp;#34; &amp;#34;for saving: %s&amp;#34;, filename, cwdp ?</description>
    </item>
    <item>
      <title>Redis AOF Rewrite</title>
      <link>https://www6v.github.io/www6vMiddleware/docs/Redis&#43;%E7%BC%93%E5%AD%98/Redis-%E5%9F%BA%E7%A1%80/%E6%8C%81%E4%B9%85%E5%8C%96/aofRewrite/</link>
      <pubDate>Sun, 21 Nov 2021 19:35:54 +0000</pubDate>
      <guid>https://www6v.github.io/www6vMiddleware/docs/Redis&#43;%E7%BC%93%E5%AD%98/Redis-%E5%9F%BA%E7%A1%80/%E6%8C%81%E4%B9%85%E5%8C%96/aofRewrite/</guid>
      <description>一. AOF 重写函数与触发时机&#xD;#&#xD;我们就了解了 AOF 重写的四个触发时机，这里我也给你总结下，方便你回 顾复习。&#xA;时机一:bgrewriteaof 命令被执行。&#xD;#&#xD;时机二:主从复制完成 RDB 文件解析和加载(无论是否成功)。&#xD;#&#xD;而对于 restartAOFAfterSYNC 函数来说，它会在主从节点的复制过程中被调用。简单来 说，就是当主从节点在进行复制时，如果从节点的 AOF 选项被打开，那么在加载解析 RDB 文件时，AOF 选项就会被关闭。然后，无论从节点是否成功加载了 RDB 文件， restartAOFAfterSYNC 函数都会被调用，用来恢复被关闭的 AOF 功能。&#xD;那么在这个过程中，restartAOFAfterSYNC 函数就会调用 startAppendOnly 函数，并进 一步调用 rewriteAppendOnlyFileBackground 函数，来执行一次 AOF 重写。&#xD;时机三:AOF 重写被设置为待调度执行。&#xD;#&#xD;时机四:AOF 被启用，同时 AOF 文件的大小比例超出阈值，以及 AOF 文件的大小绝对 值超出阈值。&#xD;#&#xD;auto-aof-rewrite-percentage:AOF 文件大小超出基础大小的比例，默认值为 100%，即超出 1 倍大小。 auto-aof-rewrite-min-size:AOF 文件大小绝对值的最小值，默认为 64MB。&#xA;另外，这里你还需要注意，在这四个时机下，其实都不能有正在执行的 RDB 子进程和 AOF 重写子进程，否则的话，AOF 重写就无法执行了。&#xA;二. AOF 重写的基本过程&#xD;#&#xD;int rewriteAppendOnlyFileBackground(void) { .</description>
    </item>
    <item>
      <title>Redis RDB</title>
      <link>https://www6v.github.io/www6vMiddleware/docs/Redis&#43;%E7%BC%93%E5%AD%98/Redis-%E5%9F%BA%E7%A1%80/%E6%8C%81%E4%B9%85%E5%8C%96/redisRDB/</link>
      <pubDate>Sat, 02 Jan 2021 21:41:43 +0000</pubDate>
      <guid>https://www6v.github.io/www6vMiddleware/docs/Redis&#43;%E7%BC%93%E5%AD%98/Redis-%E5%9F%BA%E7%A1%80/%E6%8C%81%E4%B9%85%E5%8C%96/redisRDB/</guid>
      <description>&#xA;RDB&#xD;#&#xD;功能 [1]&#xD;#&#xD;只需要把 RDB 文件直接读入内存，可以快速恢复数据库。这就避免了 AOF 需要顺序、逐一重新执行操作命令带来的低效性能问题。&#xA;Redis 设计了 bgsave 和写时复制方式，尽可能减少了内存快照对正常读写的影响，但是，频繁快照仍然是不太能接受的。&#xA;【 总结: bgsave 异步 + 写时复制（copy-on-write）】&#xA;触发机制 [2]&#xD;#&#xD;手动触发 bgsave [3] save 废弃 [3] 自动触发 save的相关配置 从节点全量复制，主节点执行bgsave生成RDB并发送给从节点 其他 优点/缺点[2]&#xD;#&#xD;优点 加载RDB恢复数据远远快于AOF的方式 缺点 没办法做到实时持久化 建议 [1]&#xD;#&#xD;数据不能丢失时，内存快照和 AOF 的混合使用是一个很好的选择； 如果允许分钟级别的数据丢失，可以只使用 RDB； 如果只用 AOF，优先使用 everysec 的配置选项，因为它在可靠性和性能之间取了一个平衡。 参考&#xD;#&#xD;《05丨内存快照：宕机后，Redis如何实现快速恢复？》 《redis开发与运维》 第5章 {% post_link &amp;lsquo;rdb&amp;rsquo; %} self </description>
    </item>
  </channel>
</rss>
